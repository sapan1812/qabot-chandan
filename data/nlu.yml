version: "2.0"

nlu:
- intent: welcome
  examples: |
    - hey
    - hello
    - hi
    - hello there
    - good morning
    - good evening
    - moin
    - hey there
    - let's go
    - hey dude
    - goodmorning
    - goodevening
    - good afternoon

- intent: subject
  examples: |
    - python
    - Python
    - 1
    - 1.

- intent: nonsubject
  examples: |
    - hadoop
    - Swift
    - swift
    - 2
    - 3
    - Hadoop

- intent: answer
  examples: |

    - use random.choice import random foo = [''a'','b'','c'','d'','e'']\n
      print(random.choice(foo))\n
    - yes. use os.path.splitext  import os  filename, file_extension = os.path.splitext(''pathtosomefile.ext'')  filename\n
     'pathtosomefile''  file_extension'.ext''\n
    - import os.path extension = os.path.splitext(filename)[1]\n
    - the most pythonic way to check the type of an object is... not to check\n
      it. since python encourages duck typing, you should just try to use the object''s\n
      methods the way you want to use them. so if your function is looking for a writable\n
      file object, don''t check that it''s a subclass of file, just try to use its .write()\n
      method! of course, sometimes these nice abstractions break down and isinstance(obj,\n
      cls) is what you need. but use sparingly.\n
    - i think the cool thing about using a dynamic language like python is you\n
      really shouldn''t have to check something like that. i would just call the required\n
      methods on your object and catch an attributeerror. later on this will allow you\n
      to call your methods with other (seemingly unrelated) objects to accomplish different\n
      tasks, such as mocking an object for testing. i''ve used this alot when getting\n
      data off the web with urllib2.urlopen() which returns a file like object. this\n
      can in turn can be passed to almost any method that reads from a file, because\n
      is implements the same read() method as a real file. but i''m sure there is a\n
      time and place for using isinstance(), otherwise it probably wouldn''t be there\n
      )\n
    - isinstance(o, str) link\n
    - isinstance(o, str) will return true if o is an str or is of a type that\n
      inherits from str. type(o) == str will return true if and only if o is a str.\n
      it will return false if o is of a type that inherits from str.\n
    - to check if the type of o is exactly str type(o) is str to check if o\n
      is an instance of str or any subclass of str (this would be the "canonical" way)\n
      isinstance(o, str) the following also works, and can be useful in some cases\n
      issubclass(type(o), str) type(o) in ([str] + str.__subclasses__()) see built-in\n
      functions in the python library reference for relevant information. one more note\n
      in this case, you may actually want to use isinstance(o, basestring) because\n
      this will also catch unicode strings (unicode is not a subclass of str; both str\n
      and unicode are subclasses of basestring). alternatively, isinstance accepts a\n
      tuple of classes. this will return true if x is an instance of any subclass of\n
      any of (str, unicode) isinstance(o, (str, unicode))\n
    - from the python docs on os.walk() # delete everything reachable from the\n
      directory named in'top'', # assuming there are no symbolic links. # caution\n
      this is dangerous! for example, if top ==''', it # could delete all your disk\n
      files. import os for root, dirs, files in os.walk(top, topdown=false) for name\n
      in files os.remove(os.path.join(root, name)) for name in dirs os.rmdir(os.path.join(root,\n
      name))\n
    - import shutil shutil.rmtree(''folder_name'') standard library reference\n
      shutil.rmtree.\n
    - if you need to transform keys or values before creating a dictionary then\n
      a generator expression could be used. example  adict = dict((str(k), v) for k,\n
      v in zip([''a'', 1,'b''], [2,'c'', 3])) take a look code like a pythonista\n
      idiomatic python.\n
    - try this  import itertools  keys = (''name'','age'','food'')  values\n
      (''monty'', 42,'spam'')  adict = dict(itertools.izip(keys,values))  adict\n
      {''food'''spam'','age'' 42,'name'''monty''} it was the simplest solution\n
      i could come up with. ps it''s also more economical in memory consumption compared\n
      to zip.\n
    -  keys = (''name'','age'','food'')  values = (''monty'', 42,'spam'')  dict(zip(keys,\n
      values)) {''food'''spam'','age'' 42,'name'''monty''}\n
    - like this  keys = [''a'','b'','c'']  values = [1, 2, 3]  dictionary\n
      dict(zip(keys, values))  print dictionary {''a'' 1,'b'' 2,'c'' 3} voila\n
      ) the pairwise dict constructor and zip function are awesomely useful\n
    - this was trivial. each module has a __file__ variable that shows its relative\n
      path from where you are right now. therefore, getting a directory for the module\n
      to notify it is simple as os.path.dirname(__file__)\n
    - import a_module print a_module.__file__ will actually give you the path\n
      to the .pyc file that was loaded, at least on mac os x. so i guess you can do\n
      import os path = os.path.dirname(amodule.__file__) you can also try path = os.path.abspath(amodule.__file__)\n
      to get the directory to look for changes.\n
    - for cross language projects i found out that strings containing rfc 3339\n
      dates are the best way to go. a rfc 3339 date looks like this 1985-04-12t232050.52z\n
      i think most of the format is obvious. the only somewhat unusual thing may be\n
      the "z" at the end. it stands for gmtutc. you could also add a timezone offset\n
      like +0200 for cest (germany in summer). i personally prefer to keep everything\n
      in utc until it is displayed. for displaying, comparisons and storage you can\n
      leave it in string format across all languages. if you need the date for calculations\n
      easy to convert it back to a native date object in most language. so generate\n
      the json like this json.dump(datetime.now().strftime(''%y-%m-%dt%h%m%s''))\n
      unfortunately javascripts date constructor doesn''t accept rfc 3339 strings but\n
      there are many parsers available on the internet. hutools.hujson tries to handle\n
      the most common encoding issues you might come across in python code including\n
      datedatetime objects while handling timezones correctly.\n
    - if you''re certain that only javascript will be consuming the json, i prefer\n
      to pass javascript date objects directly. the ctime() method on datetime objects\n
      will return a string that the javascript date object can understand. import datetime\n
      date = datetime.datetime.today() json ='{"mydate"new date("%s")}'' % date.ctime()\n
      javascript will happily use that as an object literal, and you''ve got your date\n
      object built right in.\n
    - see python pep 8. function names should be lowercase, with words separated\n
      by underscores as necessary to improve readability. mixedcase is allowed only\n
      in contexts where that''s already the prevailing style variables... use the function\n
      naming rules lowercase with words separated by underscores as necessary to improve\n
      readability. personally, i deviate from this because i also prefer mixedcase over\n
      lower_case for my own projects.\n
    - the coding style is usually part of an organization''s internal policyconvention\n
      standards, but i think in general, the all_lower_case_underscore_separator style\n
      (also called snake_case) is most common in python.\n
    - david goodger (in "code like a pythonista" here) describes the pep 8 recommendations\n
      as follows joined_lower for functions, methods, attributes, variables joined_lower\n
      or all_caps for constants studlycaps for classes camelcase only to conform to\n
      pre-existing conventions\n
    - there is pep 8, as other answers show, but pep 8 is only the styleguide\n
      for the standard library, and it''s only taken as gospel therein. one of the most\n
      frequent deviations of pep 8 for other pieces of code is the variable naming,\n
      specifically for methods. there is no single predominate style, although considering\n
      the volume of code that uses mixedcase, if one were to make a strict census one\n
      would probably end up with a version of pep 8 with mixedcase. there is little\n
      other deviation from pep 8 that is quite as common.\n
    - most python people prefer underscores, but even i am using python since\n
      more than 5 years right now, i still do not like them. they just look ugly to\n
      me, but maybe that''s all the java in my head. i simply like camelcase better\n
      since it fits better with the way classes are named, it feels more logical to\n
      have someclass.dosomething() than someclass.do_something(). if you look around\n
      in the global module index in python, you will find both, which is due to the\n
      fact that it''s a collection of libraries from various sources that grew overtime\n
      and not something that was developed by one company like sun with strict coding\n
      rules. i would say the bottom line is use whatever you like better, it''s just\n
      a question of personal taste.\n
    - personally i try to use camelcase for classes, mixedcase methods and functions.\n
      variables are usually underscore separated (when i can remember). this way i can\n
      tell at a glance what exactly i''m calling, rather than everything looking the\n
      same.\n
    - as mentioned, pep 8 says to use lower_case_with_underscores for variables,\n
      methods and functions. i prefer using lower_case_with_underscores for variables\n
      and mixedcase for methods and functions makes the code more explicit and readable.\n
      thus following the zen of python''s "explicit is better than implicit" and "readability\n
      counts"\n
    - typically, one follow the conventions used in the language''s standard\n
      library.\n
    -  import os  os.path.abspath("mydirmyfile.txt")\n
    -  import os  os.path.abspath(''mydirmyfile.txt'')'c\\example\\cwd\\mydir\\myfile.txt'' \n
    - better still, install the path.py module, it wraps all the os.path functions\n
      and other related functions into methods on an object that can be used wherever\n
      strings are used  from path import path  path(''mydirmyfile.txt'').abspath()\n
     'c\\example\\cwd\\mydir\\myfile.txt'' \n
    - edit see blair conrad''s answer for a cleaner solution  import datetime  datetime.date\n
      (2000, 2, 1) - datetime.timedelta (days = 1) datetime.date(2000, 1, 31) \n
    - edit see my other answer. it has a better implementation than this one,\n
      which i leave here just in case someone''s interested in seeing how one might\n
      "roll your own" calculator. john millikin gives a good answer, with the added\n
      complication of calculating the first day of the next month. the following isn''t\n
      particularly elegant, but to figure out the last day of the month that any given\n
      date lives in, you could try def last_day_of_month(date) if date.month == 12\n
      return date.replace(day=31) return date.replace(month=date.month+1, day=1) - datetime.timedelta(days=1)  last_day_of_month(datetime.date(2002,\n
      1, 17)) datetime.date(2002, 1, 31)  last_day_of_month(datetime.date(2002, 12,\n
      9)) datetime.date(2002, 12, 31)  last_day_of_month(datetime.date(2008, 2, 14))\n
      datetime.date(2008, 2, 29)\n
    - another solution would be to do something like this from datetime import\n
      datetime def last_day_of_month(year, month) """ work out the last day of the\n
      month """ last_days = [31, 30, 29, 28, 27] for i in last_days try end = datetime(year,\n
      month, i) except valueerror continue else return end.date() return none and\n
      use the function like this   last_day_of_month(2008, 2) datetime.date(2008, 2,\n
      29)  last_day_of_month(2009, 2) datetime.date(2009, 2, 28)  last_day_of_month(2008,\n
      11) datetime.date(2008, 11, 30)  last_day_of_month(2008, 12) datetime.date(2008,\n
      12, 31)\n
    - you would want to use __slots__ if you are going to instantiate a lot (hundreds,\n
      thousands) of objects of the same class. __slots__ only exists as a memory optimization\n
      tool. it''s highly discouraged to use __slots__ for constraining attribute creation,\n
      and in general you want to avoid it because it breaks pickle, along with some\n
      other introspection features of python.\n
    - quoting jacob hallen the proper use of __slots__ is to save space in objects.\n
      instead of having a dynamic dict that allows adding attributes to objects at anytime,\n
      there is a static structure which does not allow additions after creation. this\n
      saves the overhead of one dict for every object that uses slots. while this is\n
      sometimes a useful optimization, it would be completely unnecessary if the python\n
      interpreter was dynamic enough so that it would only require the dict when there\n
      actually were additions to the object. unfortunately there is a side effect to\n
      slots. they change the behavior of the objects that have slots in a way that can\n
      be abused by control freaks and static typing weenies. this is bad, because the\n
      control freaks should be abusing the metaclasses and the static typing weenies\n
      should be abusing decorators, since in python, there should be only one obvious\n
      way of doing something. making cpython smart enough to handle saving space without\n
      __slots__ is a major undertaking, which is probably why it is not on the list\n
      of changes for p3k (yet).\n
    - i didn''t notice this earlier when i was looking at the documentation for\n
      the calendar module, but a method called monthrange provides this information\n
      monthrange(year, month) &nbsp;&nbsp;&nbsp;&nbsp;returns weekday of first day of\n
      the month and number of days in month, for the specified year and month.  import\n
      calendar  calendar.monthrange(2002,1) (1, 31)  calendar.monthrange(2008,2) (4,\n
      29)  calendar.monthrange(2100,2) (0, 28) so calendar.monthrange(year, month)[1]\n
      seems like the simplest way to go. just to be clear, monthrange supports leap\n
      years as well  from calendar import monthrange  monthrange(2012, 2) (2, 29) my\n
      previous answer still works, but is clearly suboptimal.\n
    - A_Body "you have \xE2\x80\x94 essentially \xE2\x80\x94 no use for __slots__. for\\n
      the time when you think you might need __slots__, you actually want to use lightweight\\n
      or flyweight design patterns. these are cases when you no longer want to use\\n
      purely python objects. instead, you want a python object-like wrapper around\\n
      an array, struct, or numpy array. class flyweight(object) def get(self, thedata,\\n
      index) return thedata[index] def set(self, thedata, index, value) thedata[index]=\\n
      value the class-like wrapper has no attributes \xE2\x80\x94 it just provides\\n
      methods that act on the underlying data. the methods can be reduced to class\\n
      methods. indeed, it could be reduced to just functions operating on the underlying\\n
      array of data. "\n
    - each python object has a __dict__ atttribute which is a dictionary containing\n
      all other attributes. e.g. when you type self.attr python is actually doing self.__dict__[''attr''].\n
      as you can imagine using a dictionary to store attribute takes some extra space\n
      &amp; time for accessing it. however, when you use __slots__, any object created\n
      for that class won''t have a __dict__ attribute. instead, all attribute access\n
      is done directly via pointers. so if want a c style structure rather than a full\n
      fledged class you can use __slots__ for compacting size of the objects &amp; reducing\n
      attribute access time. a good example is a point class containing attributes x\n
      &amp; y. if you are going to have a lot of points, you can try using __slots__\n
      in order to conserve some memory.\n
    - not necessarily simpler, but a different way, if you are more familiar\n
      with the re family. import re, string s = "string. with. punctuation?" # sample\n
      string out = re.sub(''[%s]'' % re.escape(string.punctuation),''', s)\n
    - i usually use something like this  s = "string. with. punctuation?" #\n
      sample string  import string  for c in string.punctuation ... s= s.replace(c,"")\n
      ...  s'string with punctuation''\n
    - from an efficiency perspective, you''re not going to beat translate() -\n
      it''s performing raw string operations in c with a lookup table - there''s not\n
      much that will beat that but writing your own c code. if speed isn''t a worry,\n
      another option though is exclude = set(string.punctuation) s ='''.join(ch for\n
      ch in s if ch not in exclude) this is faster than s.replace with each char, but\n
      won''t perform as well as non-pure python approaches such as regexes or string.translate,\n
      as you can see from the below timings. for this type of problem, doing it at as\n
      low a level as possible pays off. timing code import re, string, timeit s = "string.\n
      with. punctuation" exclude = set(string.punctuation) table = string.maketrans("","")\n
      regex = re.compile(''[%s]'' % re.escape(string.punctuation)) def test_set(s)\n
      return'''.join(ch for ch in s if ch not in exclude) def test_re(s) # from vinko''s\n
      solution, with fix. return regex.sub('''', s) def test_trans(s) return s.translate(table,\n
      string.punctuation) def test_repl(s) # from s.lott''s solution for c in string.punctuation\n
      s=s.replace(c,"") return s print "sets ",timeit.timer(''f(s)'','from __main__\n
      import s,test_set as f'').timeit(1000000) print "regex ",timeit.timer(''f(s)'',\n
     'from __main__ import s,test_re as f'').timeit(1000000) print "translate ",timeit.timer(''f(s)'',\n
     'from __main__ import s,test_trans as f'').timeit(1000000) print "replace ",timeit.timer(''f(s)'',\n
     'from __main__ import s,test_repl as f'').timeit(1000000) this gives the following\n
      results sets  19.8566138744 regex  6.86155414581 translate  2.12455511093\n
      replace  28.4436721802\n
    - do search and replace using the regex functions, as seen here.. if you\n
      have to repeatedly perform the operation, you can keep a compiled copy of the\n
      regex pattern (your punctuation) around, which will speed things up a bit.\n
    - forgive my python illiteracy as i won''t be offering the solution in python.\n
      as i do not know what method python 2.6 uses to generate the permutations and\n
      eliben''s one looks like johnson-trotter permutation generation, you might look\n
      for article in wikipedia on permutations and their generation that looks quite\n
      like unrank function in paper by myrvold and ruskey. it would seem to me that\n
      this could be used in a generator in the same way as in other replies to lessen\n
      the memory requirement considerably. just remember that the permutations will\n
      not be in lexicographic order.\n
    - A_Body "just use the sys.getsizeof function defined in the sys module. sys.getsizeof(object[,\\n
      default]) return the size of an object in bytes. the object can be any type\\n
      of object. all built-in objects will return correct results, but this does not\\n
      have to hold true for third-party extensions as it is implementation specific.\\n
      the default argument allows to define a value which will be returned if the\\n
      object type does not provide means to retrieve the size and would cause a typeerror.\\n
      getsizeof calls the object\xE2\x80\x99s __sizeof__ method and adds an additional\\n
      garbage collector overhead if the object is managed by the garbage collector.\\n
      usage example, in python 3.0  import sys  x = 2  sys.getsizeof(x) 14  sys.getsizeof(sys.getsizeof)\\n
      32  sys.getsizeof('this') 38  sys.getsizeof('this also') 48 if you are in python\\n
     2.6 and don't have sys.getsizeof you can use this extensive module instead.\\n
      never used it though. "\n
    - this solution implements a generator, to avoid holding all the permutations\n
      on memory def permutations (orig_list) if not isinstance(orig_list, list) orig_list\n
      list(orig_list) yield orig_list if len(orig_list) == 1 return for n in sorted(orig_list)\n
      new_list = orig_list[] pos = new_list.index(n) del(new_list[pos]) new_list.insert(0,\n
      n) for resto in permutations(new_list[1]) if new_list[1] + resto  orig_list\n
      yield new_list[1] + resto\n
    - starting with python 2.6 (and if you''re on python 3) you have a standard-library\n
      tool for this itertools.permutations. if you''re using an older python (2.6)\n
      for some reason or are just curious to know how it works, here''s one nice approach,\n
      taken from def all_perms(elements) if len(elements) =1 yield elements else\n
      for perm in all_perms(elements[1]) for i in range(len(elements)) # nb elements[01]\n
      works in both string and list contexts yield perm[i] + elements[01] + perm[i]\n
      a couple of alternative approaches are listed in the documentation of itertools.permutations.\n
      here''s one def permutations(iterable, r=none) # permutations(''abcd'', 2) --\n
      ab ac ad ba bc bd ca cb cd da db dc # permutations(range(3)) -- 012 021 102 120\n
      201 210 pool = tuple(iterable) n = len(pool) r = n if r is none else r if r  n\n
      return indices = range(n) cycles = range(n, n-r, -1) yield tuple(pool[i] for i\n
      in indices[r]) while n for i in reversed(range(r)) cycles[i] -= 1 if cycles[i]\n
      == 0 indices[i] = indices[i+1] + indices[ii+1] cycles[i] = n - i else j =\n
      cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i]\n
      for i in indices[r]) break else return and another, based on itertools.product\n
      def permutations(iterable, r=none) pool = tuple(iterable) n = len(pool) r = n\n
      if r is none else r for indices in product(range(n), repeat=r) if len(set(indices))\n
      == r yield tuple(pool[i] for i in indices)\n
    - and in python 2.6 onwards import itertools itertools.permutations([1,2,3])\n
      (returned as a generator. use list(permutations(l)) to return as a list.)\n
    - the following code is an in-place permutation of a given list, implemented\n
      as a generator. since it only returns references to the list, the list should\n
      not be modified outside the generator. the solution is non-recursive, so uses\n
      low memory. work well also with multiple copies of elements in the input list.\n
      def permute_in_place(a) a.sort() yield list(a) if len(a) = 1 return first =\n
      0 last = len(a) while 1 i = last - 1 while 1 i = i - 1 if a[i]  a[i+1] j =\n
      last - 1 while not (a[i]  a[j]) j = j - 1 a[i], a[j] = a[j], a[i] # swap the\n
      values r = a[i+1last] r.reverse() a[i+1last] = r yield list(a) break if i ==\n
      first a.reverse() return if __name__ =='__main__'' for n in range(5) for\n
      a in permute_in_place(range(1, n+1)) print a print for a in permute_in_place([0,\n
      0, 1, 1, 1]) print a print\n
    - the following code with python 2.6 and above only first, import itertools\n
      import itertools permutation (order matters) print list(itertools.permutations([1,2,3,4],\n
      2)) [(1, 2), (1, 3), (1, 4), (2, 1), (2, 3), (2, 4), (3, 1), (3, 2), (3, 4), (4,\n
      1), (4, 2), (4, 3)] combination (order does not matter) print list(itertools.combinations(''123'',\n
      2)) [(''1'','2''), (''1'','3''), (''2'','3'')] cartesian product (with several\n
      iterables) print list(itertools.product([1,2,3], [4,5,6])) [(1, 4), (1, 5), (1,\n
      6), (2, 4), (2, 5), (2, 6), (3, 4), (3, 5), (3, 6)] cartesian product (with one\n
      iterable and itself) print list(itertools.product([1,2], repeat=3)) [(1, 1, 1),\n
      (1, 1, 2), (1, 2, 1), (1, 2, 2), (2, 1, 1), (2, 1, 2), (2, 2, 1), (2, 2, 2)]\n
    - this can be more complicated than it looks depending on how you want to\n
      count things. for instance, if you have a list of ints, do you want the size of\n
      the list containing the references to the ints? (ie. list only, not what is contained\n
      in it), or do you want to include the actual data pointed to, in which case you\n
      need to deal with duplicate references, and how to prevent double-counting when\n
      two objects contain references to the same object. you may want to take a look\n
      at one of the python memory profilers, such as pysizer to see if they meet your\n
      needs.\n
    - A_Body "first an answer. import sys try print sys.getsizeof(object) except attributeerror\\n
      print \"sys.getsizeof exists in python \xE2\x89\xA52.6\" discussion in python,\\n
      you cannot ever access \"direct\" memory addresses. why, then, would you need\\n
      or want to know how many such addresses are occupied by a given object?? it's\\n
      a question that's entirely inappropriate at that level of abstraction. when\\n
      you're painting your house, you don't ask what frequencies of light are absorbed\\n
      or reflected by each of the constituent atoms within the paint, you just ask\\n
      what color it is -- the details of the physical characteristics that create\\n
      that color are beside the point. similarly, the number of bytes of memory that\\n
      a given python object occupies is beside the point. so, why are you trying to\\n
      use python to write c code? ) "\n
    - A_Body "one of the official python documents contains details on extending python\\n
      using cc++. even without the use of swig, it\xE2\x80\x99s quite straightforward\\n
      and works perfectly well on windows. "\n
    - A_Body "the quickest way to do this is using swig. example from swig tutorial\\n
      * file  example.c * int fact(int n) { if (n = 1) return 1; else return n*fact(n-1);\\n
      } interface file * example.i * %module example %{ * put header files here\\n
      or function declarations like below * extern int fact(int n); %} extern int\\n
      fact(int n); building a python module on unix swig -python example.i gcc -fpic\\n
      c example.c example_wrap.c -iusrlocalincludepython2.7 gcc -shared example.o\\n
      example_wrap.o -o _example.so usage  import example  example.fact(5) 120 note\\n
      that you have to have python-dev. also in some systems python header files will\\n
      be in usrincludepython2.7 based on the way you have installed it. from the\\n
      tutorial swig is a fairly complete c++ compiler with support for nearly every\\n
      language feature. this includes preprocessing, pointers, classes, inheritance,\\n
      and even c++ templates. swig can also be used to package structures and classes\\n
      into proxy classes in the target language \xE2\x80\x94 exposing the underlying\\n
      functionality in a very natural manner. "\n
    - A_Body "i\xE2\x80\x99ve never used it but i\xE2\x80\x99ve heard good things about\\n
      ctypes. if you\xE2\x80\x99re trying to use it with c++, be sure to evade name\\n
      mangling via extern \"c\". thanks for the comment, florian b\xE3\xB6sch. "\n
    - you don''t need to use 4 spaces on your second conditional line. maybe\n
      use if (cond1 =='val1'' and cond2 =='val2'' and cond3 =='val3'' and cond4\n
      =='val4'') do_something also, don''t forget the whitespace is more flexible\n
      than you might think if ( cond1 =='val1'' and cond2 =='val2'' and cond3 ==\n
     'val3'' and cond4 =='val4'' ) do_something if (cond1 =='val1'' and cond2\n
      =='val2'' and cond3 =='val3'' and cond4 =='val4'') do_something both of\n
      those are fairly ugly though. maybe lose the brackets (the style guide discourages\n
      this though)? if cond1 =='val1'' and cond2 =='val2'' and \ cond3 =='val3''\n
      and cond4 =='val4'' do_something this at least gives you some differentiation.\n
      or even if cond1 =='val1'' and cond2 =='val2'' and \ cond3 =='val3'' and\n
      cond4 =='val4'' do_something i think i prefer if cond1 =='val1'' and \\n
      cond2 =='val2'' and \ cond3 =='val3'' and \ cond4 =='val4'' do_something\n
      here''s the style guide, which (since 2010) recommends using brackets.\n
    - this paper, claiming python to be all a scientist needs, basically says\n
      first prototype everything in python. then when you need to speed a part up, use\n
      swig and translate this part to c.\n
    - i prefer this style when i have a terribly large if-condition if ( expr1\n
      and (expr2 or expr3) and hasattr(thingy1,'__eq__'') or status=="happytimes"\n
      ) do_stuff() else do_other_stuff()\n
    - i suggest moving the and keyword to the second line and indenting all lines\n
      containing conditions with two spaces instead of four if (cond1 =='val1'' and\n
      cond2 =='val2'' and cond3 =='val3'' and cond4 =='val4'') do_something this\n
      is exactly how i solve this problem in my code. having a keyword as the first\n
      word in the line makes the condition a lot more readable, and reducing the number\n
      of spaces further distinguishes condition from action.\n
    - i''ve resorted to the following in the degenerate case where it''s simply\n
      and''s or or''s. if all( [cond1 =='val1'', cond2 =='val2'', cond3 =='val3'',\n
      cond4 =='val4''] ) if any( [cond1 =='val1'', cond2 =='val2'', cond3 ==\n
     'val3'', cond4 =='val4''] ) it shaves a few characters and makes it clear\n
      that there''s no subtlety to the condition.\n
    - "all" and "any" are nice for the many conditions of same type case. but\n
      they always evaluates all conditions. as shown in this example def c1() print\n
      " executed c1" return false def c2() print " executed c2" return false print\n
      "simple and (aborts early!)" if c1() and c2() pass print print "all (executes\n
      all ( )" if all((c1(),c2())) pass print\n
    - someone has to champion use of vertical whitespace here! ) if ( cond1\n
      == val1 and cond2 == val2 and cond3 == val3 ) do_stuff() this makes each condition\n
      clearly visible. it also allows cleaner expression of more complex conditions\n
      if ( cond1 == val1 or ( cond2_1 == val2_1 and cond2_2 = val2_2 and cond2_3 !=\n
      bad2_3 ) ) do_more_stuff() yes, we''re trading off a bit of vertical real estate\n
      for clarity. well worth it imo.\n
    - just a few other random ideas for completeness''s sake. if they work for\n
      you, use them. otherwise, you''re probably better off trying something else. you\n
      could also do this with a dictionary  x = {''cond1'' 'val1'','cond2'' \n
     'val2''}  y = {''cond1'' 'val1'','cond2'' 'val2''}  x == y true this\n
      option is more complicated, but you may also find it useful class klass(object)\n
      def __init__(self, some_vars) #initialize conditions here def __nonzero__(self)\n
      return (self.cond1 =='val1'' and self.cond2 =='val2'' and self.cond3 =='val3''\n
      and self.cond4 =='val4'') foo = klass() if foo print "foo is true!" else print\n
      "foo is false!" dunno if that works for you, but it''s another option to consider.\n
      here''s one more way class klass(object) def __init__(self) #initialize conditions\n
      here def __eq__(self) return (self.cond1 =='val1'' and self.cond2 =='val2''\n
      and self.cond3 =='val3'' and self.cond4 =='val4'') x = klass(some_values)\n
      y = klass(some_other_values) if x == y print'x == y'' else print'x!=y''\n
      the last two i haven''t tested, but the concepts should be enough to get you going\n
      if that''s what you want to go with. (and for the record, if this is just a one\n
      time thing, you''re probably just better off using the method you presented at\n
      first. if you''re doing the comparison in lots of places, these methods may enhance\n
      readability enough to make you not feel so bad about the fact that they are kind\n
      of hacky.)\n
    - what if we only insert an additional blank line between the condition and\n
      the body and do the rest in the canonical way? if (cond1 =='val1'' and cond2\n
      =='val2'' and cond3 =='val3'' and cond4 =='val4'') do_something p.s. i\n
      always use tabs, not spaces; i cannot fine-tune...\n
    - check out pyrex or cython. they''re python-like languages for interfacing\n
      between cc++ and python.\n
    - you should have a look at boost.python, here is the short introdution taken\n
      from their website the boost python library is a framework for interfacing python\n
      and c++. it allows you to quickly and seamlessly expose c++ classes functions\n
      and objects to python, and vice-versa, using no special tools -- just your c++\n
      compiler. it is designed to wrap c++ interfaces non-intrusively, so that you should\n
      not have to change the c++ code at all in order to wrap it, making boost.python\n
      ideal for exposing 3rd-party libraries to python. the library''s use of advanced\n
      metaprogramming techniques simplifies its syntax for users, so that wrapping code\n
      takes on the look of a kind of declarative interface definition language (idl).\n
    - this doesn''t improve so much but... allcondsareok = (cond1 =='val1''\n
      and cond2 =='val2'' and cond3 =='val3'' and cond4 =='val4'') if allcondsareok\n
      do_something\n
    - i like ctypes a lot, swig always tended to give me problems. also ctypes\n
      has the advantage that you don''t need to satisfy any compile time dependency\n
      on python, and your binding will work on any python that has ctypes, not just\n
      the one it was compiled against. suppose you have a simple c++ example class you\n
      want to talk to in a file called foo.cpp #include iostream class foo{ public\n
      void bar(){ stdcout  "hello"  stdendl; } }; since ctypes can only talk to\n
      c functions, you need to provide those declaring them as extern "c" extern "c"\n
      { foo* foo_new(){ return new foo(); } void foo_bar(foo* foo){ foo-bar(); } } next\n
      you have to compile this to a shared library g++ -c -fpic foo.cpp -o foo.o g++\n
      shared -wl,-soname,libfoo.so -o libfoo.so foo.o and finally you have to write\n
      your python wrapper (e.g. in foowrapper.py) from ctypes import cdll lib = cdll.loadlibrary(''.libfoo.so'')\n
      class foo(object) def __init__(self) self.obj = lib.foo_new() def bar(self)\n
      lib.foo_bar(self.obj) once you have that you can call it like f = foo() f.bar()\n
      #and you will see "hello" on the screen\n
    - the'is'' test will test for identity using the builtin'id()'' function\n
      which essentially returns the memory address of the object and therefore isn''t\n
      overloadable. however in the case of testing the equality of a class you probably\n
      want to be a little bit more strict about your tests and only compare the data\n
      attributes in your class import types class comparesnicely(object) def __eq__(self,\n
      other) for key, value in self.__dict__.iteritems() if (isinstance(value, types.functiontype)\n
      or key.startswith("__")) continue if key not in other.__dict__ return false\n
      if other.__dict__[key] != value return false return true this code will only\n
      compare non function data members of your class as well as skipping anything private\n
      which is generally what you want. in the case of plain old python objects i have\n
      a base class which implements __init__, __str__, __repr__ and __eq__ so my popo\n
      objects don''t carry the burden of all that extra (and in most cases identical)\n
      logic.\n
    - you need to be careful with inheritance  class foo def __eq__(self, other)\n
      if isinstance(other, self.__class__) return self.__dict__ == other.__dict__ else\n
      return false  class bar(foo)pass  b = bar()  f = foo()  f == b true  b == f false\n
      check types more strictly, like this def __eq__(self, other) if type(other)\n
      is type(self) return self.__dict__ == other.__dict__ return false besides that,\n
      your approach will work fine, that''s what special methods are there for.\n
    - the way you describe is the way i''ve always done it. since it''s totally\n
      generic, you can always break that functionality out into a mixin class and inherit\n
      it in classes where you want that functionality. class commonequalitymixin(object)\n
      def __eq__(self, other) return (isinstance(other, self.__class__) and self.__dict__\n
      == other.__dict__) def __ne__(self, other) return not self.__eq__(other) class\n
      foo(commonequalitymixin) def __init__(self, item) self.item = item\n
    - you don''t have to override both __eq__ and __ne__ you can override only\n
      __cmp__ but this will make an implication on the result of ==, !==,  , > and so\n
      on. is tests for object identity. this means a is b will be true in the case when\n
      a and b both hold the reference to the same object. in python you always hold\n
      a reference to an object in a variable not the actual object, so essentially for\n
      a is b to be true the objects in them should be located in the same memory location.\n
      how and most importantly why would you go about overriding this behaviour? edit\n
      i didn''t know __cmp__ was removed from python 3 so avoid it.\n
    - i think that the two terms you''re looking for are equality (==) and identity\n
      (is). for example  a = [1,2,3]  b = [1,2,3]  a == b true -- a and b have values\n
      which are equal  a is b false -- a and b are not the same list object\n
    - decorators are used for anything that you want to transparently "wrap"\n
      with additional functionality. django uses them for wrapping "login required"\n
      functionality on view functions, as well as for registering filter functions.\n
      you can use class decorators for adding named logs to classes. any sufficiently\n
      generic functionality that you can "tack on" to an existing class or function''s\n
      behavior is fair game for decoration. there''s also a discussion of use cases\n
      on the python-dev newsgroup pointed to by pep 318 -- decorators for functions\n
      and methods.\n
    - i use decorators mainly for timing purposes def time_dec(func) def wrapper(*arg)\n
      t = time.clock() res = func(*arg) print func.func_name, time.clock()-t return\n
      res return wrapper def myfunction(n) ...\n
    - i use them mainly for debugging (wrapper around a function that prints\n
      its arguments and result) and verification (e.g. to check if an argument is of\n
      correct type or, in the case of web application, if the user has sufficient privileges\n
      to call a particular method).\n
    - the twisted library uses decorators combined with generators to give the\n
      illusion that an asynchronous function is synchronous. for example def asyncf()\n
      dostuff() yield someasynchronouscall() dostuff() yield someasynchronouscall()\n
      dostuff() using this, code that would have been broken up into a ton of little\n
      callback functions can be written quite naturally as a single block, making it\n
      a lot easier to understand and maintain.\n
    - i''ve actually recently had one of those "a-ha!" moments, as you call them,\n
      and used a decorator to enable me to profile decorated functionsmethods only.\n
      it''s the profile_func decorator in this file, the output of which can be viewed\n
      in kcachegrind. very useful indeed.\n
    - decorators are used either to define a function''s properties or as boilerplate\n
      that alters it; it''s possible but counter-intuitive for them to return completely\n
      different functions. looking at the other responses here, it seems like one of\n
      the most common uses is to limit the scope of some other process - be it logging,\n
      profiling, security checks, etc. cherrypy uses object-dispatching to match urls\n
      to objects and, eventually, methods. decorators on those methods signal whether\n
      or not cherrypy is even allowed to use those methods. for example, adapted from\n
      the tutorial class helloworld ... def secret(self) return "you shouldn''t be\n
      here." .expose def index(self) return "hello world!" cherrypy.quickstart(helloworld())\n
    - for nosetests, you can write a decorator that supplies a unit test function\n
      or method with several sets of parameters ( (2, 4, 6), (5, 6, 11), ) def test_add(a,\n
      b, expected) assert a + b == expected\n
    - i''ve used them for synchronization. def synchronized(lock) """ synchronization\n
      decorator """ def wrap(f) def newfunction(*args, **kw) lock.acquire() try return\n
      f(*args, **kw) finally lock.release() return newfunction return wrap as pointed\n
      out in the comments, since python 2.5 you can use a with statement in conjunction\n
      with a threading.lock (or multiprocessing.lock since version 2.6) object to simplify\n
      the decorator''s implementation to just def synchronized(lock) """ synchronization\n
      decorator """ def wrap(f) def newfunction(*args, **kw) with lock return f(*args,\n
      **kw) return newfunction return wrap regardless, you then use it like this import\n
      threading lock = threading.lock() (lock) def do_something() # etc (lock) def\n
      do_something_else() # etc basically it just puts lock.acquire()  lock.release()\n
      on either side of the function call.\n
    - i use decorators for type checking parameters which are passed to my python\n
      methods via some rmi. so instead of repeating the same parameter counting, exception-raising\n
      mumbo-jumbo again and again def mymethod(id, name) if not (myistype(id,'uint'')\n
      and myistype(name,'utf8string'')) raise blablaexception() ... i just declare\n
      (uint, utf8string) def mymethod(id, name) ... and accepts() does all the work\n
      for me.\n
    - i used them recently, while working on social networking web application.\n
      for communitygroups, i was supposed to give membership authorization to create\n
      new discussion and reply to a message you have to be the member of that particular\n
      group. so, i wrote a decorator and put that where i required in my view.\n
    - in the beginning there was sh, sed, and awk (and find, and grep, and...).\n
      it was good. but awk can be an odd little beast and hard to remember if you don''t\n
      use it often. then the great camel created perl. perl was a system administrator''s\n
      dream. it was like shell scripting on steroids. text processing, including regular\n
      expressions were just part of the language. then it got ugly... people tried to\n
      make big applications with perl. now, don''t get me wrong, perl can be an application,\n
      but it can (can!) look like a mess if you''re not really careful. then there is\n
      all this flat data business. it''s enough to drive a programmer nuts. enter python,\n
      ruby, et al. these are really very good general purpose languages. they support\n
      text processing, and do it well (though perhaps not as tightly entwined in the\n
      basic core of the language). but they also scale up very well, and still have\n
      nice looking code at the end of the day. they also have developed pretty hefty\n
      communities with plenty of libraries for most anything. now, much of the negativeness\n
      towards perl is a matter of opinion, and certainly some people can write very\n
      clean perl, but with this many people complaining about it being too easy to create\n
      obfuscated code, you know some grain of truth is there. the question really becomes\n
      then, are you ever going to use this language for more than simple bash script\n
      replacements. if not, learn some more perl.. it is absolutely fantastic for that.\n
      if, on the other hand, you want a language that will grow with you as you want\n
      to do more, may i suggest python or ruby. either way, good luck!\n
    - any shell has several sets of features. the essential linuxunix commands.\n
      all of these are available through the subprocess library. this isn''t always\n
      the best first choice for doing all external commands. look also at shutil for\n
      some commands that are separate linux commands, but you could probably implement\n
      directly in your python scripts. another huge batch of linux commands are in the\n
      os library; you can do these more simply in python. and -- bonus! -- more quickly.\n
      each separate linux command in the shell (with a few exceptions) forks a subprocess.\n
      by using python shutil and os modules, you don''t fork a subprocess. the shell\n
      environment features. this includes stuff that sets a command''s environment (current\n
      directory and environment variables and what-not). you can easily manage this\n
      from python directly. the shell programming features. this is all the process\n
      status code checking, the various logic commands (if, while, for, etc.) the test\n
      command and all of it''s relatives. the function definition stuff. this is all\n
      much, much easier in python. this is one of the huge victories in getting rid\n
      of bash and doing it in python. interaction features. this includes command history\n
      and what-not. you don''t need this for writing shell scripts. this is only for\n
      human interaction, and not for script-writing. the shell file management features.\n
      this includes redirection and pipelines. this is trickier. much of this can be\n
      done with subprocess. but some things that are easy in the shell are unpleasant\n
      in python. specifically stuff like (a | b; c ) | something result. this runs two\n
      processes in parallel (with output of a as input to b), followed by a third process.\n
      the output from that sequence is run in parallel with something and the output\n
      is collected into a file named result. that''s just complex to express in any\n
      other language. specific programs (awk, sed, grep, etc.) can often be rewritten\n
      as python modules. don''t go overboard. replace what you need and evolve your\n
      "grep" module. don''t start out writing a python module that replaces "grep".\n
      the best thing is that you can do this in steps. replace awk and perl with python.\n
      leave everything else alone. look at replacing grep with python. this can be a\n
      bit more complex, but your version of grep can be tailored to your processing\n
      needs. look at replacing find with python loops that use os.walk. this is a big\n
      win because you don''t spawn as many processes. look at replacing common shell\n
      logic (loops, decisions, etc.) with python scripts.\n
    - adding to previous answers check the pexpect module for dealing with interactive\n
      commands (adduser, passwd etc.)\n
    - i have built semi-long shell scripts (300-500 lines) and python code which\n
      does similar functionality. when many external commands are being executed, i\n
      find the shell is easier to use. perl is also a good option when there is lots\n
      of text manipulation.\n
    - if your textfile manipulation usually is one-time, possibly done on the\n
      shell-prompt, you will not get anything better from python. on the other hand,\n
      if you usually have to do the same (or similar) task over and over, and you have\n
      to write your scripts for doing that, then python is great - and you can easily\n
      create your own libraries (you can do that with shell scripts too, but it''s more\n
      cumbersome). a very simple example to get a feeling. import popen2 stdout_text,\n
      stdin_text=popen2.popen2("your-shell-command-here") for line in stdout_text if\n
      line.startswith("#") pass else jobid=int(line.split(",")[0].split()[1].lstrip("").rstrip(""))\n
      # do something with jobid check also sys and getopt module, they are the first\n
      you will need.\n
    - python would be perfectly fine for text file manipulation. for learning,\n
      check here.\n
    -  if you want to use python as a shell, why not have a look at ipython ?\n
      it is also good to learn interactively the language. if you do a lot of text manipulation,\n
      and if you use vim as a text editor, you can also directly write plugins for vim\n
      in python. just type "help python" in vim and follow the instructions or have\n
      a look at this presentation. it is so easy and powerfull to write functions that\n
      you will use directly in your editor!\n
    - your best bet is a tool that is specifically geared towards your problem.\n
      if it''s processing text files, then sed, awk and perl are the top contenders.\n
      python is a general-purpose dynamic language. as with any general purpose language,\n
      there''s support for file-manipulation, but that isn''t what it''s core purpose\n
      is. i would consider python or ruby if i had a requirement for a dynamic language\n
      in particular. in short, learn sed and awk really well, plus all the other goodies\n
      that come with your flavour of *nix (all the bash built-ins, grep, tr and so forth).\n
      if it''s text file processing you''re interested in, you''re already using the\n
      right stuff.\n
    - i suggest the awesome online book dive into python. it''s how i learned\n
      the language originally. beyone teaching you the basic structure of the language,\n
      and a whole lot of useful data structures, it has a good chapter on file handling\n
      and subsequent chapters on regular expressions and more.\n
    - try adding a datetime.datetime to a datetime.timedelta. if you only want\n
      the time portion, you can call the time() method on the resultant datetime.datetime\n
      object to get it.\n
    - you can use full datetime variables with timedelta, and by providing a\n
      dummy date then using time to just get the time value. for example import datetime\n
      a = datetime.datetime(100,1,1,11,34,59) b = a + datetime.timedelta(0,3) # days,\n
      seconds, then other fields. print a.time() print b.time() results in the two values,\n
      three seconds apart 113459 113502 you could also opt for the more readable\n
      b = a + datetime.timedelta(seconds=3) if you''re so inclined. if you''re after\n
      a function that can do this, you can look into using addsecs below import datetime\n
      def addsecs(tm, secs) fulldate = datetime.datetime(100, 1, 1, tm.hour, tm.minute,\n
      tm.second) fulldate = fulldate + datetime.timedelta(seconds=secs) return fulldate.time()\n
      a = datetime.datetime.now().time() b = addsecs(a, 300) print a print b this outputs\n
      091155.775695 091655\n
    - one little thing, might add clarity to override the default value for seconds  b\n
      a + datetime.timedelta(seconds=3000)  b datetime.datetime(1, 1, 1, 12, 24, 59)\n
    - as others here have stated, you can just use full datetime objects throughout\n
      sometime = get_some_time() # the time to which you want to add 3 seconds later\n
      (datetime.combine(date.today(), sometime) + timedelta(seconds=3)).time() however,\n
      i think it''s worth explaining why full datetime objects are required. consider\n
      what would happen if i added 2 hours to 11pm. what''s the correct behavior? an\n
      exception, because you can''t have a time larger than 1159pm? should it wrap\n
      back around? different programmers will expect different things, so whichever\n
      result they picked would surprise a lot of people. worse yet, programmers would\n
      write code that worked just fine when they tested it initially, and then have\n
      it break later by doing something unexpected. this is very bad, which is why you''re\n
      not allowed to add timedelta objects to time objects.\n
    - thanks to pax diablo, and for the suggestion of using full datetimes throughout.\n
      if i have to accept datetime.time objects from an external source, then this seems\n
      to be an alternative add_secs_to_time() function def add_secs_to_time(timeval,\n
      secs_to_add) dummy_date = datetime.date(1, 1, 1) full_datetime = datetime.datetime.combine(dummy_date,\n
      timeval) added_datetime = full_datetime + datetime.timedelta(seconds=secs_to_add)\n
      return added_datetime.time() this verbose code can be compressed to this one-liner\n
      (datetime.datetime.combine(datetime.date(1, 1, 1), timeval) + datetime.timedelta(seconds=secs_to_add)).time()\n
      but i think i''d want to wrap that up in a function for code clarity anyway.\n
    - 80% of the time, when folks say "daemon", they only want a server. since\n
      the question is perfectly unclear on this point, it''s hard to say what the possible\n
      domain of answers could be. since a server is adequate, start there. if an actual\n
      "daemon" is actually needed (this is rare), read up on nohup as a way to daemonize\n
      a server. until such time as an actual daemon is actually required, just write\n
      a simple server. also look at the wsgi reference implementation. also look at\n
      the simple http server. "are there any additional things that need to be considered?\n
      " yes. about a million things. what protocol? how many requests? how long to service\n
      each request? how frequently will they arrive? will you use a dedicated process?\n
      threads? subprocesses? writing a daemon is a big job.\n
    - sander marechal''s code sample is superior to the original, which was originally\n
      posted in 2004. i once contributed a daemonizer for pyro, but would probably use\n
      sander''s code if i had to do it over.\n
    - the easiest way to create daemon with python is to use the twisted event-driven\n
      framework. it handles all of the stuff necessary for daemonization for you. it\n
      uses the reactor pattern to handle concurrent requests.\n
    - in order of appearance, the languages are sed, awk, perl, python. the sed\n
      program is a stream editor, and is designed to apply the actions from a script\n
      to each line (or, more generally, to specified ranges of lines) of the input file\n
      or files. its language is based on ed, the unix editor, and although it has conditionals\n
      and so on, it is hard to work with for complex tasks. you can work minor miracles\n
      with it - but at a cost to the hair on your head. however, it is probably the\n
      fastest of the programs when attempting tasks within its remit. (it has the least\n
      powerful regular expressions of the programs discussed - adequate for many purposes,\n
      but certainly not pcre - perl-compatible regular expressions) the awk program\n
      (name from the initials of its authors - aho, weinberger and kernighan) is a tool\n
      originally for formatting reports. it can be used as a souped up sed; in its more\n
      recent versions, it is computationally complete. it uses an interesting idea -\n
      the program is based on'patterns matched'' and'actions taken when the pattern\n
      matches''. the patterns are fairly powerful (extended regular expressions). the\n
      language for the actions is similar to c. one of the key features of awk is that\n
      it splits the input lines into fields automatically. perl was written in part\n
      as an awk-killer and sed-killer. two of the programs provided with it are a2p\n
      and s2p for converting awk scripts and sed scripts into perl. perl is one of the\n
      earliest of the next generation of scripting languages (tcltk can probably claim\n
      primacy). it has powerful integrated regular expression handling with a vastly\n
      more powerful language. it provides access to almost all system calls, and has\n
      the extensibility of the cpan modules. (neither awk nor sed is extensible.) one\n
      of perl''s mottos is "tmtowtdi - there''s more than one way to do it" (pronounced\n
      "tim-toady"). perl has'objects'', but it is more of an add-on than a fundamental\n
      part of the language. python was written last, and probably in part as a reaction\n
      to perl. it has some interesting syntactic ideas (indenting to indicate levels\n
       no braces or equivalents). it is more fundamentally object-oriented than perl;\n
      it is just as extensible as perl. ok - when to use each? sed - when you need to\n
      do simple text transforms on files. awk - when you only need simple formatting\n
      and summarization or transformation of data. perl - for almost any task, but especially\n
      when the task needs complex regular expressions. python - for the same tasks that\n
      you could use perl for. i''m not aware of anything that perl can do that python\n
      can''t, nor vice versa. the choice between the two would depend on other factors.\n
      i learned perl before there was a python, so i tend to use it. python has less\n
      accreted syntax and is generally somewhat simpler to learn. perl 6, when it becomes\n
      available, will be a fascinating development. (note that the'overviews'' of\n
      perl and python, in particular, are woefully incomplete; whole books could be\n
      written on the topic.)\n
    - i wouldn''t call sed a fully-fledged programming language, it is a stream\n
      editor with language constructs aimed at editing text files programmatically.\n
      awk is a little more of a general purpose language but it is still best suited\n
      for text processing. perl and python are fully fledged, general purpose programming\n
      languages. perl has its roots in text processing and has a number of awk-like\n
      constructs (there is even an awk-to-perl script floating around on the net). there\n
      are many differences between perl and python, your best bet is probably to read\n
      the summaries of both languages on something like wikipedia to get a good grasp\n
      on what they are.\n
    - first, there are two unrelated things in the list "perl, python awk and\n
      sed". thing 1 - simplistic text manipulation tools. sed. it has a fixed, relatively\n
      simple scope of work defined by the idea of reading and examining each line of\n
      a file. sed is not designed to be particularly readable. it is designed to be\n
      very small and very efficient on very tiny unix servers. awk. it has a slightly\n
      less fixed, less simple scope of work. however, the main loop of an awk program\n
      is defined by the implicit reading of lines of a source file. these are not "complete"\n
      programming languages. while you can -- with some work -- write fairly sophisticated\n
      programs in awk, it rapidly gets complicated and difficult to read. thing 2 -\n
      general-purposes programming languages. these have a rich variety of statement\n
      types, numerous built-in data structures, and no wired-in assumptions or shortcuts\n
      to speak of. perl. python. when to use them. sed. never. it really doesn''t have\n
      any value in the modern era of computers with more than 32k of memory. perl or\n
      python do the same things more clearly. awk. never. like sed, it reflects an earlier\n
      era of computing. rather than maintain this language (in addition to all the other\n
      required for a successful system), it''s more pleasant to simply do everything\n
      in one pleasant language. perl. any programming problem of any kind. if you like\n
      free-thinking syntax, where there are many, many ways to do the same thing, perl\n
      is fun. python. any programming problem of any kind. if you like fairly limited\n
      syntax, where there are fewer choices, less subtlety, and (perhaps) more clarity.\n
      python''s object-oriented nature makes it more suitable for large, complex problems.\n
      background -- i''m not bashing sed and awk out of ignorance. i learned awk over\n
      20 years ago. did many things with it; used to teach it as a core unix skill.\n
      i learned perl about 15 years ago. did many sophisticated things with it. i''ve\n
      left both behind because i can do the same things in python -- and it is simpler\n
      and more clear. there are two serious problems with sed and awk, neither of which\n
      are their age. the incompleteness of their implementation. everything sed and\n
      awk do can be done in python or perl, often more simply and sometimes faster,\n
      too. a shell pipeline has some performance advantages because of its multi-processing.\n
      python offers a subprocess module to allow me to recover those advantages. the\n
      need to learn yet another language. by doing things in python (or perl) your implementation\n
      depends on fewer languages, with a resulting increase in clarity.\n
    - edit i''ve just read "windows", this is for linux users, sorry. in bash\n
      #!binbash while [ "0" == "0" ]; do clear \n while [ "\ninput" == "" ]; do read\n
      p "do you want to quit? (yn) " -n 1 -e input if [ "\ninput" == "y" ]; then exit\n
      1 elif [ "\ninput" == "n" ]; then echo "ok, keep working ;)" fi done input="" done\n
      save it as "whatyouwant.sh", chmod +x it then run .whatyouwant.sh python or\n
      something other than python (idle, whatever). this will ask you if you actually\n
      want to exit, if not it rerun python (or the command you gave as parameter). this\n
      will clear all, the screen and all the variablesobjectanything you createdimported\n
      in python. in python just type exit() when you want to exit.\n
    - well, here''s a quick hack  clear = "\n" * 100  print clear  ...do some\n
      other stuff...  print clear or to save some typing, put this file in your python\n
      search path # wiper.py class wipe(object) def __repr__(self) return'\n''*1000\n
      wipe = wipe() then you can do this from the interpreter all you like )  from\n
      wiper import wipe  wipe  wipe  wipe\n
    - use idle. it has many handy features. ctrl+f6, for example, resets the\n
      console. closing and opening the console are good ways to clear it.\n
    - as you mentioned, you can do a system call  import os  clear = lambda\n
      os.system(''cls'')  clear() i am not sure of any other way in windows.\n
    - this will do the trick dir(module) however, if you find it annoying to\n
      read the returned list, just use the following loop to get one name per line.\n
      for i in dir(module) print i\n
    - once you''ve imported the module, you can just do help(modulename) ...\n
      to get the docs on all the functions at once, interactively. or you can use dir(modulename)\n
      ... to simply list the names of all the functions and variables defined in the\n
      module.\n
    - import types import yourmodule print [yourmodule.__dict__.get(a) for a\n
      in dir(yourmodule) if isinstance(yourmodule.__dict__.get(a), types.functiontype)]\n
    - the inspect module. also see the pydoc module, the help() function in the\n
      interactive interpreter and the pydoc command-line tool which generates the documentation\n
      you are after. you can just give them the class you wish to see the documentation\n
      of. they can also generate, for instance, html output and write it to disk.\n
    - you can use dir(module) to see all available methodsattributes. also check\n
      out pydocs.\n
    - you should check out pyflakes, pylint, and pychecker. i''ve personally\n
      used both pyflakes and pylint, and found them both to be very helpful for catching\n
      those little things you hate to mess up on. pylint generally requires a bit more\n
      configuration than pyflakes. also noteworthy eclipse''s pydev plugin comes in\n
      with a built in pylint output parser.\n
    - here are my first impressions of pyflakes, pychecker and pylint pychecker\n
      it crashes frequently, most of the runs i tried resulted in errors that originated\n
      in the pychecker code (eg attributeerror or indexerror list index out of range\n
      were the most common). for some reason i had to set the django_settings_module\n
      environment variable before it would even run on any of the app code, and the\n
      documentation is very sparse. pyflakes'pyflakes --help'' throws a typeerror\n
      - erm... documentation is also very sparse, and pyflakes is very forgiving (as\n
      far as i can tell, it only reports compile errors, warnings, redefinitions, and\n
      some concerns about imports--such as unused and wildcards). pyflakes also seems\n
      to repeat itself eventlistviews.py4'http404'' imported but unused eventlistviews.py4\n
     'http404'' imported but unused eventlistviews.py5'from eventlist.models\n
      import *'' used; unable to detect undefined names eventlistviews.py59'authenticate''\n
      imported but unused eventlistviews.py61 redefinition of unused'login'' from\n
      line 59 eventlistviews.py5'from eventlist.models import *'' used; unable\n
      to detect undefined names eventlistviews.py4'http404'' imported but unused\n
      pylint this seems to be the most capable of the tools suggested. it has the best\n
      documentation. logilab provides a tutorial, pylint has a help screen, and there\n
      is a (broken) link to a user manual, which would be extremely helpful. there are\n
      some issues with applying pylint to django, since pylint doesn''t know about the\n
      django classes (such as models.model). this means that a fair number of otherwise\n
      valuable errors are generated about missing class fields. eg e105get_events_by_tag\n
      class'tag'' has no'objects'' member parsing these out automatically will be\n
      very difficult without some additional knowledge of the classes in use. i''m not\n
      sure adding that is feasible, but it does seem likely that pylint is capable of\n
      dealing with this in the "right" way. (i probably just need to point it to the\n
      django source, but there are no command line params that look likely, and, as\n
      mentioned earlier, the user manual is inaccessible.) for the moment, i''m still\n
      looking into pylint -- pychecker and pyflakes need better documentation and they\n
      need to become more robust.\n
    - there''s pylint pychecker pyflakes and probably others, too.\n
    - pylint is the best such tool i''ve found. due to python''s nature it''s\n
      difficult to statically analyze it, but it will catch undefined variables, basic\n
      type errors, unused code, etc. you''ll want to tweak the configuration file, as\n
      by default it outputs many warnings i consider useless or harmful. here''s part\n
      of my .pylintrc dealing with warning silencing [messages control] # brain-dead\n
      errors regarding standard language features # w0142 = *args and **kwargs support\n
      # w0403 = relative imports # pointless whinging # r0201 = method could be a function\n
      # w0212 = accessing protected attribute of client class # w0613 = unused argument\n
      # w0232 = class has no __init__ method # r0903 = too few public methods # c0301\n
      line too long # r0913 = too many arguments # c0103 = invalid name # r0914 =\n
      too many local variables # pylint''s module importation is unreliable # f0401\n
      unable to import module # w0402 = uses of a deprecated module # already an error\n
      when wildcard imports are used # w0614 = unused import from wildcard # sometimes\n
      disabled depending on how bad a module is # c0111 = missing docstring # disable\n
      the message(s) with the given id(s). disable=w0142,w0403,r0201,w0212,w0613,w0232,r0903,w0614,c0111,c0301,r0913,c0103,f0401,w0402,r0914\n
    - i echo the other answers and would just add that pychecker is the quickest\n
      and easiest to use and pylint the most comprehensive and configurable. i also\n
      use epydoc a fair bit and this is good for pointing out problems with your docstrings.\n
    - for the complete list of attributes, the short answer is no. the problem\n
      is that the attributes are actually defined as the arguments accepted by the getattr\n
      built-in function. as the user can reimplement __getattr__, suddenly allowing\n
      any kind of attribute, there is no possible generic way to generate that list.\n
      the dir function returns the keys in the __dict__ attribute, i.e. all the attributes\n
      accessible if the __getattr__ method is not reimplemented. for the second question,\n
      it does not really make sense. actually, methods are callable attributes, nothing\n
      more. you could though filter callable attributes, and, using the inspect module\n
      determine the class methods, methods or functions.\n
    - that is why the new __dir__() method has been added in python 2.6 see\n
      (scroll down a little bit)\n
    - how wsgi, cgi, and the frameworks are all connected ? apache listens on\n
      port 80. it gets an http request. it parses the request to find a way to respond.\n
      apache has a lot of choices for responding. one way to respond is to use cgi to\n
      run a script. another way to respond is to simply serve a file. in the case of\n
      cgi, apache prepares an environment and invokes the script through the cgi protocol.\n
      this is a standard unix forkexec situation -- the cgi subprocess inherits an\n
      os environment including the socket and stdout. the cgi subprocess writes a response,\n
      which goes back to apache; apache sends this response to the browser. cgi is primitive\n
      and annoying. mostly because it forks a subprocess for every request, and subprocess\n
      must exit or close stdout and stderr to signify end of response. wsgi is an interface\n
      that is based on the cgi design pattern. it is not necessarily cgi -- it does\n
      not have to fork a subprocess for each request. it can be cgi, but it doesn''t\n
      have to be. wsgi adds to the cgi design pattern in several important ways. it\n
      parses the http request headers for you and adds these to the environment. it\n
      supplies any post-oriented input as a file-like object in the environment. it\n
      also provides you a function that will formulate the response, saving you from\n
      a lot of formatting details. what do i need to know  install  do if i want to\n
      run a web framework (say web.py or cherrypy) on my basic cgi configuration ? recall\n
      that forking a subprocess is expensive. there are two ways to work around this.\n
      embedded mod_wsgi or mod_python embeds python inside apache; no process is forked.\n
      apache runs the django application directly. daemon mod_wsgi or mod_fastcgi allows\n
      apache to interact with a separate daemon (or "long-running process"), using the\n
      wsgi protocol. you start your long-running django process, then you configure\n
      apache''s mod_fastcgi to communicate with this process. note that mod_wsgi can\n
      work in either mode embedded or daemon. when you read up on mod_fastcgi, you''ll\n
      see that django uses flup to create a wsgi-compatible interface from the information\n
      provided by mod_fastcgi. the pipeline works like this. apache - mod_fastcgi -\n
      flup (via fastcgi protocol) - django (via wsgi protocol) django has several "django.core.handlers"\n
      for the various interfaces. for mod_fastcgi, django provides a manage.py runfcgi\n
      that integrates flup and the handler. for mod_wsgi, there''s a core handler for\n
      this. how to install wsgi support ? follow these instructions. for background\n
      see this\n
    - you can run wsgi over cgi as pep333 demonstrates as an example. however\n
      every time there is a request a new python interpreter is started and the whole\n
      context (database connections, etc.) needs to be build which all take time. the\n
      best if you want to run wsgi would be if your host would install mod_wsgi and\n
      made an appropriate configuration to defer control to an application of yours.\n
      flup is another way to run with wsgi for any webserver that can speak fcgi, scgi\n
      or ajp. from my experience only fcgi really works, and it can be used in apache\n
      either via mod_fastcgi or if you can run a separate python daemon with mod_proxy_fcgi.\n
      wsgi is a protocol much like cgi, which defines a set of rules how webserver and\n
      python code can interact, it is defined as pep333. it makes it possible that many\n
      different webservers can use many different frameworks and applications using\n
      the same application protocol. this is very beneficial and makes it so useful.\n
    - it''s a simple abstraction layer for python, akin to what the servlet spec\n
      is for java. whereas cgi is really low level and just dumps stuff into the process\n
      environment and standard inout, the above two specs model the http request and\n
      response as constructs in the language. my impression however is that in python\n
      folks have not quite settled on de-facto implementations so you have a mix of\n
      reference implementations, and other utility-type libraries that provide other\n
      things along with wsgi support (e.g. paste). of course i could be wrong, i''m\n
      a newcomer to python. the "web scripting" community is coming at the problem from\n
      a different direction (shared hosting, cgi legacy, privilege separation concerns)\n
      than java folks had the luxury of starting with (running a single enterprise container\n
      in a dedicated environment against statically compiled and deployed code).\n
    - i think florian''s answer answers the part of your question about "what\n
      is wsgi", especially if you read the pep. as for the questions you pose towards\n
      the end wsgi, cgi, fastcgi etc. are all protocols for a web server to run code,\n
      and deliver the dynamic content that is produced. compare this to static web serving,\n
      where a plain html file is basically delivered as is to the client. cgi, fastcgi\n
      and scgi are language agnostic. you can write cgi scripts in perl, python, c,\n
      bash, whatever. cgi defines which executable will be called, based on the url,\n
      and how it will be called the arguments and environment. it also defines how\n
      the return value should be passed back to the web server once your executable\n
      is finished. the variations are basically optimisations to be able to handle more\n
      requests, reduce latency and so on; the basic concept is the same. wsgi is python\n
      only. rather than a language agnostic protocol, a standard function signature\n
      is defined def simple_app(environ, start_response) """simplest possible application\n
      object""" status ='200 ok'' response_headers = [(''content-type'',''textplain'')]\n
      start_response(status, response_headers) return [''hello world!\n''] that is a\n
      complete (if limited) wsgi application. a web server with wsgi support (such as\n
      apache with mod_wsgi) can invoke this function whenever a request arrives. the\n
      reason this is so great is that we can avoid the messy step of converting from\n
      a http getpost to cgi to python, and back again on the way out. it''s a much\n
      more direct, clean and efficient linkage. it also makes it much easier to have\n
      long-running frameworks running behind web servers, if all that needs to be done\n
      for a request is a function call. with plain cgi, you''d have to start your whole\n
      framework up for each individual request. to have wsgi support, you''ll need to\n
      have installed a wsgi module (like mod_wsgi), or use a web server with wsgi baked\n
      in (like cherrypy). if neither of those are possible, you could use the cgi-wsgi\n
      bridge given in the pep.\n
    - for what it''s worth, if you''re using numpy distutils, numpy.distutils.misc_util.configuration\n
      has a make_svn_version_py() method that embeds the revision number inside package.__svn_version__\n
      in the variable version .\n
    - there doesn''t seem to be a standard way to embed a version string in a\n
      python package. most packages i''ve seen use some variant of your solution, i.e.\n
      eitner embed the version in setup.py and have setup.py generate a module (e.g.\n
      version.py) containing only version info, that''s imported by your package, or\n
      the reverse put the version info in your package itself, and import that to set\n
      the version in setup.py\n
    - not directly an answer to your question, but you should consider naming\n
      it __version__, not version. this is almost a quasi-standard. many modules in\n
      the standard library use __version__, and this is also used in lots of 3rd-party\n
      modules, so it''s the quasi-standard. usually, __version__ is a string, but sometimes\n
      it''s also a float or tuple. edit as mentioned by s.lott (thank you!), pep 8\n
      says it explicitly version bookkeeping if you have to have subversion, cvs, or\n
      rcs crud in your source file, do it as follows. __version__ = "\nrevision 63990\n
      \n" # \nsource\n these lines should be included after the module''s docstring, before\n
      any other code, separated by a blank line above and below. you should also make\n
      sure that the version number conforms to the format described in pep 440 (pep\n
      386 a previous version of this standard).\n
    - also worth noting is that as well as __version__ being a semi-std. in python\n
      so is __version_info__ which is a tuple, in the simple cases you can just do something\n
      like __version__ ='1.2.3'' __version_info__ = tuple([ int(num) for num in __version__.split(''.'')])\n
      ...and you can get the __version__ string from a file, or whatever.\n
    - you should always use open(). as the documentation states when opening\n
      a file, it''s preferable to use open() instead of invoking this constructor directly.\n
      file is more suited to type testing (for example, writing "isinstance(f, file)").\n
      also, file() has been removed since python 3.0.\n
    - file() is a type, like an int or a list. open() is a function for opening\n
      files, and will return a file object. this is an example of when you should use\n
      open f = open(filename,'r'') for line in f process(line) f.close() this is\n
      an example of when you should use file class loggingfile(file) def write(self,\n
      data) sys.stderr.write("wrote %d bytes\n" % len(data)) super(loggingfile, self).write(data)\n
      as you can see, there''s a good reason for both to exist, and a clear use-case\n
      for both.\n
    - functionally, the two are the same; open will call file anyway, so currently\n
      the difference is a matter of style. the python docs recommend using open. when\n
      opening a file, it''s preferable to use open() instead of invoking the file constructor\n
      directly. the reason is that in future versions they is not guaranteed to be the\n
      same (open will become a factory function, which returns objects of different\n
      types depending on the path it''s opening).\n
    - two reasons the python philosophy of "there ought to be one way to do\n
      it" and file is going away. file is the actual type (using e.g. file(''myfile.txt'')\n
      is calling its constructor). open is a factory function that will return a file\n
      object. in python 3.0 file is going to move from being a built-in to being implemented\n
      by multiple classes in the io library (somewhat similar to java with buffered\n
      readers, etc.)\n
    - A_Body "only ever use open() for opening files. file() is actually being removed\\n
      in 3.0, and it's deprecated at the moment. they've had a sort of strange relationship,\\n
      but file() is going now, so there's no need to worry anymore. the following\\n
      is from the python 2.6 docs. [bracket stuff] added by me. when opening a file,\\n
      it\xE2\x80\x99s preferable to use open() instead of invoking this [file()] constructor\\n
      directly. file is more suited to type testing (for example, writing isinstance(f,\\n
      file) "\n
    - according to mr van rossum, although open() is currently an alias for file()\n
      you should use open() because this might change in the future.\n
    - you''d use it in your own class, since no builtin class makes use of it.\n
      numpy uses it, as stated in the documentation. some examples here. in your own\n
      class, you''d use it like this  class testellipsis(object) ... def __getitem__(self,\n
      item) ... if item is ellipsis ... return "returning all items" ... else ...\n
      return "return %r items" % item ...  x = testellipsis()  print x[2] return 2 items  print\n
      x[...] returning all items of course, there is the python documentation, and language\n
      reference. but those aren''t very helpful.\n
    - the ellipsis is used to slice higher-dimensional data structures. it''s\n
      designed to mean at this point, insert as many full slices () to extend the multi-dimensional\n
      slice to all dimensions. example  from numpy import arange  a = arange(16).reshape(2,2,2,2)\n
      now, you have a 4-dimensional matrix of order 2x2x2x2. to select all first elements\n
      in the 4th dimension, you can use the ellipsis notation  a[..., 0].flatten() array([\n
      0, 2, 4, 6, 8, 10, 12, 14]) which is equivalent to  a[,,,0].flatten() array([\n
      0, 2, 4, 6, 8, 10, 12, 14]) in your own implementations, you''re free to ignore\n
      the contract mentioned above and use it for whatever you see fit.\n
    - A_Body "this is another use for ellipsis, which has nothing to do with slices\\n
      i often use it in intra-thread communication with queues, as a mark that signals\\n
      \"done\"; it's there, it's an object, it's a singleton, and its name means \"\\n
      lack of\", and it's not the overused none (which could be put in a queue as part\\n
      of normal data flow). ymmv. p.s i don't mind downvotes, when what i say in\\n
      an answer is not useful in relation to the question; then i try to improve my\\n
      answer. but i sure can't understand how one can downvote any of the answers\\n
      in this question\xE2\x80\x94 when the question is \xE2\x80\x9Chow do you use\\n
      the ellipsis in python\xE2\x80\x9D\xE2\x80\xA6 it seems that people think that\\n
      downvoting means \xE2\x80\x9Ci disagree\xE2\x80\x9D or \xE2\x80\x9Ci don't like\\n
      this\xE2\x80\x9D. "\n
    - a simpler way to think about it, perhaps when main returns, your process\n
      will not exit if there are non-daemon threads still running. a bit of advice\n
      clean shutdown is easy to get wrong when threads and synchronization are involved\n
       if you can avoid it, do so. use daemon threads whenever possible.\n
    - let''s say you''re making some kind of dashboard widget. as part of this,\n
      you want it to display the unread message count in your email box. so you make\n
      a little thread that will connect to the mail server and ask how many unread\n
      messages you have. signal the gui with the updated count. sleep for a little while.\n
      when your widget starts up, it would create this thread, designate it a daemon,\n
      and start it. because it''s a daemon, you don''t have to think about it; when\n
      your widget exits, the thread will stop automatically.\n
    - some threads do background tasks, like sending keepalive packets, or performing\n
      periodic garbage collection, or whatever. these are only useful when the main\n
      program is running, and it''s okay to kill them off once the other, non-daemon,\n
      threads have exited. without daemon threads, you''d have to keep track of them,\n
      and tell them to exit, before your program can completely quit. by setting them\n
      as daemon threads, you can let them run and forget about them, and when your program\n
      quits, any daemon threads are killed automatically.\n
    - they are stored in the cgi fieldstorage object. import cgi form = cgi.fieldstorage()\n
      print "the user entered %s" % form.getvalue("uservalue")\n
    - python is only a language, to get get and post data, you need a web framework\n
      or toolkit written in python. django is one, as charlie points out, the cgi and\n
      urllib standard modules are others. also available are turbogears, pylons, cherrypy,\n
      web.py, mod_python, fastcgi, etc, etc. in django, your view functions receive\n
      a request argument which has request.get and request.post. other frameworks will\n
      do it differently.\n
    - it somewhat depends on what you use as a cgi framework, but they are available\n
      in dictionaries accessible to the program. i''d point you to the docs, but i''m\n
      not getting through to python.org right now. but this note on mail.python.org\n
      will give you a first pointer. look at the cgi and urllib python libs for more.\n
      update okay, that link busted. here''s the basic wsgi ref\n
    - suppose you''re posting a html form with this input type="text" name="username"\n
      if using raw cgi import cgi form = cgi.fieldstorage() print form["username"]\n
      if using django, pylons, flask or pyramid print request.get[''username''] # for\n
      get form method print request.post[''username''] # for post form method using\n
      turbogears, cherrypy from cherrypy import request print request.params[''username'']\n
      web.py form = web.input() print form.username werkzeug print request.form[''username'']\n
      if using cherrypy or turbogears, you can also define your handler function taking\n
      a parameter directly def index(self, username) print username google app engine\n
      class somehandler(webapp2.requesthandler) def post(self) name = self.request.get(''username'')\n
      # this will get the value from the field named username self.response.write(name)\n
      # this will write on the document so you really will have to choose one of those\n
      frameworks.\n
    - you should also consider the array module in the standard library if all\n
      the items in your list or tuple are of the same type. it can be faster and take\n
      less memory.\n
    - tuples should be slightly more efficient and because of that, faster, than\n
      lists because they are immutable.\n
    - in general, you might expect tuples to be slightly faster. however you\n
      should definitely test your specific case (if the difference might impact the\n
      performance of your program -- remember "premature optimization is the root of\n
      all evil"). python makes this very easy timeit is your friend. \n python -m timeit\n
      "x=(1,2,3,4,5,6,7,8)" 10000000 loops, best of 3 0.0388 usec per loop \n python\n
      m timeit "x=[1,2,3,4,5,6,7,8]" 1000000 loops, best of 3 0.363 usec per loop\n
      and... \n python -m timeit -s "x=(1,2,3,4,5,6,7,8)" "y=x[3]" 10000000 loops, best\n
      of 3 0.0938 usec per loop \n python -m timeit -s "x=[1,2,3,4,5,6,7,8]" "y=x[3]"\n
      10000000 loops, best of 3 0.0649 usec per loop so in this case, instantiation\n
      is almost an order of magnitude faster for the tuple, but item access is actually\n
      somewhat faster for the list! so if you''re creating a few tuples and accessing\n
      them many many times, it may actually be faster to use lists instead. of course\n
      if you want to change an item, the list will definitely be faster since you''d\n
      need to create an entire new tuple to change one item of it (since tuples are\n
      immutable).\n
    - the dis module disassembles the byte code for a function and is useful\n
      to see the difference between tuples and lists. in this case, you can see that\n
      accessing an element generates identical code, but that assigning a tuple is much\n
      faster than assigning a list.  def a() ... x=[1,2,3,4,5] ... y=x[2] ...  def\n
      b() ... x=(1,2,3,4,5) ... y=x[2] ...  import dis  dis.dis(a) 2 0 load_const 1\n
      (1) 3 load_const 2 (2) 6 load_const 3 (3) 9 load_const 4 (4) 12 load_const 5 (5)\n
      15 build_list 5 18 store_fast 0 (x) 3 21 load_fast 0 (x) 24 load_const 2 (2) 27\n
      binary_subscr 28 store_fast 1 (y) 31 load_const 0 (none) 34 return_value  dis.dis(b)\n
      2 0 load_const 6 ((1, 2, 3, 4, 5)) 3 store_fast 0 (x) 3 6 load_fast 0 (x) 9 load_const\n
      2 (2) 12 binary_subscr 13 store_fast 1 (y) 16 load_const 0 (none) 19 return_value\n
    - tuples, being immutable, are more memory efficient; lists, for efficiency,\n
      overallocate memory in order to allow appends without constant reallocs. so, if\n
      you want to iterate through a constant sequence of values in your code (eg for\n
      direction in'up'','right'','down'','left''), tuples are preferred, since\n
      such tuples are pre-calculated in compile time. access speeds should be the same\n
      (they are both stored as contiguous arrays in the memory). but, alist.append(item)\n
      is much preferred to atuple+= (item,) when you deal with mutable data. remember,\n
      tuples are intended to be treated as records without field names.\n
    - you didn''t state what web server you were using, but apache has a nice\n
      little module called mime magic which it uses to determine the type of a file\n
      when told to do so. it reads some of the file''s content and tries to figure out\n
      what type it is based on the characters found. and as dave webb mentioned the\n
      mimetypes module under python will work, provided an extension is handy. alternatively,\n
      if you are sitting on a unix box you can use sys.popen(''file -i' + filename,\n
      mode=''r'') to grab the mime type. windows should have an equivalent command,\n
      but i''m unsure as to what it is.\n
    - the mimetypes module in the standard library will determineguess the mime\n
      type from a file extension. if users are uploading files the http post will contain\n
      the mime type of the file alongside the data. for example, django makes this data\n
      available as an attribute of the uploadedfile object.\n
    - it is, in principle, impossible to determine the encoding of a text file,\n
      in the general case. so no, there is no standard python library to do that for\n
      you. if you have more specific knowledge about the text file (e.g. that it is\n
      xml), there might be library functions.\n
    - if you know the some content of the file you can try to decode it with\n
      several encoding and see which is missing. in general there is no way since a\n
      text file is a text file and those are stupid ;)\n
    - A_Body "correctly detecting the encoding all times is impossible. (from chardet\\n
      faq) however, some encodings are optimized for specific languages, and languages\\n
      are not random. some character sequences pop up all the time, while other sequences\\n
      make no sense. a person fluent in english who opens a newspaper and finds \xE2\\n
      \x80\x9Ctxzqjv 2!dasd0a qqdkjvz\xE2\x80\x9D will instantly recognize that that\\n
      isn't english (even though it is composed entirely of english letters). by studying\\n
      lots of \xE2\x80\x9Ctypical\xE2\x80\x9D text, a computer algorithm can simulate\\n
      this kind of fluency and make an educated guess about a text's language. there\\n
      is the chardet library that uses that study to try to detect encoding. chardet\\n
      is a port of the auto-detection code in mozilla. you can also use unicodedammit.\\n
      it will try the following methods an encoding discovered in the document itself\\n
      for instance, in an xml declaration or (for html documents) an http-equiv meta\\n
      tag. if beautiful soup finds this kind of encoding within the document, it parses\\n
      the document again from the beginning and gives the new encoding a try. the\\n
      only exception is if you explicitly specified an encoding, and that encoding\\n
      actually worked then it will ignore any encoding it finds in the document.\\n
      an encoding sniffed by looking at the first few bytes of the file. if an encoding\\n
      is detected at this stage, it will be one of the utf-* encodings, ebcdic, or\\n
      ascii. an encoding sniffed by the chardet library, if you have it installed.\\n
      utf-8 windows-1252 "\n
    -  x = "2342.34"  float(x) 2342.3400000000001 there you go. use float (which\n
      is almost always a c double).\n
    - if you''re interested in the technical details, one article in beautiful\n
      code deals with the internals of python''s dict implementation.\n
    - yes, it is a hash mapping or hash table. you can read a description of\n
      python''s dict implementation, as written by tim peters, here. that''s why you\n
      can''t use something'not hashable'' as a dict key, like a list  a = {}  b =\n
      [''some'','list'']  hash(b) traceback (most recent call last) file "stdin",\n
      line 1, in module typeerror list objects are unhashable  a[b] ='some'' traceback\n
      (most recent call last) file "stdin", line 1, in module typeerror list objects\n
      are unhashable you can read more about hash tables or check how it has been implemented\n
      in python and why it is implemented that way.\n
    - yes. internally it is implemented as open hashing based on a primitive\n
      polynomial over z2 (source).\n
    - to expand upon nosklo''s explanation a = {} b = [''some'','list''] a[b]\n
      ='some'' # this won''t work a[tuple(b)] ='some'' # this will, same as a[''some'',\n
     'list'']\n
    - underscore.  5+5 10  _ 10  _ + 5 15  _ 15\n
    - just for the record, ipython takes this one step further and you can access\n
      every result with _ and its numeric value in [1] 10 out[1] 10 in [2] 32 out[2]\n
      32 in [3] _ out[3] 32 in [4] _1 out[4] 10 in [5] _2 out[5] 32 in [6] _1\n
      + _2 out[6] 42 in [7] _6 out[7] 42 and it is possible to edit ranges of lines\n
      with the %ed macro too in [1] def foo() ... print "bar" ... ... in [2]\n
      foo() bar in [3] %ed 1-2\n
    - beyond performance considerations, there is a significant semantic difference.\n
      in the class attribute case, there is just one object referred to. in the instance-attribute-set-at-instantiation,\n
      there can be multiple objects referred to. for instance  class a foo = []  a,\n
      b = a(), a()  a.foo.append(5)  b.foo [5]  class a ... def __init__(self) self.foo\n
      []  a, b = a(), a()  a.foo.append(5)  b.foo []\n
    - just an elaboration on what alex coventry said, another alex (martelli)\n
      addressed a similar question on the comp.lang.python newsgroup years back. he\n
      examines the semantic difference of what a person intended vs. what he got (by\n
      using instance variables).\n
    - the difference is that the attribute on the class is shared by all instances.\n
      the attribute on an instance is unique to that instance. if coming from c++, attributes\n
      on the class are more like static member variables.\n
    - i''m not an expert on perl, but what i do know is that gmail supports imap\n
      and pop3, 2 protocols that are completely standard and allow you to do just that.\n
      maybe that helps you to get started.\n
    - within gmail, you can filter on "hasattachment", use it to identify the\n
      messages you should be getting when testing. note this appears to give both messages\n
      with attached files (paperclip icon shown), as well as inline attached images\n
      (no paperclip shown). there is no gmail api, so imap or pop are your only real\n
      options. the javamail api may be of some assistance as well as this very terse\n
      article on downloading attachments from imap using perl. some previous questions\n
      here on so may also help. this php example may help too. unfortunately from what\n
      i can see, there is no attachment information contained within the imap_header,\n
      so downloading the body is required to be able to see the x-attachment-id field.\n
      (someone please prove me wrong).\n
    - since gmail supports the standard protocols pop and imap, any platform,\n
      tool, application, component, or api that provides the client side of either protocol\n
      should work. i suggest doing a google search for your favorite languageplatform\n
      (e.g., "python"), plus "pop", plus "imap", plus perhaps "open source", plus perhaps\n
      "download" or "review", and see what you get for options. there are numerous free\n
      applications and components, pick a few that seem worthy, check for reviews, then\n
      download and enjoy.\n
    - you should be aware of the fact that you need ssl to connect to gmail (both\n
      for pop3 and imap - this is of course true also for their smtp-servers apart from\n
      port 25 but that''s another story).\n
    - the interior call to getpermutations -- it''s a generator, too. def getpermutations(string,\n
      prefix="") if len(string) == 1 yield prefix + string else for i in range(len(string))\n
      getpermutations(string[i]+string[i+1], prefix+string[i]) # ----- you need to\n
      iterate through that with a for-loop (see posting, which edged me out by seconds!)\n
    - this avoids the len(string)-deep recursion, and is in general a nice way\n
      to handle generators-inside-generators from types import generatortype def flatten(*stack)\n
      stack = list(stack) while stack try x = stack[0].next() except stopiteration\n
      stack.pop(0) continue if isinstance(x, generatortype) stack.insert(0, x) else\n
      yield x def _getpermutations(string, prefix="") if len(string) == 1 yield prefix\n
      + string else yield (_getpermutations(string[i]+string[i+1], prefix+string[i])\n
      for i in range(len(string))) def getpermutations(string) return flatten(_getpermutations(string))\n
      for permutation in getpermutations("abcd") print permutation flatten allows us\n
      to continue progress in another generator by simply yielding it, instead of iterating\n
      through it and yielding each item manually. python 3.3 will add yield from to\n
      the syntax, which allows for natural delegation to a sub-generator def getpermutations(string,\n
      prefix="") if len(string) == 1 yield prefix + string else for i in range(len(string))\n
      yield from getpermutations(string[i]+string[i+1], prefix+string[i])\n
    - def getpermutations(string, prefix="") if len(string) == 1 yield prefix\n
      + string else for i in xrange(len(string)) for perm in getpermutations(string[i]\n
      + string[i+1], prefix+string[i]) yield perm or without an accumulator def getpermutations(string)\n
      if len(string) == 1 yield string else for i in xrange(len(string)) for perm\n
      in getpermutations(string[i] + string[i+1]) yield string[i] + perm\n
    - use {{ request.user.get_profile.whatever }}. django''s templating language\n
      automatically calls things that are callable - in this case, the .get_profile()\n
      method.\n
    - yes it is possible to access profile from template using request.user.get_profile\n
      however there is a small caveat not all users will have profiles, which was in\n
      my case with admin users. so calling directly {{ request.user.get_profile.whatever\n
      }} from the template will cause an error in such cases. if you are sure all your\n
      users always have profiles it is safe to call from template, otherwise call get_profile()\n
      from within try-except block in your view and pass it to the template.\n
    - formatting works correctly even without having to round "%.1f" % n\n
    - below is a basic threading sample. it will spawn 20 threads; each thread\n
      will output its thread number. run it and observe the order in which they print.\n
      import threading class foo (threading.thread) def __init__(self,x) self.__x\n
      x threading.thread.__init__(self) def run (self) print str(self.__x) for x\n
      in xrange(20) foo(x).start() as you have hinted at python threads are implemented\n
      through time-slicing. this is how they get the "parallel" effect. in my example\n
      my foo class extends thread, i then implement the run method, which is where the\n
      code that you would like to run in a thread goes. to start the thread you call\n
      start() on the thread object, which will automatically invoke the run method...\n
      of course, this is just the very basics. you will eventually want to learn about\n
      semaphores, mutexes, and locks for thread synchronization and message passing.\n
    - floating point math is vulnerable to slight, but annoying, precision inaccuracies.\n
      if you can work with integer or fixed point, you will be guaranteed precision.\n
    - round(5.59, 1) is working fine. the problem is that 5.6 cannot be represented\n
      exactly in binary floating point.  5.6 5.5999999999999996  as vinko says, you\n
      can use string formatting to do rounding for display. python has a module for\n
      decimal arithmetic if you need that.\n
    - you get'5.6'' if you do str(round(n, 1)) instead of just round(n, 1).\n
    - you can use the string format operator %, similar to sprintf. mystring\n
      "%.2f" % 5.5999\n
    - A_Body "yes, because of the global interpreter lock (gil) there can only run one\\n
      thread at a time. here are some links with some insights about this from the\\n
      last link an interesting quote let me explain what all that means. threads\\n
      run inside the same virtual machine, and hence run on the same physical machine.\\n
      processes can run on the same physical machine or in another physical machine.\\n
      if you architect your application around threads, you\xE2\x80\x99ve done nothing\\n
      to access multiple machines. so, you can scale to as many cores are on the single\\n
      machine (which will be quite a few over time), but to really reach web scales,\\n
      you\xE2\x80\x99ll need to solve the multiple machine problem anyway. if you\\n
      want to use multi core, pyprocessing defines an process based api to do real\\n
      parallelization. the pep also includes some interesting benchmarks. "\n
    - python''s a fairly easy language to thread in, but there are caveats. the\n
      biggest thing you need to know about is the global interpreter lock. this allows\n
      only one thread to access the interpreter. this means two things 1) you rarely\n
      ever find yourself using a lock statement in python and 2) if you want to take\n
      advantage of multi-processor systems, you have to use separate processes. edit\n
      i should also point out that you can put some of the code in cc++ if you want\n
      to get around the gil as well. thus, you need to re-consider why you want to use\n
      threads. if you want to parallelize your app to take advantage of dual-core architecture,\n
      you need to consider breaking your app up into multiple processes. if you want\n
      to improve responsiveness, you should consider using threads. there are other\n
      alternatives though, namely microthreading. there are also some frameworks that\n
      you should look into stackless python greenlets gevent monocle\n
    - printf the sucker. print'%.1f'' % 5.59 # returns 5.6\n
    - use threads in python if the individual workers are doing io bound operations.\n
      if you are trying to scale across multiple cores on a machine either find a good\n
      ipc framework for python or pick a different language.\n
    - you can switch the data type to a integer  n = 5.59  int(n * 10)  10.0\n
      5.5  int(n * 10 + 0.5) 56 and then display the number by inserting the locale''s\n
      decimal separator. however, jimmy''s answer is better.\n
    - what about round(n,1)+epsilon\n
    - can''t help the way it''s stored, but at least formatting works correctly\n
     '%.1f'' % round(n, 1) # gives you'5.6''\n
    - the documentation says that there only one context variable, form. if you''re\n
      having trouble with login (which is common), the documentation says there are\n
      three context variables form a form object representing the login form. see\n
      the forms documentation for more on form objects. next the url to redirect to\n
      after successful login. this may contain a query string, too. site_name the name\n
      of the current site, according to the site_id setting.\n
    - you just need to wrap the existing functions and pass in the template you\n
      want. for example from django.contrib.auth.views import password_reset def my_password_reset(request,\n
      template_name=''pathtomytemplate'') return password_reset(request, template_name)\n
      to see this just have a look at the function declartion of the built in views\n
    - if you take a look at the sources for django.contrib.auth.views.password_reset\n
      you''ll see that it uses requestcontext. the upshot is, you can use context processors\n
      to modify the context which may allow you to inject the information that you need.\n
      the b-list has a good introduction to context processors. edit (i seem to have\n
      been confused about what the actual question was) you''ll notice that password_reset\n
      takes a named parameter called template_name def password_reset(request, is_admin_site=false,\n
      template_name=''registrationpassword_reset_form.html'', email_template_name=''registrationpassword_reset_email.html'',\n
      password_reset_form=passwordresetform, token_generator=default_token_generator,\n
      post_reset_redirect=none) check password_reset for more information. ... thus,\n
      with a urls.py like from django.conf.urls.defaults import * from django.contrib.auth.views\n
      import password_reset urlpatterns = patterns('''', (r''^accountspasswordreset\n'',\n
      password_reset, {''template_name'''my_templatespassword_reset.html''}), ...\n
      ) django.contrib.auth.views.password_reset will be called for urls matching'accountspasswordreset''\n
      with the keyword argument template_name ='my_templatespassword_reset.html''.\n
      otherwise, you don''t need to provide any context as the password_reset view takes\n
      care of itself. if you want to see what context you have available, you can trigger\n
      a templatesyntax error and look through the stack trace find the frame with a\n
      local variable named context. if you want to modify the context then what i said\n
      above about context processors is probably the way to go. in summary what do\n
      you need to do to use your own template? provide a template_name keyword argument\n
      to the view when it is called. you can supply keyword arguments to views by including\n
      a dictionary as the third member of a url pattern tuple.\n
    - you already found reply to similar question in another thread, so for completeness\n
      sake see how to achieve the same on windows uning named mutex.\n
    - simple, cross-platform solution, found in another question by zgoda import\n
      fcntl, sys pid_file ='program.pid'' fp = open(pid_file,'w'') try fcntl.lockf(fp,\n
      fcntl.lock_ex | fcntl.lock_nb) except ioerror # another instance is running sys.exit(0)\n
      a lot like s.lott''s suggestion, but with the code.\n
    - use a pid file. you have some known location, "pathtopidfile" and at\n
      startup you do something like this (partially pseudocode because i''m pre-coffee\n
      and don''t want to work all that hard) import os, os.path pidfilepath = """pathtopidfile"""\n
      if os.path.exists(pidfilepath) pidfile = open(pidfilepath,"r") pidstring = pidfile.read()\n
      if pidstring is equal to os.getpid() # something is real weird sys.exit(badcode)\n
      else use ps or pidof to see if the process with pid pidstring is still running\n
      if process with pid =='pidstring'' is still running sys.exit(alreadayrunning)\n
      else # the previous server must have crashed log server had crashed reopen pidfilepath\n
      for writing pidfile.write(os.getpid()) else open pidfilepath for writing pidfile.write(os.getpid())\n
      so, in other words, you''re checking if a pidfile exists; if not, write your pid\n
      to that file. if the pidfile does exist, then check to see if the pid is the pid\n
      of a running process; if so, then you''ve got another live process running, so\n
      just shut down. if not, then the previous process crashed, so log it, and then\n
      write your own pid to the file in place of the old one. then continue.\n
    - using a lock-file is a quite common approach on unix. if it crashes, you\n
      have to clean up manually. you could stor the pid in the file, and on startup\n
      check if there is a process with this pid, overriding the lock-file if not. (however,\n
      you also need a lock around the read-file-check-pid-rewrite-file). you will find\n
      what you need for getting and checking pid in the os-package. the common way of\n
      checking if there exists a process with a given pid, is to send it a non-fatal\n
      signal. other alternatives could be combining this with flock or posix semaphores.\n
      opening a network socket, as saua proposed, would probably be the easiest and\n
      most portable.\n
    - this may work. attempt create a pid file to a known location. if you fail,\n
      someone has the file locked, you''re done. when you finish normally, close and\n
      remove the pid file, so someone else can overwrite it. you can wrap your program\n
      in a shell script that removes the pid file even if your program crashes. you\n
      can, also, use the pid file to kill the program if it hangs.\n
    - i don''t know if it''s pythonic enough, but in the java world listening\n
      on a defined port is a pretty widely used solution, as it works on all major platforms\n
      and doesn''t have any problems with crashing programs. another advantage of listening\n
      to a port is that you could send a command to the running instance. for example\n
      when the users starts the program a second time, you could send the running instance\n
      a command to tell it to open another window (that''s what firefox does, for example.\n
      i don''t know if they use tcp ports or named pipes or something like that,'though).\n
    - a little nicer than inspecting the code object directly and working out\n
      the variables is to use the inspect module.  import inspect  def func(a,b,c=42,\n
      *args, **kwargs) pass  inspect.getargspec(func) ([''a'','b'','c''],'args'',\n
     'kwargs'', (42,)) if you want to know if its callable with a particular set of\n
      args, you need the args without a default already specified. these can be got\n
      by def getrequiredargs(func) args, varargs, varkw, defaults = inspect.getargspec(func)\n
      if defaults args = args[-len(defaults)] return args # *args and **kwargs are\n
      not required, so ignore them. then a function to tell what you are missing from\n
      your particular dict is def missingargs(func, argdict) return set(getrequiredargs(func)).difference(argdict)\n
      similarly, to check for invalid args, use def invalidargs(func, argdict) args,\n
      varargs, varkw, defaults = inspect.getargspec(func) if varkw return set() # all\n
      accepted return set(argdict) - set(args) and so a full test if it is callable\n
      is  def iscallablewithargs(func, argdict) return not missingargs(func, argdict)\n
      and not invalidargs(func, argdict) (this is good only as far as python''s arg\n
      parsing. any runtime checks for invalid values in kwargs obviously can''t be detected.)\n
    - this will print names of all passable arguments, keyword and non-keyword\n
      ones def func(one, two="value") y = one, two return y print func.func_code.co_varnames[func.func_code.co_argcount]\n
      this is because first co_varnames are always parameters (next are local variables,\n
      like y in the example above). so now you could have a function def getvalidargs(func,\n
      argsdict)'''''return dictionary without invalid function arguments.'''''' validargs\n
      func.func_code.co_varnames[func.func_code.co_argcount] return dict((key, value)\n
      for key, value in argsdict.iteritems() if key in validargs) which you then could\n
      use like this  func(**getvalidargs(func, args)) edit a small addition if you\n
      really need only keyword arguments of a function, you can use the func_defaults\n
      attribute to extract them def getvalidkwargs(func, argsdict) validargs = func.func_code.co_varnames[func.func_code.co_argcount]\n
      kwargslen = len(func.func_defaults) # number of keyword arguments validkwargs\n
      validargs[-kwargslen] # because kwargs are last return dict((key, value) for\n
      key, value in argsdict.iteritems() if key in validkwargs) you could now call your\n
      function with known args, but extracted kwargs, e.g. func(param1, param2, **getvalidkwargs(func,\n
      kwargsdict)) this assumes that func uses no *args or **kwargs magic in its signature.\n
    - in python 3.0  import inspect  import fileinput  print(inspect.getfullargspec(fileinput.input))\n
      fullargspec(args=[''files'','inplace'','backup'','bufsize'','mode'','openhook''],\n
      varargs=none, varkw=none, defaults=(none, 0,''', 0,'r'', none), kwonlyargs=[],\n
      kwdefaults=none, annotations={})\n
    - extending dzinx''s answer argnames = example.func_code.co_varnames[func.func_code.co_argcount]\n
      args = dict((key, val) for key,val in d_args.iteritems() if key in argnames) example(**args)\n
    - it''s probably best to use the python image library to do this which i''m\n
      afraid is a separate download. the easiest way to do what you want is via the\n
      load() method on the image object which returns a pixel access object which you\n
      can manipulate like an array from pil import image im = image.open("dead_parrot.jpg")\n
      #can be many different formats. pix = im.load() print im.size #get the width and\n
      hight of the image for iterating over print pix[x,y] #get the rgba value of the\n
      a pixel of an image pix[x,y] = value # set the rgba value of the image (tuple)\n
      alternatively, look at imagedraw which gives a much richer api for creating images.\n
    - there''s a really good article on wiki.wxpython.org entitled working with\n
      images. the article mentions the possiblity of using wxwidgets (wximage), pil\n
      or pythonmagick. personally, i''ve used pil and wxwidgets and both make image\n
      manipulation fairly easy.\n
    - pypng - lightweight png decoderencoder although the question hints at\n
      jpg, i hope my answer will be useful to some people. here''s how to read and write\n
      png pixels using pypng module import png, array point = (2, 10) # coordinates\n
      of pixel to be painted red reader = png.reader(filename=''image.png'') w, h, pixels,\n
      metadata = reader.read_flat() pixel_byte_width = 4 if metadata[''alpha''] else\n
      3 pixel_position = point[0] + point[1] * w new_pixel_value = (255, 0, 0, 0) if\n
      metadata[''alpha''] else (255, 0, 0) pixels[ pixel_position * pixel_byte_width\n
     (pixel_position + 1) * pixel_byte_width] = array.array(''b'', new_pixel_value)\n
      output = open(''image-with-red-dot.png'','wb'') writer = png.writer(w, h, **metadata)\n
      writer.write_array(output, pixels) output.close() pypng is a single pure python\n
      module less than 4000 lines long, including tests and comments. pil is a more\n
      comprehensive imaging library, but it''s also significantly heavier.\n
    - image manipulation is a complex topic, and it''s best if you do use a library.\n
      i can recommend gdmodule which provides easy access to many different image formats\n
      from within python.\n
    - a lot of times some quick task comes up that isn''t part of the main software\n
      you are developing. sometimes the task is one off ie compare this file to the\n
      database and let me know the differences. it is a lot easier to do text parsing\n
      in perlrubypython than it is in java or c# (partially because it is a lot easier\n
      to use regular expressions). it will probably take a lot less time to parse the\n
      text file using perlrubypython (or maybe even vbscript cringe and then load\n
      it into the database than it would to create a javac# program to do it or to\n
      do it by hand. also, due to the ease at which most of the dynamic languages parse\n
      text, they are great for code generation. sure your final project must be in c#javatransact\n
      sql but instead of cutting and pasting 100 times, finding errors, and cutting\n
      and pasting another 100 times it is often (but not always) easier just to use\n
      a code generator. a recent example at work is we needed to get data from one accounting\n
      system into our accounting system. the system has an import format, but the old\n
      system had a completely different format (fixed width although some things had\n
      to be matched). the task is not to create a program to migrate the data over and\n
      over again. it is to shove the data into our system and then maintain it there\n
      going forward. so even though we are a c# and sql server shop, i used python to\n
      convert the data into the format that could be imported by our application. ultimately\n
      it doesn''t matter that i used python, it matters that the data is in the system.\n
      my boss was pretty impressed. where i often see the dynamic languages used for\n
      is testing. it is much easier to create a pythonperlruby program to link to\n
      a web service and throw some data against it than it is to create the equivalent\n
      java program. you can also use python to hit against command line programs, generate\n
      a ton of garbage (but still valid) test data, etc.. quite easily. the other thing\n
      that dynamic languages are big on is code generation. creating the c#c++java\n
      code. some examples follow the first code generation task i often see is people\n
      using dynamic languages to maintain constants in the system. instead of hand coding\n
      a bunch of enums, a dynamic language can be used to fairly easily parse a text\n
      file and create the javac# code with the enums. sql is a whole other ball game\n
      but often you get better performance by cut and pasting 100 times instead of trying\n
      to do a function (due to caching of execution plans or putting complicated logic\n
      in a function causing you to go row by row instead of in a set). in fact it is\n
      quite useful to use the table definition to create certain stored procedures automatically.\n
      it is always better to get buy in for a code generator. but even if you don''t,\n
      is it more fun to spend time cuttingpasting or is it more fun to create a perlpythonruby\n
      script once and then have that generate the code? if it takes you hours to hand\n
      code something but less time to create a code generator, then even if you use\n
      it once you have saved time and hence money. if it takes you longer to create\n
      a code generator than it takes to hand code once but you know you will have to\n
      update the code more than once, it may still make sense. if it takes you 2 hours\n
      to hand code, 4 hours to do the generator but you know you''ll have to hand code\n
      equivalent work another 5 or 6 times than it is obviously better to create the\n
      generator. also some things are easier with dynamic languages than javac#cc++.\n
      in particular regular expressions come to mind. if you start using regular expressions\n
      in perl and realize their value, you may suddenly start making use of the java\n
      regular expression library if you haven''t before. if you have then there may\n
      be something else. i will leave you with one last example of a task that would\n
      have been great for a dynamic language. my work mate had to take a directory full\n
      of files and burn them to various cd''s for various customers. there were a few\n
      customers but a lot of files and you had to look in them to see what they were.\n
      he did this task by hand....a javac# program would have saved time, but for one\n
      time and with all the development overhead it isn''t worth it. however slapping\n
      something together in perlpythonruby probably would have been worth it. he spent\n
      several hours doing it. it would have taken less than one to create the python\n
      script to inspect each file, match which customer it goes to, and then move the\n
      file to the appropriate place.....again, not part of the standard job. but the\n
      task came up as a one off. is it better to do it yourself, spend the larger amount\n
      of time to make javac# do the task, or spend a much smaller amount of time doing\n
      it in pythonperlruby. if you are using c or c++ the point is even more dramatic\n
      due to the extra concerns of programming in c or c++ (pointers, no array bounds\n
      checking, etc.).\n
    - learning something with a flexible oop system, like lisp or perl (see moose),\n
      will allow you to better expand and understand your thoughts on software engineering.\n
      ideally, every language has some unique facet (whether it be clos or some other\n
      technique) that enhances, extends and grows your abilities as a programmer.\n
    - if all you have is a hammer, every problem begins to look like a nail.\n
      there are times when having a screwdriver or pair of pliers makes a complicated\n
      problem trivial. nobody asks contractors, carpenters, etc, "why learn to use a\n
      screwdriver if i already have a hammer?". really good contractorscarpenters have\n
      tons of tools and know how to use them well. all programmers should be doing the\n
      same thing, learning to use new tools and use them well. but before we use any\n
      power tools, lets take a moment to talk about shop safety. be sure to read, understand,\n
      and follow all the safety rules that come with your power tools. doing so will\n
      greatly reduce the risk of personal injury. and remember this there is no more\n
      important rule than to wear these safety glasses -- norm\n
    - do you expect to work for this company forever? if you''re ever out on\n
      the job market, pehaps some prospective employers will be aware of the python\n
      paradox.\n
    - dynamic languages are fantastic for prototyping ideas. often for performance\n
      reasons they won''t work for permanent solutions or products. but, with languages\n
      like python, which allow you to embed standard cc++java inside them or visa\n
      versa, you can speed up the really critical bits but leave it glued together with\n
      the flexibility of a dynamic language. ...and so you get the best of both worlds.\n
      if you need to justify this in terms of why more people should learn these languages,\n
      just point out much faster you can develop the same software and how much more\n
      robust the solution is (because debuggingfixing problems in dynamic languages\n
      is in my experience, considerably easier!).\n
    - knowing grep and ruby made it possible to narrow down a problem, and verify\n
      the fix for, an issue involving tons of java exceptions on some production servers.\n
      because i threw the solution together in ruby, it was done (designed, implemented,\n
      tested, run, bug-fixed, re-run, enhanced, results analyzed) in an afternoon instead\n
      of a couple of days. i could have solved the same problem using an all-java solution\n
      or a c# solution, but it most likely would have taken me longer. having dynamic\n
      language expertise also sometimes leads you to simpler solutions in less dynamic\n
      languages. in ruby, perl or python, you just intuitively reach for associative\n
      arrays (hashes, dictionaries, whatever word you want to use) for the smallest\n
      things, where you might be tempted to create a complex class hierarchy in a statically\n
      typed language when the problem doesn''t necessarily demand it. plus you can plug\n
      in most scripting languages into most runtimes. so it doesn''t have to be eitheror.\n
    - let me turn your question on its head by asking what use it is to an american\n
      english speaker to learn another language? the languages we speak (and those we\n
      program in) inform the way we think. this can happen on a fundamental level, such\n
      as c++ versus javascript versus lisp, or on an implementation level, in which\n
      a ruby construct provides a eureka moment for a solution in your "real job." speaking\n
      of your real job, if the market goes south and your employer decides to "right\n
      size" you, how do you think you''ll stack up against a guy who is flexible because\n
      he''s written software in tens of languages, instead of your limited exposure?\n
      all things being equal, i think the answer is clear. finally, you program for\n
      a living because you love programming... right?\n
    - often, dynamc languages (especially python and lua) are embedded in programs\n
      to add a more plugin-like functionality and because they are high-level languages\n
      that make it easy to add certain behavior, where a lowmid-level language is not\n
      needed. lua specificially lacks all the low-level system calls because it was\n
      designed for easeof-use to add functionality within the program, not as a general\n
      programming language.\n
    - i have often found that learning another language, especially a dynamically\n
      typed language, can teach you things about other languages and make you an overall\n
      better programmer. learning ruby, for example, will teach you object oriented\n
      programming in ways java wont, and vice versa. all in all, i believe that it is\n
      better to be a well rounded programmer than stuck in a single language. it makes\n
      you more valuable to the companiesclients you work for.\n
    - philosophical issues aside, i know that i have gotten value from writing\n
      quick-and-dirty ruby scripts to solve brute-force problems that java was just\n
      too big for. last year i had three separate directory structures that were all\n
      more-or-less the same, but with lots of differences among the files (the client\n
      hadn''t heard of version control and i''ll leave the rest to your imagination).\n
      it would have taken a great deal of overhead to write an analyzer in java, but\n
      in ruby i had one working in about 40 minutes.\n
    - you should also consider learning a functional programming language like\n
      scala. it has many of the advantages of ruby, including a concise syntax, and\n
      powerful features like closures. but it compiles to java class files and and integrate\n
      seamlessly into a java stack, which may make it much easier for your employer\n
      to swallow. scala isn''t dynamically typed, but its "implicit conversion" feature\n
      gives many, perhaps even all of the benefits of dynamic typing, while retaining\n
      many of the advantages of static typing.\n
    - one big reason to learn perl or ruby is to help you automate any complicated\n
      tasks that you have to do over and over. or if you have to analyse contents of\n
      log files and you need more mungeing than available using grep, sed, etc. also\n
      using other languages, e.g. ruby, that don''t have much "setup cost" will let\n
      you quickly prototype ideas before implementing them in c++, java, etc. hth cheers,\n
      rob\n
    - personally i work on a java app, but i couldn''t get by without perl for\n
      some supporting scripts. i''ve got scripts to quickly flip what db i''m pointing\n
      at, scripts to run build scripts, scripts to scrape data &amp; compare stuff.\n
      sure i could do all that with java, or maybe shell scripts (i''ve got some of\n
      those too), but who wants to compile a class (making sure the classpath is set\n
      right etc) when you just need something quick and dirty. knowing a scripting language\n
      can remove 90% of those boringrepetitive manual tasks.\n
    - they''re useful for the "quick hack" that is for plugging a gap in your\n
      main language for a quick (and potentially dirty) fix faster than it would take\n
      to develop the same in your main language. an example a simple script in perl\n
      to go through a large text file and replace all instances of an email address\n
      with another is trivial with an amount of time taken in the 10 minute range. hacking\n
      a console app together to do the same in your main language would take multiples\n
      of that. you also have the benefit that exposing yourself to additional languages\n
      broadens your abilities and learning to attack problems from a different languages\n
      perspective can be as valuable as the language itself. finally, scripting languages\n
      are very useful in the realm of extension. take lua as an example. you can bolt\n
      a lua interpreter into your app with very little overhead and you now have a way\n
      to create rich scripting functionality that can be exposed to end users or altered\n
      and distributed quickly without requiring a rebuild of the entire app. this is\n
      used to great effect in many games most notably world of warcraft.\n
    - when i first learned python, i worked for a java shop. occasionally i''d\n
      have to do serious text-processing tasks which were much easier to do with quick\n
      python scripts than java programs. for example, if i had to parse a complex csv\n
      file and figure out which of its rows corresponded to rows in our oracle database,\n
      this was much easier to do with python than java. more than that, i found that\n
      learning python made me a much better java programmer; having learned many of\n
      the same concepts in another language i feel that i understand those concepts\n
      much better. and as for what makes python easier than java, you might check out\n
      this question\n
    - it''s all about broadening your horizons as a developer. if you limit yourself\n
      to only strong-typed languages, you may not end up the best programmer you could.\n
      as for tasks, pythonluarubyperl are great for small simple tasks, like finding\n
      some files and renaming them. they also work great when paired with a framework\n
      (e.g. rails, django, lua for windows) for developing simple apps quickly. hell,\n
      37signals is based on creating simple yet very useful apps in ruby on rails.\n
    - check out the answers to this thead learning new languages is about keeping\n
      an open mind and learning new ways of doing things.\n
    - learning a new language is a long-term process. in a couple of days you''ll\n
      learn the basics, yes. but! as you probably know, the real practical applicability\n
      of any language is tied to the standard library and other available components.\n
      learning how to use the efficiently requires a lot of hands-on experience. perhaps\n
      the only immediate short-term benefit is that developers learn to distinguish\n
      the nails that need a pythonperlruby -hammer. and, if they are any good, they\n
      can then study some more (online, perhaps!) and become real experts. the long-term\n
      benefits are easier to imagine the employee becomes a better developer. better\n
      developer => better quality. we are living in a knowledge economy these days.\n
      it''s wiser to invest in those brains that already work for you. it is easier\n
      to adapt when the next big language emerges. it is very likely that the nbl will\n
      have many of the features present in today''s scripting languages first-class\n
      functions, closures, streamsgenerators, etc. new market possibilities and ability\n
      to respond more quickly. even if you are not writing python, other people are.\n
      your clients? another vendor in the project? perhaps a critical component was\n
      written in some other language? it will cost money and time, if you do not have\n
      people who can understand the code and interface with it. recruitment. if your\n
      company has a reputation of teaching new and interesting stuff to people, it will\n
      be easier to recruit the top people. everyone is doing javac#c++. it is not\n
      a very effective way to differentiate yourself in the job market.\n
    - edit i wrote this before reading the update to the original question.\n
      see my other answer for a better answer to the updated question. i will leave\n
      this as is as a warning against being the fastest gun in the west =) over a decade\n
      ago, when i was learning the ways of the computer, the old wise men with beards\n
      explained how c and c++ are the tools of the industry. no one used pascal and\n
      only the foolhardy would risk their companies with assembler. and of course, no\n
      one would even mention the awful slow ugly thing called java. it will not be a\n
      tool for serious business. so. um. replace the languages in the above story and\n
      perhaps you can predict the future. perhaps you can''t. point is, java will not\n
      be the last programming language ever and also you will most likely switch employers\n
      as well. the future is charging at you 24 hours per day. be prepared. learning\n
      new languages is good for you. also, in some cases it can give you bragging rights\n
      for a long time. my first university course was in scheme. so when people talk\n
      to me about the new language du jour, my response is something like "first-class\n
      functions? that''s so last century." and of course, you get more stuff done with\n
      a high-level language.\n
    - testing. it''s often quicker and easier to test your c#java application\n
      by using a dynamic language. you can do exploratory testing at the interactive\n
      prompt and quickly create automated test scripts.\n
    - i primarily program in java and c# but use dynamic languages (rubyperl)\n
      to support smoother deployment, kicking off os tasks, automated reporting, some\n
      log parsing, etc. after a short time learning and experimenting with ruby or perl\n
      you should be able to write some regex manipulating scripts that can alter data\n
      formats or grab information from logs. an example of a small rubyperl script\n
      that could be written quickly would be a script to parse a very large log file\n
      and report out only a few events of interest in either a human readable format\n
      or a csv format. also, having experience with a variety of different programming\n
      languages should help you think of new ways to tackle problems in more structured\n
      languages like java, c++, and c#.\n
    - dynamic languages are a different way to think and sometimes the practices\n
      you learn from a dynamic or functional language can transfer to the more statically\n
      typed languages but if you never take the time to learn different languages, you''ll\n
      never get the benefit of having a knew way to think when you are coding.\n
    - for after work work, for freelance jobs...) and final to be programming\n
      literate as possible as...;)\n
    - towards answering the updated question, its a chickenegg problem. the\n
      best way to justify an expense is to show how it reduces a cost somewhere else,\n
      so you may need to spend some extrapersonal time to learn something first to\n
      build some kind of functional prototype. show your boss a demo like "hey, i did\n
      this thing, and it saves me this much time [or better yet, this much \n\n], imagine\n
      if everyone could use this how much money we would save" and then after they agree,\n
      explain how it is some other technology and that it is worth the expense to get\n
      more training, and training for others on how to do it better.\n
    - others have already explained why learning more languages makes you a better\n
      programmer. as for convincing your boss it''s worth it, this is probably just\n
      your company''s culture. some places make career and skill progress a policy (move\n
      up or out), some places value it but leave it up to the employee''s initiative,\n
      and some places are very focused on the bottom line. if you have to explain why\n
      learning a language is a good thing to your boss, my advice would be to stay at\n
      work only as long as necessary, then go home and study new things on your own.\n
    - given the increasing focus to running dynamic languages (da-vinci vm etc.)\n
      on the jvm and the increasing number of dynamic languages that do run on it (jruby,\n
      grrovy, jython) i think the usecases are just increasing. some of the scenarios\n
      i found really benifited are prototyping- use ror or grails to build quick prototypes\n
      with advantage of being able to runn it on the standard app server and (maybe)\n
      reuse existing services etc. testing- right unit tests much much faster in dynamic\n
      languages performanceautomation test scripting- some of these tools are starting\n
      to allow the use standard dynamic language of choice to write the test scripts\n
      instead of proprietary script languages. side benefit might be to the able to\n
      reuse some unit test code you''ve already written.\n
    - a good hockey player plays where the puck is. a great hockey player plays\n
      where the puck is going to be. - wayne gretzky our industry is always changing.\n
      no language can be mainstream forever. to me java, c++, .net is where the puck\n
      is right now. and python, ruby, perl is where the puck is going to be. decide\n
      for yourself if you wanna be good or great!\n
    - don''t tell your employer that you want to learn ruby. tell him you want\n
      to learn about the state-of-the-art in web framework technologies. it just happens\n
      that the hottest ones are django and ruby on rails.\n
    - i think the main benefits of dynamic languages can be boiled down to rapid\n
      development glue the short design-code-test cycle time makes dynamic languages\n
      ideal for prototyping, tools, and quick &amp; dirty one-off scripts. imho, the\n
      latter two can make a huge impact on a programmer''s productivity. it amazes me\n
      how many people trudge through things manually instead of whipping up a tool to\n
      do it for them. i think it''s because they don''t have something like perl in\n
      their toolbox. the ability to interface with just about anything (other programs\n
      or languages, databases, etc.) makes it easy to reuse existing work and automate\n
      tasks that would otherwise need to be done manually.\n
    - im not sure if this is what you are looking for, but we write our main\n
      application with java at the small company i work for, but have used python to\n
      write smaller scripts quickly. backup software, temporary scripts to manipulate\n
      data and push out results. it just seems easier sometimes to sit down with python\n
      and write a quick script than mess with classes and stuff in java. temp scripts\n
      that aren''t going to stick around don''t need a lot of design time wasted on\n
      them. and i am lazy, but it is good to just learn as much as you can of course\n
      and see what features exist in other languages. knowing more never hurts you in\n
      future career changes )\n
    - i don''t think anyone has mentioned this yet. learning a new language can\n
      be fun! surely that''s a good enough reason to try something new.\n
    - paul graham posted an article several years ago about why python programmers\n
      made better java programmers. ( basically, regardless of whether the new language\n
      is relevant to the company''s current methodology, learning a new language means\n
      learning new ideas. someone who is willing to learn a language that isn''t considered\n
      "business class" means that he is interested in programming, beyond just earning\n
      a paycheck. to quote paul''s site and people don''t learn python because it will\n
      get them a job; they learn it because they genuinely like to program and aren''t\n
      satisfied with the languages they already know. which makes them exactly the kind\n
      of programmers companies should want to hire. hence what, for lack of a better\n
      name, i''ll call the python paradox if a company chooses to write its software\n
      in a comparatively esoteric language, they''ll be able to hire better programmers,\n
      because they''ll attract only those who cared enough to learn it. and for programmers\n
      the paradox is even more pronounced the language to learn, if you want to get\n
      a good job, is a language that people don''t learn merely to get a job. if an\n
      employer was willing to pay for the cost of learning a new language, chances are\n
      the people who volunteered to learn (assuming it wasn''t a mandatory class) would\n
      be the same people to are already on the "fast track".\n
    - don''t bother your employer, spend ~\n40 on a book, download some software,\n
      and devote some time each day to readdo exercises. in no time you''ll be trained\n
      )\n
    - the "real benefit" that an employer could see is a better programmer who\n
      can implement solutions faster; however, you will not be able to provide any hard\n
      numbers to justify the expense and an employer will most likely have you work\n
      on what makes money now as opposed to having you work on things that make the\n
      future better. the only time you can get training on the employer''s dime, is\n
      when they perceive a need for it and it''s cheaper than hiring a new person who\n
      already has that skill-set.\n
    - you may be interested in this question "biggest differences of thrift\n
      vs protocol buffers?"\n
    - one of the things near the top of my "to-do" list for pbs is to port google''s\n
      internal protocol buffer performance benchmark - it''s mostly a case of taking\n
      confidential message formats and turning them into entirely bland ones, and then\n
      doing the same for the data. when that''s been done, i''d imagine you could build\n
      the same messages in thrift and then compare the performance. in other words,\n
      i don''t have the data for you yet - but hopefully in the next couple of weeks...\n
    - if the raw net performance is the target, then nothing beats iiop (see\n
      rmiiiop). smallest possible footprint -- only binary data, no markup at all.\n
      serializationdeserialization is very fast too. since it''s iiop (that is corba),\n
      almost all languages have bindings. but i presume the performance is not the only\n
      requirement, right?\n
    - i''m in the process of writing some code in an open source project named\n
      thrift-protobuf-compare comparing between protobuf and thrift. for now it covers\n
      few serialization aspects, but i intend to cover more. the results (for thrift\n
      and protobuf) are discussed in my blog, i''ll add more when i''ll get to it. you\n
      may look at the code to compare api, description language and generated code.\n
      i''ll be happy to have contributions to achieve a more rounded comparison.\n
    - there was a lot of discussion on hidden language features a while back\n
      hidden-features-of-python. where some pitfalls were mentioned (and some of the\n
      good stuff too). also you might want to check out python warts. but for me, integer\n
      division''s a gotcha  52 2 you probably wanted  5*1.02 2.5 if you really want\n
      this (c-like) behaviour, you should write  52 2 as that will work with floats\n
      too (and it will work when you eventually go to python 3)  5*1.02 2.0 gvr explains\n
      how integer division came to work how it does on the history of python.\n
    - A_Body "james dumay eloquently reminded me of another python gotcha not all of\\n
      python's \xE2\x80\x9Cincluded batteries\xE2\x80\x9D are wonderful. james\xE2\\n
      \x80\x99 specific example was the http libraries httplib, urllib, urllib2, urlparse,\\n
      mimetools, and ftplib. some of the functionality is duplicated, and some of\\n
      the functionality you'd expect is completely absent, e.g. redirect handling.\\n
      frankly, it's horrible. if i ever have to grab something via http these days,\\n
      i use the urlgrabber module forked from the yum project. "\n
    - dynamic binding makes typos in your variable names surprisingly hard to\n
      find. it''s easy to spend half an hour fixing a trivial bug. edit an example...\n
      for item in some_list ... # lots of code ... # more code for tiem in some_other_list\n
      process(item) # oops!\n
    - you should be aware of how class variables are handled in python. consider\n
      the following class hierarchy class aaa(object) x = 1 class bbb(aaa) pass class\n
      ccc(aaa) pass now, check the output of the following code  print aaa.x, bbb.x,\n
      ccc.x 1 1 1  bbb.x = 2  print aaa.x, bbb.x, ccc.x 1 2 1  aaa.x = 3  print aaa.x,\n
      bbb.x, ccc.x 3 2 3 surprised? you won''t be if you remember that class variables\n
      are internally handled as dictionaries of a class object. if a variable name is\n
      not found in the dictionary of current class, the parent classes are searched\n
      for it. so, the following code again, but with explanations # aaa {''x'' 1},\n
      bbb {}, ccc {}  print aaa.x, bbb.x, ccc.x 1 1 1  bbb.x = 2 # aaa {''x'' 1},\n
      bbb {''x'' 2}, ccc {}  print aaa.x, bbb.x, ccc.x 1 2 1  aaa.x = 3 # aaa {''x''\n
      3}, bbb {''x'' 2}, ccc {}  print aaa.x, bbb.x, ccc.x 3 2 3 same goes for handling\n
      class variables in class instances (treat this example as a continuation of the\n
      one above)  a = aaa() # a {}, aaa {''x'' 3}  print a.x, aaa.x 3 3  a.x = 4\n
      # a {''x'' 4}, aaa {''x'' 3}  print a.x, aaa.x 4 3\n
    - the only gotchasurprise i''ve dealt with is with cpython''s gil. if for\n
      whatever reason you expect python threads in cpython to run concurrently... well\n
      they''re not and this is pretty well documented by the python crowd and even guido\n
      himself. a long but thorough explanation of cpython threading and some of the\n
      things going on under the hood and why true concurrency with cpython isn''t possible.\n
    - A_Body "expressions in default arguments are calculated when the function is defined,\\n
      not when it\xE2\x80\x99s called. example consider defaulting an argument to\\n
      the current time import time  def report(when=time.time()) ... print when\\n
      ...  report() 1210294387.19  time.sleep(5)  report() 1210294387.19 the when\\n
      argument doesn't change. it is evaluated when you define the function. it won't\\n
      change until the application is re-started. strategy you won't trip over this\\n
      if you default arguments to none and then do something useful when you see it\\n
     def report(when=none) ... if when is none ... when = time.time() ... print\\n
      when ...  report() 1210294762.29  time.sleep(5)  report() 1210294772.23 exercise\\n
      to make sure you've understood why is this happening?  def spam(eggs=[]) ...\\n
      eggs.append(\"spam\") ... return eggs ...  spam() ['spam']  spam() ['spam',\\n
      \spam']  spam() ['spam',spam',spam']  spam() ['spam',spam',spam',spam'] "\n
    - loops and lambdas (or any closure, really) variables are bound by name\n
      funcs = [] for x in range(5) funcs.append(lambda x) [f() for f in funcs] # output\n
      # 4 4 4 4 4 a work around is either creating a separate function or passing the\n
      args by name funcs = [] for x in range(5) funcs.append(lambda x=x x) [f() for\n
      f in funcs] # output # 0 1 2 3 4\n
    - the purpose of metaclasses isn''t to replace the classobject distinction\n
      with metaclassclass - it''s to change the behaviour of class definitions (and\n
      thus their instances) in some way. effectively it''s to alter the behaviour of\n
      the class statement in ways that may be more useful for your particular domain\n
      than the default. the things i have used them for are tracking subclasses, usually\n
      to register handlers. this is handy when using a plugin style setup, where you\n
      wish to register a handler for a particular thing simply by subclassing and setting\n
      up a few class attributes. eg. suppose you write a handler for various music formats,\n
      where each class implements appropriate methods (play  get tags etc) for its\n
      type. adding a handler for a new type becomes class mp3file(musicfile) extensions\n
      [''.mp3''] # register this type as a handler for mp3 files ... # implementation\n
      of mp3 methods go here the metaclass then maintains a dictionary of {''.mp3''\n
     mp3file, ... } etc, and constructs an object of the appropriate type when you\n
      request a handler through a factory function. changing behaviour. you may want\n
      to attach a special meaning to certain attributes, resulting in altered behaviour\n
      when they are present. for example, you may want to look for methods with the\n
      name _get_foo and _set_foo and transparently convert them to properties. as a\n
      real-world example, here''s a recipe i wrote to give more c-like struct definitions.\n
      the metaclass is used to convert the declared items into a struct format string,\n
      handling inheritance etc, and produce a class capable of dealing with it. for\n
      other real-world examples, take a look at various orms, like sqlalchemy''s orm\n
      or sqlobject. again, the purpose is to interpret defintions (here sql column definitions)\n
      with a particular meaning.\n
    - the only time i used metaclasses in python was when writing a wrapper for\n
      the flickr api. my goal was to scrape flickr''s api site and dynamically generate\n
      a complete class hierarchy to allow api access using python objects # both the\n
      photo type and the flickr.photos.search api method # are generated at "run-time"\n
      for photo in flickr.photos.search(text=balloons) print photo.description so in\n
      that example, because i generated the entire python flickr api from the website,\n
      i really don''t know the class definitions at runtime. being able to dynamically\n
      generate types was very useful.\n
    - "but does that mean it should just be an example of the sort of expression\n
      you could use, or should it be an actual expression, that can be executed (eval\n
      etc..) to recreate the object? or... should it be just a rehasing of the actual\n
      expression which was used, for pure information purposes?" wow, that''s a lot\n
      of hand-wringing. an "an example of the sort of expression you could use" would\n
      not be a representation of a specific object. that can''t be useful or meaningful.\n
      what is the difference between "an actual expression, that can ... recreate the\n
      object" and "a rehasing of the actual expression which was used [to create the\n
      object]"? both are an expression that creates the object. there''s no practical\n
      distinction between these. a repr call could produce either a new expression or\n
      the original expression. in many cases, they''re the same. note that this isn''t\n
      always possible, practical or desirable. in some cases, you''ll notice that repr()\n
      presents a string which is clearly not an expression of any kind. the default\n
      repr() for any class you define isn''t useful as an expression. in some cases,\n
      you might have mutual (or circular) references between objects. the repr() of\n
      that tangled hierarchy can''t make sense. in many cases, an object is built incrementally\n
      via a parser. for example, from xml or json or something. what would the repr\n
      be? the original xml or json? clearly not, since they''re not python. it could\n
      be some python expression that generated the xml. however, for a gigantic xml\n
      document, it might not be possible to write a single python expression that was\n
      the functional equivalent of parsing xml.\n
    - you never absolutely need to use a metaclass, since you can always construct\n
      a class that does what you want using inheritance or aggregation of the class\n
      you want to modify. that said, it can be very handy in smalltalk and ruby to be\n
      able to modify an existing class, but python doesn''t like to do that directly.\n
      there''s an excellent developerworks article on metaclassing in python that might\n
      help. the wikipedia article is also pretty good.\n
    - guideline if you can succinctly provide an exact representation, format\n
      it as a python expression (which implies that it can be both eval''d and copied\n
      directly into source code, in the right context). if providing an inexact representation,\n
      use ... format. there are many possible representations for any value, but the\n
      one that''s most interesting for python programmers is an expression that recreates\n
      the value. remember that those who understand python are the target audience&mdash;and\n
      that''s also why inexact representations should include relevant context. even\n
      the default xxx object at 0xnnn, while almost entirely useless, still provides\n
      type, id() (to distinguish different objects), and indication that no better representation\n
      is available.\n
    - let''s start with tim peter''s classic quote metaclasses are deeper magic\n
      than 99% of users should ever worry about. if you wonder whether you need them,\n
      you don''t (the people who actually need them know with certainty that they need\n
      them, and don''t need an explanation about why). tim peters (c.l.p post 2002-12-22)\n
      having said that, i have (periodically) run across true uses of metaclasses. the\n
      one that comes to mind is in django where all of your models inherit from models.model.\n
      models.model, in turn, does some serious magic to wrap your db models with django''s\n
      orm goodness. that magic happens by way of metaclasses. it creates all manner\n
      of exception classes, manager classes, etc. etc. see djangodbmodelsbase.py,\n
      class modelbase() for the beginning of the story.\n
    - it should be a python expression that, when eval''d, creates an object\n
      with the exact same properties as this one. for example, if you have a fraction\n
      class that contains two integers, a numerator and denominator, your __repr__()\n
      method would look like this # in the definition of fraction class def __repr__(self)\n
      return "fraction(%d, %d)" % (self.numerator, self.denominator) assuming that the\n
      constructor takes those two values.\n
    - metaclasses can be handy for construction of domain specific languages\n
      in python. concrete examples are django, sqlobject's declarative syntax of database\n
      schemata. a basic example from a conservative metaclass by ian bicking the metaclasses\n
      i''ve used have been primarily to support a sort of declarative style of programming.\n
      for instance, consider a validation schema class registration(schema.schema)\n
      first_name = validators.string(notempty=true) last_name = validators.string(notempty=true)\n
      mi = validators.maxlength(1) class numbers(foreach.foreach) class number(schema.schema)\n
      type = validators.oneof([''home'','work'']) phone_number = validators.phonenumber()\n
      some other techniques ingredients for building a dsl in python (pdf). edit (by\n
      ali) an example of doing this using collections and instances is what i would\n
      prefer. the important fact is the instances, which give you more power, and eliminate\n
      reason to use metaclasses. further worth noting that your example uses a mixture\n
      of classes and instances, which is surely an indication that you can''t just do\n
      it all with metaclasses. and creates a truly non-uniform way of doing it. number_validator\n
      [ v.oneof(''type'', [''home'','work'']), v.phonenumber(''phone_number''),\n
      ] validators = [ v.string(''first_name'', notempty=true), v.string(''last_name'',\n
      notempty=true), v.maxlength(''mi'', 1), v.foreach([number_validator,]) ] it''s\n
      not perfect, but already there is almost zero magic, no need for metaclasses,\n
      and improved uniformity.\n
    - i have a class that handles non-interactive plotting, as a frontend to\n
      matplotlib. however, on occasion one wants to do interactive plotting. with only\n
      a couple functions i found that i was able to increment the figure count, call\n
      draw manually, etc, but i needed to do these before and after every plotting call.\n
      so to create both an interactive plotting wrapper and an offscreen plotting wrapper,\n
      i found it was more efficient to do this via metaclasses, wrapping the appropriate\n
      methods, than to do something like class plottinginteractive add_slice = wrap_pylab_newplot(add_slice)\n
      this method doesn''t keep up with api changes and so on, but one that iterates\n
      over the class attributes in __init__ before re-setting the class attributes is\n
      more efficient and keeps things up to date class _interactify(type) def __init__(cls,\n
      name, bases, d) super(_interactify, cls).__init__(name, bases, d) for base in\n
      bases for attrname in dir(base) if attrname in d continue # if overridden,\n
      don''t reset attr = getattr(cls, attrname) if type(attr) == types.methodtype\n
      if attrname.startswith("add_") setattr(cls, attrname, wrap_pylab_newplot(attr))\n
      elif attrname.startswith("set_") setattr(cls, attrname, wrap_pylab_show(attr))\n
      of course, there might be better ways to do this, but i''ve found this to be effective.\n
      of course, this could also be done in __new__ or __init__, but this was the solution\n
      i found the most straightforward.\n
    - i was thinking the same thing just yesterday and completely agree. the\n
      complications in the code caused by attempts to make it more declarative generally\n
      make the codebase harder to maintain, harder to read and less pythonic in my opinion.\n
      it also normally requires a lot of copy.copy()ing (to maintain inheritance and\n
      to copy from class to instance) and means you have to look in many places to see\n
      whats going on (always looking from metaclass up) which goes against the python\n
      grain also. i have been picking through formencode and sqlalchemy code to see\n
      if such a declarative style was worth it and its clearly not. such style should\n
      be left to descriptors (such as property and methods) and immutable data. ruby\n
      has better support for such declarative styles and i am glad the core python language\n
      is not going down that route. i can see their use for debugging, add a metaclass\n
      to all your base classes to get richer info. i also see their use only in (very)\n
      large projects to get rid of some boilerplate code (but at the loss of clarity).\n
      sqlalchemy for example does use them elsewhere, to add a particular custom method\n
      to all subclasses based on an attribute value in their class definition e.g a\n
      toy example class test(baseclass_with_metaclass) method_maker_value = "hello"\n
      could have a metaclass that generated a method in that class with special properties\n
      based on "hello" (say a method that added "hello" to the end of a string). it\n
      could be good for maintainability to make sure you did not have to write a method\n
      in every subclass you make instead all you have to define is method_maker_value.\n
      the need for this is so rare though and only cuts down on a bit of typing that\n
      its not really worth considering unless you have a large enough codebase.\n
    -  from datetime import date   repr(date.today()) # calls date.today().__repr__()\n
     'datetime.date(2009, 1, 16)''  eval(_) # _ is the output of the last command\n
      datetime.date(2009, 1, 16) the output is a string that can be parsed by the python\n
      interpreter and results in an equal object. if that''s not possible, it should\n
      return a string in the form of ...some useful description....\n
    - metaclasses aren''t replacing programming! they''re just a trick which\n
      can automate or make more elegant some tasks. a good example of this is pygments\n
      syntax highlighting library. it has a class called regexlexer which lets the user\n
      define a set of lexing rules as regular expressions on a class. a metaclass is\n
      used to turn the definitions into a useful parser. they''re like salt; it''s easy\n
      to use too much.\n
    - the way i used metaclasses was to provide some attributes to classes. take\n
      for example class nameclass(type) def __init__(cls, *args, **kwargs) type.__init__(cls,\n
      *args, **kwargs) cls.name = cls.__name__ will put the name attribute on every\n
      class that will have the metaclass set to point to nameclass.\n
    - besides the jeff hardy blog post on django + ironpython mentioned by tony\n
      meyer, it might be useful to also read jeff''s two other posts in the same series\n
      on his struggles with ironpython, easy_install and zlib. the first is solving\n
      the zlib problem which discusses the absence of zlib for ironpython; hence, no\n
      easyinstall. jeff reimplemented zlib based on componentace''s zlib.net. and finally,\n
      in easy_install on ironpython, part deux jeff discusses some final tweaks that\n
      are needed before easy_install can be used with ironpython.\n
    - if you hate numpy, get out rpy and your local copy of r, and use it instead.\n
      (i would also echo to make you you really need to invert the matrix. in r, for\n
      example, linalg.solve and the solve() function don''t actually do a full inversion,\n
      since it is unnecessary.)\n
    - you can''t do this, which is by design. the django framework authors intended\n
      a strict separation of presentation code from data logic. filtering models is\n
      data logic, and outputting html is presentation logic. so you have several options.\n
      the easiest is to do the filtering, then pass the result to render_to_response.\n
      or you could write a method in your model so that you can say {% for object in\n
      data.filtered_set %}. finally, you could write your own template tag, although\n
      in this specific case i would advise against that.\n
    - i run into this problem on a regular basis and often use the "add a method"\n
      solution. however, there are definitely cases where "add a method" or "compute\n
      it in the view" don''t work (or don''t work well). e.g. when you are caching template\n
      fragments and need some non-trivial db computation to produce it. you don''t want\n
      to do the db work unless you need to, but you won''t know if you need to until\n
      you are deep in the template logic. some other possible solutions use the {%\n
      expr expression> as var_name> %} template tag found at the expression is any legal\n
      python expression with your template''s context as your local scope. change your\n
      template processor. jinja2 ( has syntax that is almost identical to the django\n
      template language, but with full python power available. it''s also faster. you\n
      can do this wholesale, or you might limit its use to templates that you are working\n
      on, but use django''s "safer" templates for designer-maintained pages.\n
    - here''s a database provider that runs on .net &amp; that works with django\n
    - you should have a look at numpy if you do matrix manipulation. this is\n
      a module mainly written in c, which will be much faster than programming in pure\n
      python. here is an example of how to invert a matrix, and do other matrix manipulation.\n
      from numpy import matrix from numpy import linalg a = matrix( [[1,2,3],[11,12,13],[21,22,23]])\n
      # creates a matrix. x = matrix( [[1],[2],[3]] ) # creates a matrix (like a column\n
      vector). y = matrix( [[1,2,3]] ) # creates a matrix (like a row vector). print\n
      a.t # transpose of a. print a*x # matrix multiplication of a and x. print a.i\n
      # inverse of a. print linalg.solve(a, x) # solve the linear equation system. you\n
      can also have a look at the array module, which is a much more efficient implementation\n
      of lists when you have to deal with only one data type.\n
    - make sure you really need to invert the matrix. this is often unnecessary\n
      and can be numerically unstable. when most people ask how to invert a matrix,\n
      they really want to know how to solve ax = b where a is a matrix and x and b are\n
      vectors. it''s more efficient and more accurate to use code that solves the equation\n
      ax = b for x directly than to calculate a inverse then multiply the inverse by\n
      b. even if you need to solve ax = b for many b values, it''s not a good idea to\n
      invert a. if you have to solve the system for multiple b values, save the cholesky\n
      factorization of a, but don''t invert it. see don''t invert that matrix.\n
    - this was demoed at last year''s pycon (the details are also available).\n
      more recently, jeff hardy has blogged about this, including suggestions.\n
    - here''s another path you can use. i''m not sure if this is part of the\n
      standard distribution or if the file is automatically created on first use of\n
      the idle. c\python25\lib\idlelib\idle.pyw\n
    - i''d recommend you start by looking at section 3.4.2 of donald knuth''s\n
      seminumerical algorithms. if your arrays are large, there are more efficient algorithms\n
      in chapter 3 of principles of random variate generation by john dagpunar. if your\n
      arrays are not terribly large or you''re not concerned with squeezing out as much\n
      efficiency as possible, the simpler algorithms in knuth are probably fine.\n
    - here''s what i came up with for weighted selection without replacement\n
      def weightedselectionwithoutreplacement(l, n) """selects without replacement\n
      n random elements from a list of (weight, item) tuples.""" l = sorted((random.random()\n
      * x[0], x[1]) for x in l) return l[-n] this is o(m log m) on the number of items\n
      in the list to be selected from. i''m fairly certain this will weight items correctly,\n
      though i haven''t verified it in any formal sense. here''s what i came up with\n
      for weighted selection with replacement def weightedselectionwithreplacement(l,\n
      n) """selects with replacement n random elements from a list of (weight, item)\n
      tuples.""" cuml = [] total_weight = 0.0 for weight, item in l total_weight +=\n
      weight cuml.append((total_weight, item)) return [cuml[bisect.bisect(cuml, random.random()*total_weight)]\n
      for x in range(n)] this is o(m + n log m), where m is the number of items in the\n
      input list, and n is the number of items to be selected.\n
    - one of the fastest ways to make many with replacement samples from an unchanging\n
      list is the alias method. the core intuition is that we can create a set of equal-sized\n
      bins for the weighted list that can be indexed very efficiently through bit operations,\n
      to avoid a binary search. it will turn out that, done correctly, we will need\n
      to only store two items from the original list per bin, and thus can represent\n
      the split with a single percentage. let''s us take the example of five equally\n
      weighted choices, (a1, b1, c1, d1, e1) to create the alias lookup normalize\n
      the weights such that they sum to 1.0. (a0.2 b0.2 c0.2 d0.2 e0.2) this is\n
      the probability of choosing each weight. find the smallest power of 2 greater\n
      than or equal to the number of variables, and create this number of partitions,\n
      |p|. each partition represents a probability mass of 1|p|. in this case, we create\n
      8 partitions, each able to contain 0.125. take the variable with the least remaining\n
      weight, and place as much of it''s mass as possible in an empty partition. in\n
      this example, we see that a fills the first partition. (p1{a|null,1.0},p2,p3,p4,p5,p6,p7,p8)\n
      with (a0.075, b0.2 c0.2 d0.2 e0.2) if the partition is not filled, take the\n
      variable with the most weight, and fill the partition with that variable. repeat\n
      steps 3 and 4, until none of the weight from the original partition need be assigned\n
      to the list. for example, if we run another iteration of 3 and 4, we see (p1{a|null,1.0},p2{a|b,0.6},p3,p4,p5,p6,p7,p8)\n
      with (a0, b0.15 c0.2 d0.2 e0.2) left to be assigned at runtime get a u(0,1)\n
      random number, say binary 0.001100000 bitshift it lg2(p), finding the index partition.\n
      thus, we shift it by 3, yielding 001.1, or position 1, and thus partition 2. if\n
      the partition is split, use the decimal portion of the shifted random number to\n
      decide the split. in this case, the value is 0.5, and 0.5  0.6, so return a. here\n
      is some code and another explanation, but unfortunately it doesn''t use the bitshifting\n
      technique, nor have i actually verified it.\n
    - there''s a file called idle.py in your python installation directory in\n
      lib\idlelib\idle.py if you run that file with python, then idle should start.\n
      c\python25\pythonw.exe c\python25\lib\idlelib\idle.py\n
    - besides that zope component architekture pycontainer\n
    - as an alternative to monkeypatching, i like di. a nascent project such\n
      as may fit the bill. or see the blog post dependency injection in python by dennis\n
      kempin (aug'08).\n
    - i haven''t used it, but the spring python framework is based on spring\n
      and implements inversion of control. there also appears to be a guice in python\n
      project snake-guice\n
    - spring python is an offshoot of the java-based spring framework and spring\n
      security, targeted for python. this project currently contains the following features\n
      inversion of control (dependency injection) - use either classic xml, or the python\n
      decorator (similar to the spring javaconfig subproject) to wire things together.\n
      while the format isn''t identical to the guice style (centralized wiring vs. wiring\n
      information in each class), it is a valuable way to wire your python app. aspect-oriented\n
      programming - apply interceptors in a horizontal programming paradigm (instead\n
      of vertical oop inheritance) for things like transactions, security, and caching.\n
      databasetemplate - reading from the database requires a monotonous cycle of opening\n
      cursors, reading rows, and closing cursors, along with exception handlers. with\n
      this template class, all you need is the sql query and row-handling function.\n
      spring python does the rest. database transactions - wrapping multiple database\n
      calls with transactions can make your code hard to read. this module provides\n
      multiple ways to define transactions without making things complicated. security\n
       plugin security interceptors to lock down access to your methods, utilizing\n
      both authentication and domain authorization. remoting - it is easy to convert\n
      your local application into a distributed one. if you have already built your\n
      client and server pieces using the ioc container, then going from local to distributed\n
      is just a configuration change. samples - to help demonstrate various features\n
      of spring python, some sample applications have been created petclinic - spring\n
      framework''s sample web app has been rebuilt from the ground up using python web\n
      containers including cherrypy. go check it out for an example of how to use this\n
      framework. (note other python web frameworks will be added to this list in the\n
      future). spring wiki - wikis are powerful ways to store and manage content, so\n
      we created a simple one as a demo! spring bot - use spring python to build a tiny\n
      bot to manage the irc channel of your open source project.\n
    - you can also use new.instancemethod() to create an instance method (either\n
      bound or unbound) from a function.\n
    - functions only become methods at runtime. that is, when you get c.f you\n
      get a bound function (and c.f.im_class is c). at the time your function is defined\n
      it is just a plain function, it is not bound to any class. this unbound and disassociated\n
      function is what is decorated by logger. self.__class__.__name__ will give you\n
      the name of the class, but you can also use descriptors to accomplish this in\n
      a somewhat more general way. this pattern is described in a blog post on decorators\n
      and descriptors, and an implementation of your logger decorator in particular\n
      would look like class logger(object) def __init__(self, func) self.func = func\n
      def __get__(self, obj, type=none) return self.__class__(self.func.__get__(obj,\n
      type)) def __call__(self, *args, **kw) print'entering %s'' % self.func return\n
      self.func(*args, **kw) class c(object) def f(self, x, y) return x+y c().f(1,\n
      2) # = entering bound method c.f of __main__.c object at 0x... obviously the output\n
      can be improved (by using, for example, getattr(self.func,'im_class'', none)),\n
      but this general pattern will work for both methods and functions. however it\n
      will not work for old-style classes (but just don''t use those ;)\n
    - claudiu''s answer is correct, but you can also cheat by getting the class\n
      name off of the self argument. this will give misleading log statements in cases\n
      of inheritance, but will tell you the class of the object whose method is being\n
      called. for example from functools import wraps # use this to preserve function\n
      signatures and docstrings def logger(func) (func) def with_logging(*args, **kwargs)\n
      print "entering %s.%s" % (args[0].__class__.__name__, func.__name__) return func(*args,\n
      **kwargs) return with_logging class c(object) def f(self) pass c().f() as i\n
      said, this won''t work properly in cases where you''ve inherited a function from\n
      a parent class; in this case you might say class b(c) pass b = b() b.f() and\n
      get the message entering b.f where you actually want to get the message entering\n
      c.f since that''s the correct class. on the other hand, this might be acceptable,\n
      in which case i''d recommend this approach over claudiu''s suggestion.\n
    - class functions should always take self as their first argument, so you\n
      can use that instead of im_class. def logger(myfunc) def new(self, *args, **keyargs)\n
      print'entering %s.%s'' % (self.__class__.__name__, myfunc.__name__) return myfunc(self,\n
      *args, **keyargs) return new class c(object) def f(self) pass c().f() at first\n
      i wanted to use self.__name__ but that doesn''t work because the instance has\n
      no name. you must use self.__class__.__name__ to get the name of the class.\n
    - it seems that while the class is being created, python creates regular\n
      function objects. they only get turned into unbound method objects afterwards.\n
      knowing that, this is the only way i could find to do what you want def logger(myfunc)\n
      def new(*args, **keyargs) print'entering %s.%s'' % (myfunc.im_class.__name__,\n
      myfunc.__name__) return myfunc(*args, **keyargs) return new class c(object) def\n
      f(self) pass c.f = logger(c.f) c().f() this outputs the desired result. if you\n
      want to wrap all the methods in a class, then you probably want to create a wrapclass\n
      function, which you could then use like this c = wrapclass(c)\n
    - A_Body "in the time module, there are two timing functions time and clock. time\\n
      gives you \"wall\" time, if this is what you care about. however, the python\\n
      docs say that clock should be used for benchmarking. note that clock behaves\\n
      different in separate systems on ms windows, it uses the win32 function queryperformancecounter(),\\n
      with \"resolution typically better than a microsecond\". it has no special meaning,\\n
      it's just a number (it starts counting the first time you call clock in your\\n
      process). # ms windows t0= time.clock() do_something() t= time.clock() - t0\\n
      # t is wall seconds elapsed (floating point) on *nix, clock reports cpu time.\\n
      now, this is different, and most probably the value you want, since your program\\n
      hardly ever is the only process requesting cpu time (even if you have no other\\n
      processes, the kernel uses cpu time now and then). so, this number, which typically\\n
      is smaller\xE2\xB9 than the wall time (i.e. time.time() - t0), is more meaningful\\n
      when benchmarking code # linux t0= time.clock() do_something() t= time.clock()\\n
       t0 # t is cpu seconds elapsed (floating point) apart from all that, the timeit\\n
      module has the timer class that is supposed to use what's best for benchmarking\\n
      from the available functionality. \xE2\xB9 unless threading gets in the way\xE2\\n
      \x80\xA6 \xE2\xB2 python \xE2\x89\xA53.3 there are time.perf_counter() and time.process_time().\\n
      perf_counter is being used by the timeit module. "\n
    - there is something that works as you want it to twisted.python.reflect.namedany  from\n
      twisted.python.reflect import namedany  namedany("operator.eq") built-in function\n
      eq  namedany("pysqlite2.dbapi2.connect") built-in function connect  namedany("os")\n
      module'os'' from'usrlibpython2.5os.pyc''\n
    - from the python docs on __import__ __import__( name[, globals[, locals[,\n
      fromlist[, level]]]]) ... when the name variable is of the form package.module,\n
      normally, the top-level package (the name up till the first dot) is returned,\n
      not the module named by name. however, when a non-empty fromlist argument is given,\n
      the module named by name is returned. this is done for compatibility with the\n
      bytecode generated for the different kinds of import statement; when using "import\n
      spam.ham.eggs", the top-level package spam must be placed in the importing namespace,\n
      but when using "from spam.ham import eggs", the spam.ham subpackage must be used\n
      to find the eggs variable. as a workaround for this behavior, use getattr() to\n
      extract the desired components. for example, you could define the following helper\n
      def my_import(name) mod = __import__(name) components = name.split(''.'') for\n
      comp in components[1] mod = getattr(mod, comp) return mod to paraphrase when\n
      you ask for somepackage.somemodule, __import__ returns somepackage.__init__.py,\n
      which is often empty. it will return somemodule if you provide fromlist (a list\n
      of the variable names inside somemodule you want, which are not actually returned)\n
      you can also, as i did, use the function they suggest. note i asked this question\n
      fully intending to answer it myself. there was a big bug in my code, and having\n
      misdiagnosed it, it took me a long time to figure it out, so i figured i''d help\n
      the so community out and post the gotcha i ran into here.\n
    - the time module in python gives you access to the clock() function, which\n
      returns time in seconds as a floating point. different systems will have different\n
      accuracy based on their internal clock setup (ticks per second) but it''s generally\n
      at least under 20milliseconds, and in some cases better than a few microseconds.\n
    - import datetime start = datetime.datetime.now() do_long_code() finish =\n
      datetime.datetime.now() delta = finish - start print delta.seconds from midnight\n
      import datetime midnight = datetime.datetime.now().replace(hour=0, minute=0, second=0,\n
      microsecond=0) now = datetime.datetime.now() delta = now - midnight print delta.seconds\n
    - what you need is time() function from time module import time start =\n
      time.time() do_long_code() print "it took", time.time() - start, "seconds." you\n
      can use timeit module for more options though.\n
    - cython and pyrex can be used to generate c code using a python-like syntax.\n
      psyco is also fantastic for appropriate projects (sometimes you''ll not notice\n
      much speed boost, sometimes it''ll be as much as 50x as fast). i still reckon\n
      the best way is to profile your code (cprofile, etc.) and then just code the bottlenecks\n
      as c functions for python.\n
    - rather than just punting to c, i''d suggest make your code count. do more\n
      with fewer executions of lines change the algorithm to a faster one. it doesn''t\n
      need to be fancy to be faster in many cases. use python primitives that happens\n
      to be written in c. some things will force an interpreter dispatch where some\n
      wont. the latter is preferable beware of code that first constructs a big data\n
      structure followed by its consumation. think the difference between range and\n
      xrange. in general it is often worth thinking about memory usage of the program.\n
      using generators can sometimes bring o(n) memory use down to o(1). python is generally\n
      non-optimizing. hoist invariant code out of loops, eliminate common subexpressions\n
      where possible in tight loops. if something is expensive, then precompute or memoize\n
      it. regular expressions can be compiled for instance. need to crunch numbers?\n
      you might want to check numpy out. many python programs are slow because they\n
      are bound by disk io or database access. make sure you have something worthwhile\n
      to do while you wait on the data to arrive rather than just blocking. a weapon\n
      could be something like the twisted framework. note that many crucial data-processing\n
      libraries have c-versions, be it xml, json or whatnot. they are often considerably\n
      faster than the python interpreter. if all of the above fails for profiled and\n
      measured code, then begin thinking about the c-rewrite path.\n
    - i hope you''ve read resuming what''s already there are usualy 3 principles\n
      write code that gets transformed in better bytecode, like, use locals, avoid unnecessary\n
      lookupscalls, use idiomatic constructs (if there''s natural syntax for what you\n
      want, use it - usually faster. eg don''t do "for key in some_dict.keys()", do\n
      "for key in some_dict") whatever is written in c is considerably faster, abuse\n
      whatever c functionsmodules you have available when in doubt, import timeit,\n
      profile\n
    - the canonical reference to how to improve python code is here performancetips.\n
      i''d recommend against optimizing in c unless you really need to though. for most\n
      applications, you can get the performance you need by following the rules posted\n
      in that link.\n
    - A_Body "first thing that comes to mind psyco. it runs only on x86, for the time\\n
      being. then, constant binding. that is, make all global references (and global.attr,\\n
      global.attr.attr\xE2\x80\xA6) be local names inside of functions and methods.\\n
      this isn't always successful, but in general it works. it can be done by hand,\\n
      but obviously is tedious. you said apart from in-code optimization, so i won't\\n
      delve into this, but keep your mind open for typical mistakes (for i in range(10000000)\\n
      comes to mind) that people do. "\n
    - this won''t necessarily speed up any of your code, but is critical knowledge\n
      when programming in python if you want to avoid slowing your code down. the "global\n
      interpreter lock" (gil), has the potential to drastically reduce the speed of\n
      your multi-threaded program if its behavior is not understood (yes, this bit me\n
      ... i had a nice 4 processor machine that wouldn''t use more than 1.2 processors\n
      at a time). there''s an introductory article with some links to get you started\n
      at smoothspan.\n
    - run your app through the python profiler. find a serious bottleneck. rewrite\n
      that bottleneck in c. repeat.\n
    - the usual suspects -- profile it, find the most expensive line, figure\n
      out what it''s doing, fix it. if you haven''t done much profiling before, there\n
      could be some big fat quadratic loops or string duplication hiding behind otherwise\n
      innocuous-looking expressions. in python, two of the most common causes i''ve\n
      found for non-obvious slowdown are string concatenation and generators. since\n
      python''s strings are immutable, doing something like this result = u"" for item\n
      in my_list result += unicode (item) will copy the entire string twice per iteration.\n
      this has been well-covered, and the solution is to use "".join result = "".join\n
      (unicode (item) for item in my_list) generators are another culprit. they''re\n
      very easy to use and can simplify some tasks enormously, but a poorly-applied\n
      generator will be much slower than simply appending items to a list and returning\n
      the list. finally, don''t be afraid to rewrite bits in c! python, as a dynamic\n
      high-level language, is simply not capable of matching c''s speed. if there''s\n
      one function that you can''t optimize any more in python, consider extracting\n
      it to an extension module. my favorite technique for this is to maintain both\n
      python and c versions of a module. the python version is written to be as clear\n
      and obvious as possible -- any bugs should be easy to diagnose and fix. write\n
      your tests against this module. then write the c version, and test it. its behavior\n
      should in all cases equal that of the python implementation -- if they differ,\n
      it should be very easy to figure out which is wrong and correct the problem.\n
    - regarding "secondly when writing a program from scratch in python, what\n
      are some good ways to greatly improve performance?" remember the jackson rules\n
      of optimization rule 1 don''t do it. rule 2 (for experts only) don''t do it\n
      yet. and the knuth rule "premature optimization is the root of all evil." the\n
      more useful rules are in the general rules for optimization. don''t optimize as\n
      you go. first get it right. then get it fast. optimizing a wrong program is still\n
      wrong. remember the 8020 rule. always run "before" and "after" benchmarks. otherwise,\n
      you won''t know if you''ve found the 80%. use the right algorithms and data structures.\n
      this rule should be first. nothing matters as much as algorithm and data structure.\n
      bottom line you can''t prevent or avoid the "optimize this program" effort. it''s\n
      part of the job. you have to plan for it and do it carefully, just like the design,\n
      code and test activities.\n
    - people have given some good advice, but you have to be aware that when\n
      high performance is needed, the python model is punt to c. efforts like psyco\n
      may in the future help a bit, but python just isn''t a fast language, and it isn''t\n
      designed to be. very few languages have the ability to do the dynamic stuff really\n
      well and still generate very fast code; at least for the forseeable future (and\n
      some of the design works against fast compilation) that will be the case. so,\n
      if you really find yourself in this bind, your best bet will be to isolate the\n
      parts of your system that are unacceptable slow in (good) python, and design around\n
      the idea that you''ll rewrite those bits in c. sorry. good design can help make\n
      this less painful. prototype it in python first though, then you''ve easily got\n
      a sanity check on your c, as well. this works well enough for things like numpy,\n
      after all. i can''t emphasize enough how much good design will help you though.\n
      if you just iteratively poke at your python bits and replace the slowest ones\n
      with c, you may end up with a big mess. think about exactly where the c bits are\n
      needed, and how they can be minimized and encapsulated sensibly.\n
    - just a note on using psyco in some cases it can actually produce slower\n
      run-times. especially when trying to use psyco with code that was written in c.\n
      i can''t remember the the article i read this, but the map() and reduce() functions\n
      were mentioned specifically. luckily you can tell psyco not to handle specified\n
      functions andor modules.\n
    - this is the procedure that i try to follow import psyco; psyco.full()\n
      if it''s not fast enough, run the code through a profiler, see where the bottlenecks\n
      are. (disable psyco for this step!) try to do things such as other people have\n
      mentioned to get the code at those bottlenecks as fast as possible. stuff like\n
      [str(x) for x in l] or [x.strip() for x in l] is much, much slower than map(str,\n
      x) or map(str.strip, x). after this, if i still need more speed, it''s actually\n
      really easy to get pyrex up and running. i first copy a section of python code,\n
      put it directly in the pyrex code, and see what happens. then i twiddle with it\n
      until it gets faster and faster.\n
    - it''s often possible to achieve near-c speeds (close enough for any project\n
      using python in the first place!) by replacing explicit algorithms written out\n
      longhand in python with an implicit algorithm using a built-in python call. this\n
      works because most python built-ins are written in c anyway. well, in cpython\n
      of course ;-)\n
    - i''m surprised no one mentioned shedskin it automagically converts your\n
      python program to c++ and in some benchmarks yields better improvements than psyco\n
      in speed. plus anecdotal stories on the simplicity there are limitations though,\n
      please see\n
    - something like this? for letter in range(ord(''a''), ord(''z'') + 1) print\n
      chr(letter) + "", lowertext.count(chr(letter)) (i don''t speak python; please\n
      forgive my syntax errors)\n
    - if using psyco, i''d recommend psyco.profile() instead of psyco.full().\n
      for a larger project it will be smarter about the functions that got optimized\n
      and use a ton less memory. i would also recommend looking at iterators and generators.\n
      if your application is using large data sets this will save you many copies of\n
      containers.\n
    - do you mean using import string string.ascii_lowercase then, counters\n
      dict() for letter in string.ascii_lowercase counters[letter] = lowertext.count(letter)\n
      all lowercase letters are accounted for, missing counters will have zero value.\n
      using generators counters = dict( (letter,lowertext.count(letter)) for letter\n
      in string.ascii_lowercase )\n
    - if you just want to do a frequency count of a string, try this s ='hi\n
      there'' f = {} for c in s f[c] = f.get(c, 0) + 1 print f\n
    -  the question is how to make alltheletters equal to said letters without\n
      something like alltheletters = "abcdefg...xyz" that''s actually provided by the\n
      string module, it''s not like you have to manually type it yourself ;) import\n
      string alltheletters = string.ascii_lowercase def alphcount(text) lowertext =\n
      text.lower() for letter in alltheletters print letter + "", lowertext.count(letter)\n
    - main question is "iterate through the alphabet" import string for c in\n
      string.lowercase print c how get letter frequencies with some efficiency and\n
      without counting non-letter characters import string sample = "hello there, this\n
      is a test!" letter_freq = dict((c,0) for c in string.lowercase) for c in [c for\n
      c in sample.lower() if c.isalpha()] letter_freq[c] += 1 print letter_freq\n
    - A_Body "the question you've asked (how to iterate through the alphabet) is not\\n
      the same question as the problem you're trying to solve (how to count the frequency\\n
      of letters in a string). you can use string.lowercase, as other posters have\\n
      suggested import string alltheletters = string.lowercase to do things the way\\n
      you're \"used to\", treating letters as numbers, you can use the \"ord\" and\\n
      \"chr\" functions. there's absolutely no reason to ever do exactly this, but\\n
      maybe it comes closer to what you're actually trying to figure out def getalltheletters(begin='a',\\n
      end='z') beginnum = ord(begin) endnum = ord(end) for number in xrange(beginnum,\\n
      endnum+1) yield chr(number) you can tell it does the right thing because this\\n
      code prints true import string print'.join(getalltheletters()) == string.lowercase\\n
      but, to solve the problem you're actually trying to solve, you want to use a\\n
      dictionary and collect the letters as you go from collections import defaultdict\\n
      def letteroccurrances(string) frequencies = defaultdict(lambda 0) for character\\n
      in string frequencies[character.lower()] += 1 return frequencies use like so\\n
      occs = letteroccurrances(\"hello, world!\") print occs['l'] print occs['h']\\n
      this will print3' and1' respectively. note that this works for unicode as\\n
      well # -*- coding utf-8 -*- occs = letteroccurrances(u\"h\xE3\xA9\xE4\xBA\xE4\\n
      \xBA\xE3\xB3, \xE1\xBA\x83\xE3\xB3\xE5\x95\xE4\xBAd!\") print occs[u'l'] print\\n
      occs[u'\xE4\xBA'] if you were to try the other approach on unicode (incrementing\\n
      through every character) you'd be waiting a long time; there are millions of\\n
      unicode characters. to implement your original function (print the counts of\\n
      each letter in alphabetical order) in terms of this def alphcount(text) for\\n
      character, count in sorted(letteroccurrances(text).iteritems()) print \"%s\\n
      %s\" % (character, count) alphcount(\"hello, world!\") "\n
    - so, you''re not going to like the answer, partly because i''m not yet done\n
      writing the code and partly because it''s a lot of work. what you need to do,\n
      as i discovered when i ran into this myself, is spend a lot of time reading through\n
      the formset and model-formset code to get a feel for how it all works (not helped\n
      by the fact that some of the functionality lives on the formset classes, and some\n
      of it lives in factory functions which spit them out). you will need this knowledge\n
      in the later steps. write your own formset class which subclasses from baseinlineformset\n
      and accepts initial. the really tricky bit here is that you must override __init__(),\n
      and you must make sure that it calls up to baseformset.__init__() rather than\n
      using the direct parent or grandparent __init__() (since those are baseinlineformset\n
      and basemodelformset, respectively, and neither of them can handle initial data).\n
      write your own subclass of the appropriate admin inline class (in my case it was\n
      tabularinline) and override its get_formset method to return the result of inlineformset_factory()\n
      using your custom formset class. on the actual modeladmin subclass for the model\n
      with the inline, override add_view and change_view, and replicate most of the\n
      code, but with one big change build the initial data your formset will need,\n
      and pass it to your custom formset (which will be returned by your modeladmin''s\n
      get_formsets() method). i''ve had a few productive chats with brian and joseph\n
      about improving this for future django releases; at the moment, the way the model\n
      formsets work just make this more trouble than it''s usually worth, but with a\n
      bit of api cleanup i think it could be made extremely easy.\n
    - you shouldn''t be having trouble developing against your own machine. what\n
      error are you getting? an openid provider will ask you to give your site (in this\n
      case or similar) access to your identity. if you click ok then it will redirect\n
      you that url. i''ve never had problems with livejournal and i expect that myopenid.com\n
      will work too. if you''re having problems developing locally i suggest that the\n
      problem you''re having is unrelated to the url being localhost, but something\n
      else. without an error message or problem description it''s impossible to say\n
      more. edit it turns out that yahoo do things differently to other openid providers\n
      that i''ve come across and disallow redirections to ip address, sites without\n
      a correct tld in their domain name and those that run on ports other than 80 or\n
      443. see here for a post from a yahoo developer on this subject. this post offers\n
      a work around, but i would suggest that for development myopenid.com would be\n
      far simpler than working around yahoo, or running your own provider.\n
    - i''m also looking into this. i too am working on a django project that\n
      might utilize open id. for references, check out phpmyid openid''s page hopefully\n
      someone here has tackled this issue.\n
    - i''m using phpmyid to authenticate at stackoverflow right now. generates\n
      a standard http auth realm and works perfectly. it should be exactly what you\n
      need.\n
    - why not run an openid provider from your local machine? if you are a .net\n
      developer there is an openid provider library for .net at google code. this uses\n
      the standard .net profile provider mechanism and wraps it with an openid layer.\n
      we are using it to add openid to our custom authentication engine. if you are\n
      working in another languageplatform there are a number of openid implementation\n
      avalaiable from the openid community site here.\n
    - you could probably use the django openid library to write a provider to\n
      test against. have one that always authenticates and one that always fails.\n
    - i have no problems testing with myopenid.com. i thought there would be\n
      a problem testing on my local machine but it just worked. (i''m using asp.net\n
      with dotnetopenid library). the'realm'' and return url must contain the port\n
      number like' i assume it works ok because the provider does a client side redirect.\n
    - the libraries at openid enabled ship with examples that are sufficient\n
      to run a local test provider. look in the examplesdjopenid directory of the\n
      python-openid source distribution. running that will give you an instance of this\n
      test provider.\n
    - i would like to add that there is a fast sprite library rabbyt which may\n
      be a good complement for pyglet.\n
    - i was considering both pygame and pyglet for a small 2d shooter, and after\n
      looking at source code and some tutorials went with pyglet. i was very happy with\n
      the results. pyglet worked immediately and was enjoyable to work with, and conceptually\n
      very clean. it certainly had a pythonic feel to me you could get a straightforward\n
      and readable example going very quickly, and it uses decorators to good effect\n
      for event handling. it also didn''t force a particular program structure, which\n
      made it easy for me to mix in the physics modelling of pymunk ( while it is based\n
      on opengl and you can use those features for special effects, i was able to do\n
      just fine without any knowledge of them. it also works well with py2exe and py2app,\n
      which is important because a lot of people do not have a python interpreter installed.\n
      on the downside, there is less information about it on the web because it is newer,\n
      as well as fewer sample games to look at. also, it changed quite a bit from previous\n
      versions, so some of the tutorials which are there are now out of date (there\n
      is the "new style event loop" and the sprite class as major additions.) i would\n
      recommend downloading the examples (there is a nice asteroids clone called astraea\n
      included) and seeing if you like the style.\n
    - pygame lgpl license pyglet bsd license pygame relies on sdl libraries\n
      heavily pyglet is a pure python library with fewer dependencies, i think it requires\n
      better understanding of opengl pygame is around here for a long time, a lot of\n
      people used it pyglet is a new lib pygame is geared towards game development (cursors,\n
      sprites, joystickgamepad support) pyglet is more general purpose (though it has\n
      a sprite class) i found also this discussion on pyglet-users mailing list from\n
      pygame+pyopengl to pyglet disclaimer i did not use either yet, only tried some\n
      tutorials ;-)\n
    - though i liked the inheritance idea from s. lott and agree with the'type(a)''\n
      thing, but since functions too have accessible attributes, i think the it can\n
      be managed this way class dog def __init__(self, barkmethod=none) self.bark=self.barkp\n
      if barkmethod self.bark=barkmethod def barkp(self) """original bark""" print\n
      "woof" d=dog() print "calling original bark" d.bark() print "that was %s\n" %\n
      d.bark.__doc__ def barknew() """a new type of bark""" print "wooooooof" d1=dog(barknew)\n
      print "calling the new bark" d1.bark() print "that was %s\n" % d1.bark.__doc__\n
      def barknew1() """another type of new bark""" print "nowoof" d1.bark=barknew1\n
      print "another new" d1.bark() print "that was %s\n" % d1.bark.__doc__ and the\n
      output is  calling original bark woof that was original bark calling the new\n
      bark wooooooof that was a new type of bark another new nowoof that was another\n
      type of new bark\n
    - since functions are first class objects in python you can pass them while\n
      initializing your class object or override it anytime for a given class instance\n
      class dog def __init__(self, barkmethod=none) self.bark=self.barkp if barkmethod\n
      self.bark=barkmethod def barkp(self) print "woof" d=dog() print "calling original\n
      bark" d.bark() def barknew() print "wooooooof" d1=dog(barknew) print "calling\n
      the new bark" d1.bark() def barknew1() print "nowoof" d1.bark=barknew1 print\n
      "calling another new" d1.bark() and the results are calling original bark woof\n
      calling the new bark wooooooof calling another new nowoof\n
    - yes, it''s possible class dog def bark(self) print "woof" def new_bark(self)\n
      print "woof woof" foo = dog() functype = type(dog.bark) # "woof" foo.bark() #\n
      replace bark with new_bark for this object only foo.bark = functype(new_bark,\n
      foo, dog) foo.bark() # "woof woof"\n
    - class dog def bark(self) print "woof" boby = dog() boby.bark() # woof\n
      # method override def new_bark() print "wooooof!!" boby.bark = new_bark boby.bark()\n
      # wooooof!! you can use the boby variable inside the function if you need. since\n
      you are overriding the method just for this one instance object, this way is simpler\n
      and has exactly the same effect as using self.\n
    - please do not do this as shown. you code becomes unreadable when you monkeypatch\n
      an instance to be different from the class. you cannot debug monkeypatched code.\n
      when you find a bug in boby and print type(boby), you''ll see that (a) it''s a\n
      dog, but (b) for some obscure reason it doesn''t bark correctly. this is a nightmare.\n
      do not do it. please do this instead. class dog def bark(self) print "woof"\n
      class bobydog( dog ) def bark( self ) print "wooooof!!" otherdog= dog() otherdog.bark()\n
      # woof boby = bobydog() boby.bark() # wooooof!!\n
    - perl? yikes. as someone has observed perl is like a big explosion in a\n
      punctuation factory. it''s terseness is not an advantage if the resultant code\n
      is not self documenting. have used groovy for some utility tasks, easy to get\n
      going. full access to java libraries, plus some cool addtions to it, like listing\n
      the files in a directory using a closure  process all files printing out full\n
      name (. and .. auto excluded) new file(basedir).eachfile{ f- if (f.isfile()) println\n
      f.canonicalpath }\n
    - try groovy .. it has all features that you need there. you can use existing\n
      java lib without any modification on its classes. basically .. groovy is java++,\n
      it is more dynamic and fun to learn (just like ruby) i dont like ruby or python\n
      syntax so i will put them behind. groovy is just like cc++ syntax so i like him\n
      lol )\n
    - python has all nine criteria. it scores a 56. i''m sure ruby has everything\n
      python has. it seems to have fewer libraries. so it scores a 51. i don''t know\n
      if groovy has every feature. since python is 56 and ruby is a 51, python just\n
      barely edges out ruby. however, i think this kind of decision can still boil down\n
      to some subjective issues outside these nine criteria.\n
    - i know it''s not on your list, but at least look at perl. richness of apilibraries\n
      to sink a ship. runs on more systems than most people realise exists. works well\n
      with binary libraries. has a huge community. portability, see above. database\n
      manipulation more ways to do it. ( pick your favorite module ) and one of the\n
      most expressiveterse languages around.\n
    - just to muddy the waters... groovy give you access to java. java has an\n
      extremely rich set of apislibraries, applications, etc. groovy is embeddable,\n
      although easiest in java. dllslibraries (if you''re talking about non-groovyjava)\n
      may be somewhat problematic, although there are ways and some apis to help. i''ve\n
      done some python programming, but being more familiar with java, groovy comes\n
      a lot easier to me.\n
    - this sort of adding-up-scores-by-features is not a good way to choose a\n
      programming language. you''d be better off choosing whichever you know the best.\n
      if you don''t know any of them, try them out for a little while. if you have a\n
      really specific project in mind, then maybe some programming languages would be\n
      better, but if you just have general preferences you will never come to a consensus.\n
      that said, python is pretty flexible, it''s the most popular on your list so the\n
      easiest to solve whatever sorts of problems you have by searching, so i''d recommend\n
      python.\n
    - i think it''s going to be difficult to get an objective comparison. i personally\n
      prefer python. to address one of your criteria, python was designed from the start\n
      to be an embeddable language. it has a very rich c api, and the interpreter is\n
      modularized to make it easy to call from c. if java is your host environment,\n
      you should look at jython, an implementation of python inside the java environment\n
      (vm and libs).\n
    - make one or both of the terms a floating point number, like so 4.0100.0\n
      alternatively, turn on the feature that will be default in python 3.0,'true\n
      division'', that does what you want. at the top of your module or script, do\n
      from __future__ import division\n
    - try 4.0100\n
    - check out the looper utility from the tempita project. it gives you a wrapper\n
      object around the loop item that provides properties such as previous, next, first,\n
      last etc. take a look at the source code for the looper class, it is quite simple.\n
      there are other such loop helpers out there, but i cannot remember any others\n
      right now. example > easy_install tempita > python >>> from tempita import looper\n
      >>> for loop, i in looper([1, 2, 3]) ... print loop.previous, loop.item, loop.index,\n
      loop.next, loop.first, loop.last, loop.length, loop.odd, loop.even ... none 1\n
      0 2 true false 3 true 0 1 2 1 3 false false 3 false 1 2 3 2 none false true 3\n
      true 0\n
    - when dealing with generators where you need some context, i often use the\n
      below utility function to give a sliding window view on an iterator import collections,\n
      itertools def window(it, winsize, step=1) """sliding window iterator.""" it=iter(it)\n
      # ensure we have an iterator l=collections.deque(itertools.islice(it, winsize))\n
      while 1 # continue till stopiteration gets raised. yield tuple(l) for i in range(step)\n
      l.append(it.next()) l.popleft() it''ll generate a view of the sequence n items\n
      at a time, shifting step places over. eg.  list(window([1,2,3,4,5],3)) [(1, 2,\n
      3), (2, 3, 4), (3, 4, 5)] when using in lookaheadbehind situations where you\n
      also need to deal with numbers without having a next or previous value, you may\n
      want pad the sequence with an appropriate value such as none. l= range(10) # print\n
      adjacent numbers for cur, next in window(l + [none] ,2) if next is none print\n
      "%d is the last number." % cur else print "%d is followed by %d" % (cur,next)\n
    - expressed as a generator function def neighborhood(iterable) iterator\n
      iter(iterable) prev = none item = iterator.next() # throws stopiteration if\n
      empty. for next in iterator yield (prev,item,next) prev = item item = next yield\n
      (prev,item,none) usage for prev,item,next in neighborhood(l) print prev, item,\n
      next edit i thought it would reduce the readability, but this way seem to look\n
      better.\n
    - you cant get a decimal value by dividing one integer with another, you''ll\n
      allways get an integer that way (result truncated to integer). you need at least\n
      one value to be a decimal number.\n
    - immediately previous? you mean the following, right? previous = none for\n
      item in somelist if item == target break previous = item # previous is the item\n
      before the target if you want n previous items, you can do this with a kind of\n
      circular queue of size n. queue = [] for item in somelist if item == target\n
      break queue .append( item ) if len(queue )  n queue .pop(0) if len(queue )  n\n
      previous = none previous = previous[0] # previous is *n* before the target\n
    - the most simple way is to search the list for the item def get_previous(l,\n
      item) idx = l.find(item) return none if idx == 0 else l[idx-1] of course, this\n
      only works if the list only contains unique items. the other solution is for\n
      idx in range(len(l)) item = l[idx] if item == 2 l[idx-1]\n
    - iterators only have the next() method so you cannot look forwards or backwards,\n
      you can only get the next item. enumerate(iterable) can be useful if you are iterating\n
      a list or tuple.\n
    - a simple route 4  100.0 or 4.0  100\n
    - you need to tell python to use floating point values, not integers. you\n
      can do that simply by using a decimal point yourself in the inputs  4100.0 0.040000000000000001\n
    - i don''t think there is a straightforward way, especially that an iterable\n
      can be a generator (no going back). there''s a decent workaround, relying on explicitly\n
      passing the index into the loop body for itemindex, item in enumerate(l) if\n
      itemindex0 previousitem = l[itemindex-1] else previousitem = none the enumerate()\n
      function is a builtin.\n
    - A_Body "there are three options  4  float(100) 0.04  4  100.0 0.04 which is\\n
      the same behavior as the c, c++, java etc, or  from __future__ import division\\n
     4  100 0.04 you can also activate this behavior by passing the argument -qnew\\n
      to the python interpreter \n python -qnew  4  100 0.04 the second option will\\n
      be the default in python 3.0. if you want to have the old integer division,\\n
      you have to use the  operator. edit added section about -qnew, thanks to\\n
      \xEE\xA4\xEE\x96\xEE\xA9\xEE\xA4\xEE\x96\xEE\x99\xEE\x9F\xEE\xA5! "\n
    - you might want to look at python''s decimal package, also. this will provide\n
      nice decimal results.  decimal.decimal(''4'')100 decimal("0.04")\n
    - other answers suggest how to get a floating-point value. while this wlil\n
      be close to what you want, it won''t be exact  0.4100. 0.0040000000000000001\n
      if you actually want a decimal value, do this  import decimal  decimal.decimal(''4'')\n
     decimal.decimal(''100'') decimal("0.04") that will give you an object that properly\n
      knows that 4  100 in base 10 is "0.04". floating-point numbers are actually in\n
      base 2, i.e. binary, not decimal.\n
    - l=[1,2,3] for i,item in enumerate(l) if item==2 get_previous=l[i-1] print\n
      get_previous 1\n
    - it''s not a method, it''s a field. the field is called __name__. class.__name__\n
      will give the name of the class as a string. object.__class__.__name__ will give\n
      the name of the class of an object.\n
    - in [1] class test(object) ... pass ... in [2] test.__name__ out[2]\n
     'test''\n
    - i agree with mr.shark, but if you have an instance of a class, you''ll\n
      need to use its __class__ member  class test() ... pass ...  a_test = test()   a_test.__name__\n
      traceback (most recent call last) file "stdin", line 1, in module attributeerror\n
      test instance has no attribute'__name__''   a_test.__class__ class __main__.test\n
      at 0x009eede0\n
    - in [8] str(''2''.__class__) out[8] "type'str''" in [9] str(len.__class__)\n
      out[9] "type'builtin_function_or_method''" in [10] str(4.6.__class__) out[10]\n
      "type'float''" or, as was pointed out before, in [11] 4.6.__class__.__name__\n
      out[11]'float''\n
    - for larger files you could compute a md5 or sha hash of the files.\n
    - i would use a hash of the file''s contents using md5. import hashlib def\n
      checksum(f) md5 = hashlib.md5() md5.update(open(f).read()) return md5.hexdigest()\n
      def is_contents_same(f1, f2) return checksum(f1) == checksum(f2) if not is_contents_same(''foo.txt'',\n
     'bar.txt'') print'the contents are not the same!''\n
    - here is also the code to handle the result def foo (a) x=a y=a*2 return\n
      (x,y) (x,y) = foo(50)\n
    - if you''re going for even basic efficiency, you probably want to check\n
      the file size first if os.path.getsize(filename1) == os.path.getsize(filename2)\n
      if open(''filename1'',''r'').read() == open(''filename2'',''r'').read() # files\n
      are the same. this saves you reading every line of two files that aren''t even\n
      the same size, and thus can''t be the same. (even further than that, you could\n
      call out to a fast md5sum of each file and compare those, but that''s not "in\n
      python", so i''ll stop here.)\n
    - A_Body "this is a functional-style file comparison function. it returns instantly\\n
      false if the files have different sizes; otherwise, it reads in 4kib block sizes\\n
      and returns false instantly upon the first difference from __future__ import\\n
      with_statement import os import itertools, functools, operator def filecmp(filename1,\\n
      filename2) \"do the two files have exactly the same contents?\" with open(filename1,\\n
      \"rb\") as fp1, open(filename2, \"rb\") as fp2 if os.fstat(fp1.fileno()).st_size\\n
      != os.fstat(fp2.fileno()).st_size return false # different sizes \xE2\x88\xB4\\n
      not equal fp1_reader= functools.partial(fp1.read, 4096) fp2_reader= functools.partial(fp2.read,\\n
      4096) cmp_pairs= itertools.izip(iter(fp1_reader,'), iter(fp2_reader,'))\\n
      inequalities= itertools.starmap(operator.ne, cmp_pairs) return not any(inequalities)\\n
      if __name__ == \"__main__\" import sys print filecmp(sys.argv[1], sys.argv[2])\\n
      just a different take ) "\n
    - since i can''t comment on the answers of others i''ll write my own. if\n
      you use md5 you definitely must not just md5.update(f.read()) since you''ll use\n
      too much memory. def get_file_md5(f, chunk_size=8192) h = hashlib.md5() while\n
      true chunk = f.read(chunk_size) if not chunk break h.update(chunk) return h.hexdigest()\n
    - the low level way from __future__ import with_statement with open(filename1)\n
      as f1 with open(filename2) as f2 if f1.read() == f2.read() ... the high level\n
      way import filecmp if filecmp.cmp(filename1, filename2, shallow=false) ...\n
    - return as a tuple, e.g. def foo (a) x=a y=a*2 return (x,y)\n
    - you separate the values you want to return by commas def get_name() #\n
      you code return first_name, last_name the commas indicate it''s a tuple, so you\n
      could wrap your values by parentheses return (first_name, last_name) then when\n
      you call the function you a) save all values to one variable as a tuple, or b)\n
      separate your variable names by commas name = get_name() # this is a tuple first_name,\n
      last_name = get_name() (first_name, last_name) = get_name() # you can put parentheses,\n
      but i find it ugly\n
    -  f = open(filename1, "r").read() f2 = open(filename2,"r").read() print\n
      f == f2\n
    - you can use numpy.linalg.det to compute the determinant of an array in\n
      [1] import numpy in [2] m = [[1, 2], [3, 4]] in [3] print numpy.linalg.det(m)\n
      out[3] -2.0000000000000004\n
    - the py2exe and 2to3 programs serve completely different purposes, so i''m\n
      not sure what your ultimate goal is. if you want to build an executable from a\n
      working python program, use the version of py2exe that is suitable for whichever\n
      python you are using (version 2 or version 3). if you want to convert an existing\n
      python 2 program to python 3, use 2to3 plus any additional editing as necessary.\n
      the python 3 documentation describes the conversion process in more detail. update\n
      i now understand that you might have been trying to run 2to3 against py2exe itself\n
      to try to make a python 3 compatible version. unfortunately, this is definitely\n
      beyond the capabilities of 2to3. you will probably have to wait for the py2exe\n
      project to release a python 3 compatible version.\n
    - i''d prefer'something''.decode(...) since the unicode type is no longer\n
      there in python 3.0, while text = b''binarydata''.decode(encoding) is still valid.\n
    - A_Body "it's easy to benchmark it  from timeit import timer  ts = timer(\"s.decode('utf-8')\"\\n
      , \"s =\xE3\xA9\xE3\xA9\xE3\xA9'\")  ts.timeit() 8.9185450077056885  tu = timer(\"\\n
      unicode(s,utf-8')\", \"s =\xE3\xA9\xE3\xA9\xE3\xA9'\")  tu.timeit() 2.7656929492950439\\n
     obviously, unicode() is faster. fwiw, i don't know where you get the impression\\n
      that methods would be faster - it's quite the contrary. "\n
    - i can''t find anything that''s a clone of numpy, but there''s a long list\n
      of java numerics packages here - these should all be usable from jython. which\n
      one meets your requirements depends on what you''re doing with numpy, i guess.\n
    - it''s not possible afaik... which is a pity. basically, elementtree modules\n
      assume that the reader is 100% xml compliant, so it shouldn''t matter if they\n
      output a section as cdata or some other format that generates the equivalent text.\n
      see this thread on the python mailing list for more info. basically, they recommend\n
      some kind of dom-based xml library instead.\n
    - michael foord, aka voidspace has an excellent tutorial on urllib2 which\n
      you can find here urllib2 - the missing manual what you are doing should be pretty\n
      straightforward, observe this sample code import urllib2 import re response =\n
      urllib2.urlopen(" html = response.read() pattern ='(v.+space)'' wordpattern\n
      re.compile(pattern, re.ignorecase) results = wordpattern.search(html) print\n
      results.groups()\n
    - lxml has support for cdata and api like elementtree.\n
    - after a bit of work, i found the answer myself. looking at the elementtree.py\n
      source code, i found there was special handling of xml comments and preprocessing\n
      instructions. what they do is create a factory function for the special element\n
      type that uses a special (non-string) tag value to differentiate it from regular\n
      elements. def comment(text=none) element = element(comment) element.text = text\n
      return element then in the _write function of elementtree that actually outputs\n
      the xml, there''s a special case handling for comments if tag is comment file.write("!--\n
      %s --" % _escape_cdata(node.text, encoding)) in order to support cdata sections,\n
      i create a factory function called cdata, extended the elementtree class and changed\n
      the _write function to handle the cdata elements. this still doesn''t help if\n
      you want to parse an xml with cdata sections and then output it again with the\n
      cdata sections, but it at least allows you to create xmls with cdata sections\n
      programmatically, which is what i needed to do. the implementation seems to work\n
      with both elementtree and celementtree. import elementtree.elementtree as etree\n
      #~ import celementtree as etree def cdata(text=none) element = etree.element(cdata)\n
      element.text = text return element class elementtreecdata(etree.elementtree)\n
      def _write(self, file, node, encoding, namespaces) if node.tag is cdata text\n
      node.text.encode(encoding) file.write("\n![cdata[%s]]\n" % text) else etree.elementtree._write(self,\n
      file, node, encoding, namespaces) if __name__ == "__main__" import sys text =\n
      """ ?xml version=''1.0'' encoding=''utf-8''? text this is just some sample text.\n
      text """ e = etree.element("data") cdata = cdata(text) e.append(cdata) et = elementtreecdata(e)\n
      et.write(sys.stdout, "utf-8")\n
    - actually this code has a bug, since you don''t catch ]] appearing in the\n
      data you are inserting as cdata as per is there a way to escape a cdata end token\n
      in xml? you should break it into two cdata''s in that case, splitting the ]] between\n
      the two. basically data = data.replace("]]", "]]]]![cdata[") (not necessarily\n
      correct, please verify)\n
    - the dom has (atleast in level 2) an interface datasection, and an operation\n
      documentcreatecdatasection. they are extension interfaces, supported only if\n
      an implementation supports the "xml" feature. from xml.dom import minidom my_xmldoc=minidom.parse(xmlfile)\n
      my_xmldoc.createcdatasection(data) now u have cadata node add it wherever u want....\n
    - from the doc file.read() (my emphasis) file.read([size]) read at most\n
      size bytes from the file (less if the read hits eof before obtaining size bytes).\n
      if the size argument is negative or omitted, read all data until eof is reached.\n
      the bytes are returned as a string object. an empty string is returned when eof\n
      is encountered immediately. (for certain files, like ttys, it makes sense to continue\n
      reading after an eof is hit.) note that this method may call the underlying c\n
      function fread more than once in an effort to acquire as close to size bytes as\n
      possible. also note that when in non-blocking mode, less data than was requested\n
      may be returned, even if no size parameter was given. be aware that a regexp search\n
      on a large string object may not be efficient, and consider doing the search line-by-line,\n
      using file.next() (a file object is its own iterator).\n
    - you can use python in interactive mode to search for solutions. if f is\n
      your object, you can enter dir(f) to see all methods and attributes. there''s\n
      one called read. enter help(f.read) and it tells you that f.read() is the way\n
      to retrieve a string from an file object.\n
    - what about using logging.disable? i''ve also found i had to use logging.isenabledfor\n
      if the logging message is expensive to create.\n
    - i''d use some fancy logging decorator, or a bunch of them def dologging(logtreshold)\n
      def logfunction(afunc) def innerfunc(*args, **kwargs) if loglevel = logtreshold\n
      print "called %s at %s"%(afunc.__name__, time.strftime("%h%m%s")) print "parameters\n
      ", args, kwargs if kwargs else "" try return afunc(*args, **kwargs) finally\n
      print "%s took %s"%(afunc.__name__, time.strftime("%h%m%s")) return innerfunc\n
      return logfunction all you need is to declare loglevel constant in each module\n
      (or just globally and just import it in all modules) and then you can use it like\n
      this (2.5) def mypreciousfunction(one, two, three=4) print "i''m doing some\n
      fancy computations -)" return and if loglevel is no less than 2.5 you''ll get\n
      output like this called mypreciousfunction at 184913 parameters (1, 2) i''m\n
      doing some fancy computations -) mypreciousfunction took 184913 as you can\n
      see, some work is needed for better handling of kwargs, so the default values\n
      will be printed if they are present, but that''s another question. you should\n
      probably use some logger module instead of raw print statements, but i wanted\n
      to focus on the decorator idea and avoid making code too long. anyway - with such\n
      decorator you get function-level logging, arbitrarily many log levels, ease of\n
      application to new function, and to disable logging you only need to set loglevel.\n
      and you can define different output streamsfiles for each function if you wish.\n
      you can write dologging as def dologging(logthreshold, outstream=sys.stdout)\n
      ..... print outstream, "called %s at %s" etc. and utilize log files defined on\n
      a per-function basis.\n
    - you could try something like this # create something that accepts anything\n
      class fake(object) def __getattr__(self, key) return self def __call__(self,\n
      *args, **kwargs) return true # replace the logging module import sys sys.modules["logging"]\n
      fake() it essentially replaces (or initially fills in) the space for the logging\n
      module with an instance of fake which simply takes in anything. you must run the\n
      above code (just once!) before the logging module is attempted to be used anywhere.\n
      here is a test import logging logging.basicconfig(level=logging.debug, format=''%(asctime)s\n
      %(levelname)-8s %(message)s'', datefmt=''%a, %d %b %y %h%m%s'', filename=''tempmyapp.log'',\n
      filemode=''w'') logging.debug(''a debug message'') logging.info(''some information'')\n
      logging.warning(''a shot across the bows'') with the above, nothing at all was\n
      logged, as was to be expected.\n
    - as an imperfect shortcut, how about mocking out logging in specific modules\n
      using something like minimock? for example, if my_module.py was import logging\n
      class c(object) def __init__(self, *args, **kw) logging.info("instantiating")\n
      you would replace your use of my_module with from minimock import mock import\n
      my_module my_module.logging = mock(''logging'') c = my_module.c() you''d only\n
      have to do this once, before the initial import of the module. getting the level\n
      specific behaviour would be simple enough by mocking specific methods, or having\n
      logging.getlogger return a mock object with some methods impotent and others delegating\n
      to the real logging module. in practice, you''d probably want to replace minimock\n
      with something simpler and faster; at the very least something which doesn''t\n
      print usage to stdout! of course, this doesn''t handle the problem of module a\n
      importing logging from module b (and hence a also importing the log granularity\n
      of b)... this will never be as fast as not running the log statements at all,\n
      but should be much faster than going all the way into the depths of the logging\n
      module only to discover this record shouldn''t be logged after all.\n
    - you can use the chilkat library. it''s commercial, but has a free evaluation\n
      and seems pretty nice. here''s an example i got from here import chilkat # demonstrates\n
      how to create a winzip-compatible 128-bit aes strong encrypted zip zip = chilkat.ckzip()\n
      zip.unlockcomponent("anything for 30-day trial") zip.newzip("strongencrypted.zip")\n
      # set the encryption property = 4, which indicates winzip compatible aes encryption.\n
      zip.put_encryption(4) # the key length can be 128, 192, or 256. zip.put_encryptkeylength(128)\n
      zip.setpassword("secret") zip.appendfiles("exampledata*",true) zip.writezip()\n
    - the solution used in twisted, which doesn''t need pywin32 def isvista()\n
      if getattr(sys, "getwindowsversion", none) is not none return sys.getwindowsversion()[0]\n
      == 6 else return false note that it will also match windows server 2008.\n
    - the simplest solution i found is this one import sys def iswindowsvista()\n
     '''''return true iff current os is windows vista.'''''' if sys.platform != "win32"\n
      return false import win32api ver_nt_workstation = 1 version = win32api.getversionex(1)\n
      if not version or len(version)  9 return false return ((version[0] == 6) and\n
      (version[1] == 0) and (version[8] == ver_nt_workstation))\n
    - python has the lovely'platform'' module to help you out.  import platform  platform.win32_ver()\n
      (''xp'','5.1.2600'','sp2'','multiprocessor free'')  platform.system()'windows''  platform.version()\n
     '5.1.2600''  platform.release()'xp'' note as mentioned in the comments proper\n
      values may not be returned when using older versions of python.\n
    - it looks a lot like you''re trying to use a list as a database. nowadays\n
      python includes sqlite bindings in the core distribution. if you don''t need persistence,\n
      it''s really easy to create an in-memory sqlite database (see then you can use\n
      sql statements to do all this sorting and filtering without having to reinvent\n
      the wheel.\n
    - if you''ll be doing a lot of sorting and filtering, you may like some helper\n
      functions. m = [ [''4'','21'','1'','14'','2008-10-24 154258''], [''3'',\n
     '22'','4'','2somename'','2008-10-24 152203''], [''5'','21'','3'',\n
     '19'','2008-10-24 154545''], [''6'','21'','1'','1somename'','2008-10-24\n
      154549''], [''7'','22'','3'','2somename'','2008-10-24 154551''] ]\n
      # sort and filter helpers. sort_on = lambda pos lambda x x[pos] filter_on =\n
      lambda pos,val lambda l l[pos] == val # sort by second column m = sorted(m,\n
      key=sort_on(1)) # filter on 4th column, where value ='2somename'' m = filter(filter_on(3,''2somename''),m)\n
    -  use a function to reorder the list so that i can group by each item in\n
      the list. for example i''d like to be able to group by the second column (so that\n
      all the 21''s are together) lists have a built in sort method and you can provide\n
      a function that extracts the sort key.  import pprint  l.sort(key = lambda ll\n
      ll[1])  pprint.pprint(l) [[''4'','21'','1'','14'','2008-10-24 154258''],\n
      [''5'','21'','3'','19'','2008-10-24 154545''], [''6'','21'','1'',\n
     '1somename'','2008-10-24 154549''], [''3'','22'','4'','2somename'',\n
     '2008-10-24 152203''], [''7'','22'','3'','2somename'','2008-10-24 154551'']]\n
      use a function to only display certain values from each inner list. for example\n
      i''d like to reduce this list to only contain the 4th field value of'2somename''\n
      this looks like a job for list comprehensions  [ll[3] for ll in l] [''14'','2somename'',\n
     '19'','1somename'','2somename'']\n
    - if you assigned it to var "a"... #1 a.sort(lambda x,y cmp(x[1], y[1]))\n
      #2 filter(lambda x x[3]=="2somename", a)\n
    - if i understand your question correctly, the following code should do the\n
      job l = [ [''4'','21'','1'','14'','2008-10-24 154258''], [''3'','22'',\n
     '4'','2somename'','2008-10-24 152203''], [''5'','21'','3'','19'',\n
     '2008-10-24 154545''], [''6'','21'','1'','1somename'','2008-10-24 154549''],\n
      [''7'','22'','3'','2somename'','2008-10-24 154551''] ] def comparefield(field)\n
      def c(l1,l2) return cmp(l1[field], l2[field]) return c # use comparefield(1)\n
      as the ordering criterion, i.e. sort only with # respect to the 2nd field l.sort(comparefield(1))\n
      for row in l print row print # select only those sublists for which 4th field==''2somename''\n
      l2somename = [row for row in l if row[3]==''2somename''] for row in l2somename\n
      print row output [''4'','21'','1'','14'','2008-10-24 154258''] [''5'',\n
     '21'','3'','19'','2008-10-24 154545''] [''6'','21'','1'','1somename'',\n
     '2008-10-24 154549''] [''3'','22'','4'','2somename'','2008-10-24 152203'']\n
      [''7'','22'','3'','2somename'','2008-10-24 154551''] [''3'','22'',\n
     '4'','2somename'','2008-10-24 152203''] [''7'','22'','3'','2somename'',\n
     '2008-10-24 154551'']\n
    - for part (2), with x being your array, i think you want, [y for y in x\n
      if y[3] =='2somename''] which will return a list of just your data lists that\n
      have a fourth value being'2somename''... although it seems kamil is giving you\n
      the best advice with going for sql...\n
    - you''re simply creating indexes on your structure, right?  from collections\n
      import defaultdict  def indexon( things, pos ) ... inx= defaultdict(list) ...\n
      for t in things ... inx[t[pos]].append(t) ... return inx ...  a=[ ... [''4'',\n
     '21'','1'','14'','2008-10-24 154258''], ... [''3'','22'','4'','2somename'',\n
     '2008-10-24 152203''], ... [''5'','21'','3'','19'','2008-10-24 154545''],\n
      ... [''6'','21'','1'','1somename'','2008-10-24 154549''], ... [''7'',\n
     '22'','3'','2somename'','2008-10-24 154551''] ... ] here''s your first\n
      request, grouped by position 1.  import pprint  pprint.pprint( dict(indexon(a,1))\n
      ) {''21'' [[''4'','21'','1'','14'','2008-10-24 154258''], [''5'','21'',\n
     '3'','19'','2008-10-24 154545''], [''6'','21'','1'','1somename'',\n
     '2008-10-24 154549'']],'22'' [[''3'','22'','4'','2somename'','2008-10-24\n
      152203''], [''7'','22'','3'','2somename'','2008-10-24 154551'']]}\n
      here''s your second request, grouped by position 3.  dict(indexon(a,3)) {''19''\n
      [[''5'','21'','3'','19'','2008-10-24 154545'']],'14'' [[''4'','21'',\n
     '1'','14'','2008-10-24 154258'']],'2somename'' [[''3'','22'','4'',\n
     '2somename'','2008-10-24 152203''], [''7'','22'','3'','2somename'',\n
     '2008-10-24 154551'']],'1somename'' [[''6'','21'','1'','1somename'',\n
     '2008-10-24 154549'']]}  pprint.pprint(_) {''14'' [[''4'','21'','1'',\n
     '14'','2008-10-24 154258'']],'19'' [[''5'','21'','3'','19'','2008-10-24\n
      154545'']],'1somename'' [[''6'','21'','1'','1somename'','2008-10-24\n
      154549'']],'2somename'' [[''3'','22'','4'','2somename'','2008-10-24\n
      152203''], [''7'','22'','3'','2somename'','2008-10-24 154551'']]}\n
    - for the first question, the first thing you should do is sort the list\n
      by the second field x = [ [''4'','21'','1'','14'','2008-10-24 154258''],\n
      [''3'','22'','4'','2somename'','2008-10-24 152203''], [''5'','21'',\n
     '3'','19'','2008-10-24 154545''], [''6'','21'','1'','1somename'',\n
     '2008-10-24 154549''], [''7'','22'','3'','2somename'','2008-10-24 154551'']\n
      ] from operator import itemgetter x.sort(key=itemgetter(1)) then you can use itertools''\n
      groupby function from itertools import groupby y = groupby(x, itemgetter(1))\n
      now y is an iterator containing tuples of (element, item iterator). it''s more\n
      confusing to explain these tuples than it is to show code for elt, items in groupby(x,\n
      itemgetter(1)) print(elt, items) for i in items print(i) which prints 21 itertools._grouper\n
      object at 0x511a0 [''4'','21'','1'','14'','2008-10-24 154258''] [''5'',\n
     '21'','3'','19'','2008-10-24 154545''] [''6'','21'','1'','1somename'',\n
     '2008-10-24 154549''] 22 itertools._grouper object at 0x51170 [''3'','22'',\n
     '4'','2somename'','2008-10-24 152203''] [''7'','22'','3'','2somename'',\n
     '2008-10-24 154551''] for the second part, you should use list comprehensions\n
      as mentioned already here from pprint import pprint as pp pp([y for y in x if\n
      y[3] =='2somename'']) which prints [[''3'','22'','4'','2somename'','2008-10-24\n
      152203''], [''7'','22'','3'','2somename'','2008-10-24 154551'']]\n
    - it seems the question could be more precisely stated as "how to convert\n
      html to xml so that xpath expressions can be evaluated against it". here are two\n
      good tools tagsoup, an open-source program, is a java and sax - based tool, developed\n
      by john cowan. this is a sax-compliant parser written in java that, instead of\n
      parsing well-formed or valid xml, parses html as it is found in the wild poor,\n
      nasty and brutish, though quite often far from short. tagsoup is designed for\n
      people who have to process this stuff using some semblance of a rational application\n
      design. by providing a sax interface, it allows standard xml tools to be applied\n
      to even the worst html. tagsoup also includes a command-line processor that reads\n
      html files and can generate either clean html or well-formed xml that is a close\n
      approximation to xhtml. taggle is a commercial c++ port of tagsoup. sgmlreader\n
      is a tool developed by microsoft''s chris lovett. sgmlreader is an xmlreader api\n
      over any sgml document (including built in support for html). a command line utility\n
      is also provided which outputs the well formed xml result. download the zip file\n
      including the standalone executable and the full source code sgmlreader.zip\n
    - an outstanding achievement is the pure xslt 2.0 parser of html written\n
      by david carlisle. reading its code would be a great learning exercise for everyone\n
      of us. from the description "dhtmlparse(string) &nbsp;dhtmlparse(string,namespace,html-mode)\n
      &nbsp;&nbsp;the one argument form is equivalent to) &nbsp;&nbsp;dhtmlparse(string,''\n
      &nbsp;&nbsp;parses the string as html andor xml using some inbuilt heuristics\n
      to) &nbsp;&nbsp;control implied opening and closing of elements. &nbsp;&nbsp;it\n
      doesn''t have full knowledge of html dtd but does have full list of &nbsp;&nbsp;empty\n
      elements and full list of entity definitions. html entities, and &nbsp;&nbsp;decimal\n
      and hex character references are all accepted. note html-entities &nbsp;&nbsp;are\n
      recognised even if html-mode=false(). &nbsp;&nbsp;element names are lowercased\n
      (if html-mode is true()) and placed into the &nbsp;&nbsp;namespace specified by\n
      the namespace parameter (which may be "" to denote &nbsp;&nbsp;no-namespace unless\n
      the input has explict namespace declarations, in &nbsp;&nbsp;which case these\n
      will be honoured. &nbsp;&nbsp;attribute names are lowercased if html-mode=true()"\n
      read a more detailed description here. hope this helped. cheers, dimitre novatchev.\n
    - for ruby, i highly recommend hpricot that jb evain pointed out. if you''re\n
      looking for a faster libxml-based competitor, nokogiri (see is pretty good too\n
      (it supports both xpath and css searches like hpricot but is faster). there''s\n
      a basic wiki and some benchmarks.\n
    - there is a free c implementation for xml called libxml2 which has some\n
      api bits for xpath which i have used with great success which you can specify\n
      html as the document being loaded. this had worked for me for some less than perfect\n
      html documents.. for the most part, xpath is most useful when the inbound html\n
      is properly coded and can be read'like an xml document''. you may want to consider\n
      using a utility that is specific to this purpose for cleaning up html documents.\n
      here is one example as far as these xpath tools go- you will likely find that\n
      most implementations are actually based on pre-existing c or c++ libraries such\n
      as libxml2.\n
    - in python, elementtidy parses tag soup and produces an element tree, which\n
      allows querying using xpath  from elementtidy.tidyhtmltreebuilder import tidyhtmltreebuilder\n
      as tb  tb = tb()  tb.feed("phello world")  e= tb.close()  e.find(".{ element\n
      { at 264eb8\n
    - beautifulsoup is a good python library for dealing with messy html in clean\n
      ways.\n
    - you should not rely the security of the application on the framework. even\n
      though django does come in with a pretty good number of measures against classical\n
      security issues, it can not guarantee that your application will be secure, you\n
      need much more than a programming framework to get a security critical application.\n
      i''d say yes, django is a good choice as long as you know its powers and limitations\n
      and are aware of the security flaws of every application.\n
    - i think it might be easier to do this with a custom auth backend and thus\n
      remove the need for a customized modeladmin. i did something similar with this\n
      snippet\n
    - the reasons for building banking apps in java are not related to security,\n
      at least imho. they are related to java is the cobol of the 21st century, so\n
      there is a lot of legacy code that would have to be rewritten and that takes time.\n
      basically banking apps are old apps, they were built in java some ten years ago\n
      and nobody wants to throw all the old code away (which btw is almost always a\n
      bad decision), some people believe that a static typed language is somewhat "safer"\n
      than the dynamic typed language. this is, imho, not true (take for instance collections\n
      prior to java 5).\n
    - are you referring to the fact that the complete application is built in\n
      java, or just the part you see in your browser? if the latter, the reason is probably\n
      because in the context of webpages, java applets can be downloaded and run.\n
    - if you need to use something similar to the {% url %} template tag in your\n
      code, django provides the django.core.urlresolvers.reverse(). the reverse function\n
      has the following signature reverse(viewname, urlconf=none, args=none, kwargs=none)\n
    - none of the above. just use admin.site.unregister(). here''s how i recently\n
      added filtering users on is_active in the admin (n.b. is_active filtering is now\n
      on the user model by default in django core; still works here as an example),\n
      all dry as can be from django.contrib import admin from django.contrib.auth.admin\n
      import useradmin from django.contrib.auth.models import user class myuseradmin(useradmin)\n
      list_filter = useradmin.list_filter + (''is_active'',) admin.site.unregister(user)\n
      admin.site.register(user, myuseradmin)\n
    - i''m using two different approaches in my models.py. the first is the permalink\n
      decorator from django.db.models import permalink def get_absolute_url(self)\n
      """construct the absolute url for this item.""" return (''project.app.views.view_name'',\n
      [str(self.id)]) get_absolute_url = permalink(get_absolute_url) you can also call\n
      reverse directly from django.core.urlresolvers import reverse def get_absolute_url(self)\n
      """construct the absolute url for this item.""" return reverse(''project.app.views.view_name'',\n
      none, [str(self.id)])\n
    - i find your connection between java and banking wrong ended. most banking\n
      software has terrible security. and much banking software is written in java.\n
      does ths mean java makes it more difficult to write secure software than other\n
      languages? probably it''s not java''s fault that there is so little quality security\n
      (and safety) wise in banking software. actually, like the other posters mention,\n
      the choice of your language usually has very little consequences for your security\n
       unless you select one of the few languages where only hotshot coders can write\n
      secure code in (c and php come to mind). many huge e-commerce sites are written\n
      in python, ruby and perl using various frameworks. and i would argue that the\n
      security requirements for merchants are much higher than the requirements of the\n
      banking industry. that is because merchants have to provide security and good\n
      user experience, while banking customers are willing to put up with unusable interfaces\n
      secureid tokens and whatever. so yes django is up to the task.\n
    - be aware that using reverse() requires that your urlconf module is 100%\n
      error free and can be processed - iow no viewdoesnotexist errors or so, or you\n
      get the dreaded noreversematch exception (errors in templates usually fail silently\n
      resulting in none).\n
    - probably the reason behind java is not in the in the security. i think\n
      java is more used in large development companies and banks usually resort to them\n
      for their development needs (which probably are not only related to the web site\n
      but creep deeper in the backend). so, i see no security reasons, mostly cultural\n
      ones.\n
    - actually, the security in java and python is the same. digest-only password\n
      handling, cookies that timeout rapidly, careful deletion of sessions, multi-factor\n
      authentication. none of this is unique to a java framework or a python framework\n
      like django. django, indeed, has a security backend architecture that allows you\n
      to add your own ldap (or ad) connection, possibly changing the digest technique\n
      used. django has a profile model where you can keep additional authentication\n
      factors. django offers a few standard decorators for view function authorization\n
      checking. since python is so flexible, you can trivially write your own decorator\n
      functions to layer in different or additional authentication checking. security\n
      is a number of first-class features in django.\n
    - to clamp numpy array values  c = a + b  c[c  256] = 256\n
    - as everyone suggested already, the weird colors you''re observing are overflow.\n
      and as you point out in the comment of schnaader''s answer you still get overflow\n
      if you add your images like this addition=(im1arr+im2arr)2 the reason for this\n
      overflow is that your numpy arrays (im1arr im2arr) are of the uint8 type (i.e.\n
      8-bit). this means each element of the array can only hold values up to 255, so\n
      when your sum exceeds 255, it loops back around 0 array([255,10,100],dtype=''uint8'')\n
      + array([1,10,160],dtype=''uint8'') array([ 0, 20, 4], dtype=uint8) to avoid overflow,\n
      your arrays should be able to contain values beyond 255. you need to convert them\n
      to floats for instance, perform the blending operation and convert the result\n
      back to uint8 im1arrf = im1arr.astype(''float'') im2arrf = im2arr.astype(''float'')\n
      additionf = (im1arrf+im2arrf)2 addition = additionf.astype(''uint8'') you should\n
      not do this addition = im1arr2 + im2arr2 as you lose information, by squashing\n
      the dynamic of the image (you effectively make the images 7-bit) before you perform\n
      the blending information. matlab note the reason you don''t see this problem\n
      in matlab, is probably because matlab takes care of the overflow implicitly in\n
      one of its functions.\n
    - using pil''s blend() with an alpha value of 0.5 would be equivalent to\n
      (im1arr + im2arr)2. blend does not require that the images have alpha layers.\n
      try this from pil import image im1 = image.open(''usersrem7desktop_1.jpg'')\n
      im2 = image.open(''usersrem7desktop_2.jpg'') image.blend(im1,im2,0.5).save(''usersrem7desktopa.jpg'')\n
    - possibly the most popular usage is operator.itemgetter. given a list lst\n
      of tuples, you can sort by the ith element by lst.sort(key=operator.itemgetter(i))\n
      certainly, you could do the same thing without operator by defining your own key\n
      function, but the operator module makes it slightly neater. as to the rest, python\n
      allows a functional style of programming, and so it can come up -- for instance,\n
      greg''s reduce example. you might argue "why do i need operator.add when i can\n
      just do add = lambda x, y x+y?" the answers are operator.add is (i think) slightly\n
      faster. it makes the code easier to understand for you, or another person later,\n
      looking at it. they don''t need to look for the definition of add, because they\n
      know what the operator module does.\n
    - one example is in the use of the reduce() function  import operator  a\n
      [2, 3, 4, 5]  reduce(lambda x, y x + y, a) 14  reduce(operator.add, a) 14\n
    - it seems the code you posted just sums up the values and values bigger\n
      than 256 are overflowing. you want something like "(a + b)  2" or "min(a + b,\n
      256)". the latter seems to be the way that your matlab example does it.\n
    - your sample images are not showing up form me so i am going to do a bit\n
      of guessing. i can''t remember exactly how the numpy to pil conversion works but\n
      there are two likely cases. i am 95% sure it is 1 but am giving 2 just in case\n
      i am wrong. 1) 1 im1arr is a mxn array of integers (argb) and when you add im1arr\n
      and im2arr together you are overflowing from one channel into the next if the\n
      components b1+b2>255. i am guessing matlab represents their images as mxnx3 arrays\n
      so each color channel is separate. you can solve this by splitting the pil image\n
      channels and then making numpy arrays 2) 1 im1arr is a mxnx3 array of bytes and\n
      when you add im1arr and im2arr together you are wrapping the component around.\n
      you are also going to have to rescale the range back to between 0-255 before displaying.\n
      your choices are divide by 2, scale by 255array.max() or do a clip. i don''t\n
      know what matlab does\n
    - A_Body "i think you can shave off a few method calls if you do it like this  from\\n
      datetime import datetime  datetime.now(pytz.timezone(\"australiamelbourne\"\\n
      )) \\ .replace(hour=0, minute=0, second=0, microsecond=0) \\ .astimezone(pytz.utc)\\n
      but\xE2\x80\xA6 there is a bigger problem than aesthetics in your code it will\\n
      give the wrong result on the day of the switch to or from daylight saving time.\\n
      the reason for this is that neither the datetime constructors nor replace()\\n
      take dst changes into account. for example  now = datetime(2012, 4, 1, 5, 0,\\n
      0, 0, tzinfo=pytz.timezone(\"australiamelbourne\"))  print now 2012-04-01 050000+1000\\n
     print now.replace(hour=0) 2012-04-01 000000+1000 # wrong! midnight was at\\n
      2012-04-01 000000+1100  print datetime(2012, 3, 1, 0, 0, 0, 0, tzinfo=tz)\\n
      2012-03-01 000000+1000 # wrong again! however, the documentation for tz.localize()\\n
      states this method should be used to construct localtimes, rather than passing\\n
      a tzinfo argument to a datetime constructor. thus, your problem is solved like\\n
      so  import pytz  from datetime import datetime, date, time  tz = pytz.timezone(\"\\n
      australiamelbourne\")  the_date = date(2012, 4, 1) # use date.today() here  midnight_without_tzinfo\\n
      datetime.combine(the_date, time())  print midnight_without_tzinfo 2012-04-01\\n
      000000  midnight_with_tzinfo = tz.localize(midnight_without_tzinfo)  print\\n
      midnight_with_tzinfo 2012-04-01 000000+1100  print midnight_with_tzinfo.astimezone(pytz.utc)\\n
      2012-03-31 130000+0000 no guarantees for dates before 1582, though. "\n
    - setting the tz environment variable modifies what timezone python''s date\n
      and time functions work with.  time.gmtime() (2008, 12, 17, 1, 16, 46, 2, 352,\n
      0)  time.localtime() (2008, 12, 16, 20, 16, 47, 1, 351, 0)  os.environ[''tz'']=''australiamelbourne''  time.localtime()\n
      (2008, 12, 17, 12, 16, 53, 2, 352, 1)\n
    - each time zone has a number, eg uscentral = -6. this is defined as the\n
      offset in hours from utc. since 0000 is midnight, you can simply use this offset\n
      to find the time in any time zone when it is midnight utc. to access that, i believe\n
      you can use time.timezone according to the python docs, time.timezone actually\n
      gives the negative value of this number time.timezone the offset of the local\n
      (non-dst) timezone, in seconds west of utc (negative in most of western europe,\n
      positive in the us, zero in the uk). so you would simply use that number for the\n
      time in hours if it''s positive (i.e., if it''s midnight in chicago (which has\n
      a +6 timezone value), then it''s 6000 = 6am utc). if the number is negative, subtract\n
      from 24. for example, berlin would give -1, so 24 - 1 => 2300 = 11pm.\n
    - the given answers fail to take into account that the wrapped function may\n
      raise an exception. in that case, the directory will never be restored. the code\n
      below adds exception handling to the previous answers. as a decorator def preserve_cwd(function)\n
      .wraps(function) def decorator(*args, **kwargs) cwd = os.getcwd() try return\n
      function(*args, **kwargs) finally os.chdir(cwd) return decorator and as a context\n
      manager .contextmanager def remember_cwd() curdir = os.getcwd() try yield finally\n
      os.chdir(curdir)\n
    - A_Body "the answer for a decorator has been given; it works at the function definition\\n
      stage as requested. with python 2.5+, you also have an option to do that at\\n
      the function call stage using a context manager from __future__ import with_statement\\n
      # needed for 2.5 \xE2\x89\xA4 python  2.6 import contextlib, os .contextmanager\\n
      def remember_cwd() curdir= os.getcwd() try yield finally os.chdir(curdir)\\n
      which can be used if needed at the function call time as print \"getcwd before\"\\n
      , os.getcwd() with remember_cwd() walk_around_the_filesystem() print \"getcwd\\n
      after\", os.getcwd() it's a nice option to have. edit i added error handling\\n
      as suggested by codeape. since my answer has been voted up, it's fair to offer\\n
      a complete answer, all other issues aside. "\n
    - def preserve_cwd(function) def decorator(*args, **kwargs) cwd = os.getcwd()\n
      result = function(*args, **kwargs) os.chdir(cwd) return result return decorator\n
      here''s how it''s used def test() print'was'',os.getcwd() os.chdir('''')\n
      print'now'',os.getcwd()  print os.getcwd() usersdspitzer  test() was usersdspitzer\n
      now   print os.getcwd() usersdspitzer\n
    - check your jython sys.path . make sure that the library you want to load\n
      are in this path. look at jython faq for more details.\n
    - you embed jython and you will use some python-modules somewere if you\n
      want to set the path (sys.path) in your java-code  public void init() { interp\n
      new pythoninterpreter(null, new pysystemstate()); pysystemstate sys = py.getsystemstate();\n
      sys.path.append(new pystring(rootpath)); sys.path.append(new pystring(modulesdir));\n
      } py is in org.python.core. rootpath and modulesdir is where you want ! let rootpath\n
      point where you located the standard-jython-lib have a look at srcorgpythonutilpyservlet.java\n
      in the jython-source-code for example\n
    - just wanted to point out that you can still achieve fine-grained testing\n
      while verifying the results you can test individual chunks of code by nesting\n
      them inside some setup and verification code int x = 0; generated_code assert(x\n
      == 100); provided you have your generated code assembled from smaller chunks,\n
      and the chunks do not change frequently, you can exercise more conditions and\n
      test a little better, and hopefully avoid having all your tests break when you\n
      change specifics of one chunk.\n
    - yes, results are the only thing that matters. the real chore is writing\n
      a framework that allows your generated code to run independently... spend your\n
      time there.\n
    - recall that "unit testing" is only one kind of testing. you should be able\n
      to unit test the internal pieces of your code generator. what you''re really looking\n
      at here is system level testing (a.k.a. regression testing). it''s not just semantics...\n
      there are different mindsets, approaches, expectations, etc. it''s certainly more\n
      work, but you probably need to bite the bullet and set up an end-to-end regression\n
      test suite fixed c++ files -> swig interfaces -> python modules -> known output.\n
      you really want to check the known input (fixed c++ code) against expected output\n
      (what comes out of the final python program). checking the code generator results\n
      directly would be like diffing object files...\n
    - if you are running on *nux you might consider dumping the unittest framework\n
      in favor of a bash script or makefile. on windows you might consider building\n
      a shell appfunction that runs the generator and then uses the code (as another\n
      process) and unittest that. a third option would be to generate the code and then\n
      build an app from it that includes nothing but a unittest. again you would need\n
      a shell script or whatnot to run this for each input. as to how to encode the\n
      expected behavior, it occurs to me that it could be done in much the same way\n
      as you would for the c++ code just using the generated interface rather than the\n
      c++ one.\n
    - according to the faq 4.1 what parts of the python library are supported?\n
      the good news is that jython now supports a large majority of the standard python\n
      library. the bad news is that this has moved so rapidly, it''s hard to keep the\n
      documentation up to date. built-in modules (e.g. those that are written in c for\n
      cpython) are a different story. these would have to be ported to java, or implemented\n
      with a jni bridge in order to be used by jython. some built-in modules have been\n
      ported to jpython, most notably cstringio, cpickle, struct, and binascii. it is\n
      unlikely that jni modules will be included in jython proper though. if you want\n
      to use a standard python module, just try importing it. if that works, you''re\n
      probably all set. you can also do a dir() on the modules to check the list of\n
      functions it implements. if there is some standard python module that you have\n
      a real need for that doesn''t work with jython yet, please send us mail. in other\n
      words, you can directly use python modules from jython, unless you''re trying\n
      to use built-in modules, in which case you''re stuck with whatever has been ported\n
      to jython.\n
    - i started writing up a summary of my experience with my own code generator,\n
      then went back and re-read your question and found you had already touched upon\n
      the same issues yourself, focus on the execution results instead of the code layoutlook.\n
      problem is, this is hard to test, the generated code might not be suited to actually\n
      run in the environment of the unit test system, and how do you encode the expected\n
      results? i''ve found that you need to break down the code generator into smaller\n
      pieces and unit test those. unit testing a full code generator is more like integration\n
      testing than unit testing if you ask me.\n
    - A_Body "you can convert the file easily enough just using the unicode function,\\n
      but you'll run into problems with unicode characters without a straight ascii\\n
      equivalent. this blog recommends the unicodedata module, which seems to take\\n
      care of roughly converting characters without direct corresponding ascii values,\\n
      e.g.  title = u\"kl\xE3\xBCft skr\xE3\xA4ms inf\xE3\xB6r p\xE3\xA5 f\xE3\xA9\\n
      d\xE3\xA9ral \xE3\xA9lectoral gro\xE3\x9Fe\" is typically converted to klft skrms\\n
      infr p fdral lectoral groe which is pretty wrong. however, using the unicodedata\\n
      module, the result can be much closer to the original text  import unicodedata\\n
     unicodedata.normalize('nfkd', title).encode('ascii','ignore')kluft skrams\\n
      infor pa federal electoral groe' "\n
    - here''s some simple (and stupid) code to do encoding translation. i''m\n
      assuming (but you shouldn''t) that the input file is in utf-16 (windows calls\n
      this simply'unicode''). input_codec ='utf-16'' output_codec ='ascii'' unicode_file\n
      open(''filename'') unicode_data = unicode_file.read().decode(input_codec) ascii_file\n
      open(''new filename'','w'') ascii_file.write(unicode_data.write(unicode_data.encode(output_codec)))\n
      note that this will not work if there are any characters in the unicode file that\n
      are not also ascii characters. you can do the following to turn unrecognized characters\n
      into'?''s ascii_file.write(unicode_data.write(unicode_data.encode(output_codec,\n
     'replace''))) check out the docs for more simple choices. if you need to do anything\n
      more sophisticated, you may wish to check out the unicode hammer at the python\n
      cookbook.\n
    - it''s important to note that there is no'unicode'' file format. unicode\n
      can be encoded to bytes in several different ways. most commonly utf-8 or utf-16.\n
      you''ll need to know which one your 3rd-party tool is outputting. once you know\n
      that, converting between different encodings is pretty easy in_file = open("myfile.txt",\n
      "rb") out_file = open("mynewfile.txt", "wb") in_byte_string = in_file.read() unicode_string\n
      bytestring.decode(''utf-16'') out_byte_string = unicode_string.encode(''ascii'')\n
      out_file.write(out_byte_string) out_file.close() as noted in the other replies,\n
      you''re probably going to want to supply an error handler to the encode method.\n
      using'replace'' as the error handler is simple, but will mangle your text if\n
      it contains characters that cannot be represented in ascii.\n
    - A_Body "i think this is a deeper issue than you realize. simply changing the file\\n
      from unicode into ascii is easy, however, getting all of the unicode characters\\n
      to translate into reasonable ascii counterparts (many letters are not available\\n
      in both encodings) is another. this python unicode tutorial may give you a better\\n
      idea of what happens to unicode strings that are translated to ascii here's\\n
      a useful quote from the site python 1.6 also gets a \"unicode\" built-in function,\\n
      to which you can specify the encoding   unicode('hello') u'hello'   unicode('hello',\\n
      \ascii') u'hello'   unicode('hello',iso-8859-1') u'hello'   all three of these\\n
      return the same thing, since the characters inhello' are common to all three\\n
      encodings. now let's encode something with a european accent, which is outside\\n
      of ascii. what you see at a console may depend on your operating system locale;\\n
      windows lets me type in iso-latin-1.   a = unicode('andr\xE3\xA9','latin-1')\\n
      a u'andr\\202' if you can't type an acute letter e, you can enter the string\\n
      \andr\\202', which is unambiguous. unicode supports all the common operations\\n
      such as iteration and splitting. we won't run over them here. "\n
    - like this uc = open(filename).read().decode(''utf8'') ascii = uc.decode(''ascii'')\n
      note, however, that this will fail with a unicodedecodeerror exception if there\n
      are any characters that can''t be converted to ascii. edit as pete karl just\n
      pointed out, there is no one-to-one mapping from unicode to ascii. so some characters\n
      simply can''t be converted in an information-preserving way. moreover, standard\n
      ascii is more or less a subset of utf-8, so you don''t really even need to do\n
      any decoding.\n
    -  locals() - no. globals() - yes. window is a reference to the global scope,\n
      like globals() in python. globals()["foo"] is the same as window["foo"]\n
    - try converting the exponent to a floating number, as the default behaviour\n
      of  in python is integer division n**(1float(3))\n
    - i seem to remember brendan eich commented on this in a recent podcast;\n
      if i recall correctly, it''s not being considered, as it adds unreasonable restrictions\n
      to optimization. he compared it to the arguments local in that, while useful for\n
      varargs, its very existence removes the ability to guess at what a function will\n
      touch just by looking at its definition. btw i believe js did have support for\n
      accessing locals through the arguments local at one time - a quick search shows\n
      this has been deprecated though.\n
    - -bartek, i think that window[functionname] won''t work if you in some closure,\n
      and the function name is local to that closure. for example function foo() {\n
      var bar = function () { alert(''hello world''); }; var s ='bar''; window[s]();\n
     this won''t work } in this case, s is'bar'', but the function'bar'' only\n
      exists inside the scope of the function'foo''. it is not defined in the window\n
      scope. of course, this doesn''t really answer the original question, i just wanted\n
      to chime in on this response. i don''t believe there is a way to do what the original\n
      question asked.\n
    -  yes, you''re right. window[functionname]() doesn''t work in this case,\n
      but eval does. if i needed something like this, i''d create my own object to keep\n
      those functions together. var func = {}; func.bar = ...; var s = "bar"; func[s]();\n
    - as far as i know there are no real bugs, but the performance when threading\n
      in cpython is really bad (compared to most other threading implementations, but\n
      usually good enough if all most of the threads do is block) due to the gil (global\n
      interpreter lock), so really it is implementation specific rather than language\n
      specific. jython, for example, does not suffer from this due to using the java\n
      thread model. see this post on why it is not really feasible to remove the gil\n
      from the cpython implementation, and this for some practical elaboration and workarounds.\n
      do a quick google for "python gil" for more information.\n
    - i''ve used it in several applications and have never had nor heard of threading\n
      being anything other than 100% reliable, as long as you know its limits. you can''t\n
      spawn 1000 threads at the same time and expect your program to run properly on\n
      windows, however you can easily write a worker pool and just feed it 1000 operations,\n
      and keep everything nice and under control.\n
    - gmpy is a c-coded python extension module that wraps the gmp library to\n
      provide to python code fast multiprecision arithmetic (integer, rational, and\n
      float), random number generation, advanced number-theoretical functions, and more.\n
      includes a root function x.root(n) returns a 2-element tuple (y,m), such that\n
      y is the (possibly truncated) n-th root of x; m, an ordinary python int, is 1\n
      if the root is exact (x==y**n), else 0. n must be an ordinary python int, >=0.\n
      for example, 20th root  import gmpy  i0=11968003966030964356885611480383408833172346450467339251  m0=gmpy.mpz(i0)  m0\n
      mpz(11968003966030964356885611480383408833172346450467339251l)  m0.root(20) (mpz(567),\n
      0)\n
    - python threads are good for concurrent io programming. threads are swapped\n
      out of the cpu as soon as they block waiting for input from file, network, etc.\n
      this allows other python threads to use the cpu while others wait. this would\n
      allow you to write a multi-threaded web server or web crawler, for example. however,\n
      python threads are serialized by the gil when they enter interpreter core. this\n
      means that if two threads are crunching numbers, only one can run at any given\n
      moment. it also means that you can''t take advantage of multi-core or multi-processor\n
      architectures. there are solutions like running multiple python interpreters concurrently,\n
      using a c based threading library. this is not for the faint of heart and the\n
      benefits might not be worth the trouble. let''s hope for an all python solution\n
      in a future release.\n
    - if you want to be clever tagdict.update(map(reversed, enumerate(tag)))\n
      thanks to brian for the update. this is apparently ~5% faster than the iterative\n
      version. (edit thanks saverio for pointing out my answer was incorrect (now fixed).\n
      probably the most efficientpythonic way would be torsten marek''s answer, slightly\n
      modified tagdict.update((t, i) for (i,t) in enumerate(tag)) )\n
    - it''s a one-liner tagdict = dict((t, i) for i, t in enumerate(tag))\n
    - in older versions of python, 13 is equal to 0. in python 3.0, 13 is equal\n
      to 0.33333333333 (and 13 is equal to 0). so, either change your code to use\n
      13.0 or switch to python 3.0 .\n
    - you actually want to do this for i, tag in enumerate(tag) tagdict[tag]\n
      i the .update() method is used for updating a dictionary using another dictionary,\n
      not for changing a single keyvalue pair.\n
    - you can make it run slightly faster by avoiding the while loops in favor\n
      of setting low to 10 ** (len(str(x))  n) and high to low * 10. probably better\n
      is to replace the len(str(x)) with the bitwise length and using a bit shift. based\n
      on my tests, i estimate a 5% speedup from the first and a 25% speedup from the\n
      second. if the ints are big enough, this might matter (and the speedups may vary).\n
      don''t trust my code without testing it carefully. i did some basic testing but\n
      may have missed an edge case. also, these speedups vary with the number chosen.\n
      if the actual data you''re using is much bigger than what you posted here, this\n
      change may be worthwhile. from timeit import timer def find_invpow(x,n) """finds\n
      the integer component of the n''th root of x, an integer such that y ** n = x  (y\n
      + 1) ** n. """ high = 1 while high ** n  x high *= 2 low = high2 while low  high\n
      mid = (low + high)  2 if low  mid and mid**n  x low = mid elif high  mid and\n
      mid**n  x high = mid else return mid return mid + 1 def find_invpowalt(x,n)\n
      """finds the integer component of the n''th root of x, an integer such that y\n
      ** n = x  (y + 1) ** n. """ low = 10 ** (len(str(x))  n) high = low * 10 while\n
      low  high mid = (low + high)  2 if low  mid and mid**n  x low = mid elif high  mid\n
      and mid**n  x high = mid else return mid return mid + 1 x = 237734537465873465\n
      n = 5 tests = 10000 print "norm", timer(''find_invpow(x,n)'','from __main__\n
      import find_invpow, x,n'').timeit(number=tests) print "alt", timer(''find_invpowalt(x,n)'',\n
     'from __main__ import find_invpowalt, x,n'').timeit(number=tests) norm 0.626754999161\n
      alt 0.566340923309\n
    - if it''s a really big number. you could use a binary search. def find_invpow(x,n)\n
      """finds the integer component of the n''th root of x, an integer such that y\n
      ** n = x  (y + 1) ** n. """ high = 1 while high ** n = x high *= 2 low = high2\n
      while low  high mid = (low + high)  2 if low  mid and mid**n  x low = mid\n
      elif high  mid and mid**n  x high = mid else return mid return mid + 1 for example  x\n
      237734537465873465  n = 5  y = find_invpow(x,n)  y 2986  y**n = x = (y+1)**n\n
      true   x = 119680039660309643568856114803834088331723464504673392511960931441  n\n
      45  y = find_invpow(x,n)  y 227661383982863143360l  y**n = x  (y+1)**n true  find_invpow(y**n,n)\n
      == y true \n
    - well, if you''re not particularly worried about precision, you could convert\n
      it to a sting, chop off some digits, use the exponent function, and then multiply\n
      the result by the root of how much you chopped off. e.g. 32123 is about equal\n
      to 32 * 1000, the cubic root is about equak to cubic root of 32 * cubic root of\n
      1000. the latter can be calculated by dividing the number of 0s by 3. this avoids\n
      the need for the use of extension modules.\n
    - the gil (global interpreter lock) might be a problem, but the api is quite\n
      ok. try out the excellent processing module, which implements the threading api\n
      for separate processes. i am using that right now (albeit on os x, have yet to\n
      do some testing on windows) and am really impressed. the queue class is really\n
      saving my bacon in terms of managing complexity! edit it seemes the processing\n
      module is being included in the standard library as of version 2.6 (import multiprocessing).\n
      joy!\n
    - the standard implementation of python (generally known as cpython as it\n
      is written in c) uses os threads, but since there is the global interpreter lock,\n
      only one thread at a time is allowed to run python code. but within those limitations,\n
      the threading libraries are robust and widely used. if you want to be able to\n
      use multiple cpu cores, there are a few options. one is to use multiple python\n
      interpreters concurrently, as mentioned by others. another option is to use a\n
      different implementation of python that does not use a gil. the two main options\n
      are jython and ironpython. jython is written in java, and is now fairly mature,\n
      though some incompatibilities remain. for example, the web framework django does\n
      not run perfectly yet, but is getting closer all the time. jython is great for\n
      thread safety, comes out better in benchmarks and has a cheeky message for those\n
      wanting the gil. ironpython uses the .net framework and is written in c#. compatibility\n
      is reaching the stage where django can run on ironpython (at least as a demo)\n
      and there are guides to using threads in ironpython.\n
    - oh, for numbers that big, you would use the decimal module. ns your number\n
      as a string ns = "11968003966030964356885611480383408833172346450467339251196093144141045683463085291115677488411620264826942334897996389485046262847265769280883237649461122479734279424416861834396522819159219215308460065265520143082728303864638821979329804885526557893649662037092457130509980883789368448042961108430809620626059287437887495827369474189818588006905358793385574832590121472680866521970802708379837148646191567765584039175249171110593159305029014037881475265618958103073425958633163441030267478942720703134493880117805010891574606323700178176718412858948243785754898788359757528163558061136758276299059029113119763557411729353915848889261125855717014320045292143759177464380434854573300054940683350937992500211758727939459249163046465047204851616590276724564411037216844005877918224201569391107769029955591465502737961776799311859881060956465198859727495735498887960494256488224613682478900505821893815926193600121890632"\n
      from decimal import decimal d = decimal(ns) one_third = decimal("0.3333333333333333")\n
      print d ** one_third and the answer is 2.287391878618402702753613056e+305 tz\n
      pointed out that this isn''t accurate... and he''s right. here''s my test. from\n
      decimal import decimal def nth_root(num_decimal, n_integer) exponent = decimal("1.0")\n
     decimal(n_integer) return num_decimal ** exponent def test() ns = "11968003966030964356885611480383408833172346450467339251196093144141045683463085291115677488411620264826942334897996389485046262847265769280883237649461122479734279424416861834396522819159219215308460065265520143082728303864638821979329804885526557893649662037092457130509980883789368448042961108430809620626059287437887495827369474189818588006905358793385574832590121472680866521970802708379837148646191567765584039175249171110593159305029014037881475265618958103073425958633163441030267478942720703134493880117805010891574606323700178176718412858948243785754898788359757528163558061136758276299059029113119763557411729353915848889261125855717014320045292143759177464380434854573300054940683350937992500211758727939459249163046465047204851616590276724564411037216844005877918224201569391107769029955591465502737961776799311859881060956465198859727495735498887960494256488224613682478900505821893815926193600121890632"\n
      nd = decimal(ns) cube_root = nth_root(nd, 3) print (cube_root ** decimal("3.0"))\n
       nd if __name__ == "__main__" test() it''s off by about 10**891\n
    - as gae builds on how data is managed in django there is a lot of info on\n
      how to address similar questions in the django documentation (for example see\n
      here, scroll down to'your first model''). in short you design you db model as\n
      a regular object model and let gae sort out all of the object-relational mappings.\n
    - afaik, no. if you just want to check the existence of a given variable,\n
      you can do it by testing for it, something like this if (foo) foo();\n
    - possibly for your curiosity this could be the technique that maple would\n
      use to actually find the nth root of large numbers. pose the fact that x^n - 11968003....\n
      0 mod p, and go from there...\n
    - i think this is what you want to do d = {} for i, tag in enumerate(ithtag)\n
      d[tag] = i\n
    - you can use you build the model and the application once and it works on\n
      gae but also witl sqlite, mysql, posgres, oracle, mssql, firebird\n
    - well, i don''t think that there is something like that in js. you can always\n
      use eval instead of locals(). like this eval(s+"()"); you just have to know that\n
      actually function foo exists. edit don''t use eval) use var functionname="myfunctionname";\n
      window[functionname]();\n
    - designing a bigtable schema is an open process, and basically requires\n
      you to think about the access patterns you will be using and how often each will\n
      be used the relationships between your types what indices you are going to need\n
      the write patterns you will be using (in order to effectively spread load) gae''s\n
      datastore automatically denormalizes your data. that is, each index contains a\n
      (mostly) complete copy of the data, and thus every index adds significantly to\n
      time taken to perform a write, and the storage space used. if this were not the\n
      case, designing a datastore schema would be a lot more work you would have to\n
      think carefully about the primary key for each type, and consider the effect of\n
      your decision on the locality of data. for example, when rendering a blog post\n
      you would probably need to display the comments to go along with it, so each comment''s\n
      key would probably begin with the associated post''s key. with datastore, this\n
      is not such a big deal the query you use will look something like "select * from\n
      comment where post_id = n." (if you want to page the comments, you would also\n
      have a limit clause, and a possible suffix of " and comment_id > last_comment_id".)\n
      once you add such a query, datastore will build the index for you, and your reads\n
      will be magically fast. something to keep in mind is that each additional index\n
      creates some additional cost it is best if you can use as few access patterns\n
      as possible, since it will reduce the number of indices gae will construct, and\n
      thus the total storage required by your data. reading over this answer, i find\n
      it a little vague. maybe a hands-on design question would help to scope this down?\n
      )\n
    - try tagdict[ithtag] = i\n
    - i agree with adam, but i think the pattern in urls.py should be ... r''^browse(?pmatch.+)\n''\n
      ... the'\w'' will only match'word'' characters, but the'.'' will match anything.\n
    - same answer came to me while reading the question. i believe model_browse\n
      view is the best way to sort the query parameters and use it as a generic router.\n
    - somtimes yaml can be good for this. import yaml a = [0, 1, [''a'','b'',\n
     'c''], 2, 3, 4] print yaml.dump(a) produces - 0 - 1 - [a, b, c] - 2 - 3 - 4\n
    - a possibility that you might consider is matching the entire string of\n
      possible values within the url pattern portion and pull out the specific pieces\n
      within your view. as an example urlpatterns = patterns('''', url(r''^browse(?pmatch.+)\n'',\n
     'app.views.view'', name=''model_browse''), ) def view(request, match) pieces\n
      match.split('''') # even indexed pieces are the names, odd are values ... no\n
      promises about the regexp i used, but i think you understand what i mean. (edited\n
      to try and fix the regexp.)\n
    - search "alex martelli", "alex martelli patterns" and "thomas wouters" on\n
      google video. there''s plenty of interesting talks on andvanced python, design\n
      patterns in python, and so on.\n
    - i''ll plug building skills in python. plus, if you want something more\n
      challenging, building skills in oo design is a rather large and complex series\n
      of exercises.\n
    - the python cookbook is absolutely essential if you want to master idiomatic\n
      python. besides, that''s the book that made me fall in love with the language.\n
    - depending on exactly what you mean by "gotten to grips with the basics",\n
      i''d suggest reading through dive into python and typingexecuting all the chapter\n
      code, then get something like programming collective intelligence and working\n
      through it - you''ll learn python quite well, not to mention some quite excellent\n
      algorithms that''ll come in handy to a web developer.\n
    - people tend to say something along the lines of "the best way to learn\n
      is by doing" but i''ve always found that unless you''re specifically learning\n
      a language to contribute to some project it''s difficult to actually find little\n
      problems to tackle to keep yourself going. a good solution to this is project\n
      euler, which has a list of various programming\mathematics challenges ranging\n
      from simple to quite brain-taxing. as an example, the first challenge is if we\n
      list all the natural numbers below 10 that are multiples of 3 or 5, we get 3,\n
      5, 6 and 9. the sum of these multiples is 23. and by problem #50 it''s already\n
      getting a little tougher which prime, below one-million, can be written as the\n
      sum of the most consecutive primes there are 208 in total, but i think some new\n
      ones get added here and there. while i already knew python fairly well before\n
      starting project euler, i found that i learned some cool tricks purely through\n
      using the language so much. good luck!\n
    - write a web app, likely in django - the docs will teach you a lot of good\n
      python style. use some of the popular libraries like pygments or the universal\n
      feed parser. both of these make extremely useful functions, which are hard to\n
      get right, available in a well-documented api. in general, i''d stay away from\n
      libs that aren''t well documented - you''ll bang your head on the wall trying\n
      to reverse-engineer them - and libraries that are wrappers around c libraries,\n
      if you don''t have any c experience. i worked on wxpython code when i was still\n
      learning python, which was my first language, and at the time it was little more\n
      than a wrapper around wxwidgets. that code was easily the ugliest i''ve ever written.\n
      i didn''t get that much out of dive into python, except for the dynamic import\n
      chapter - that''s not really well-documented elsewhere.\n
    - well, there are great ressources for advanced python programming  dive\n
      into python (read it for free) online python cookbooks (e.g. here and there) o''reilly''s\n
      python cookbook (see amazon) a funny riddle game  python challenge here is a\n
      list of subjects you must master if you want to write "python" on your resume\n
     list comprehensions iterators and generators decorators they are what make python\n
      such a cool language (with the standard library of course, that i keep discovering\n
      everyday).\n
    - another good option is to use ipython, which is an interactive environment\n
      with a lot of extra features, including automatic pretty printing, tab-completion\n
      of methods, easy shell access, and a lot more. it''s also very easy to install.\n
      ipython tutorial\n
    - i honestly loved the book programming python. it has a large assortment\n
      of small projects, most of which can be completed in an evening at a leisurely\n
      pace. they get you acquainted with most of the standard library and will likely\n
      hold your interest. most importantly these small projects are actually useful\n
      in a "day to day" sense. the book pretty much only assumes you know and understand\n
      the bare essentials of python as a language, rather than knowledge of it''s huge\n
      api library. i think you''ll find it''ll be well worth working through.\n
    - from pprint import pprint a = [0, 1, [''a'','b'','c''], 2, 3, 4] pprint(a)\n
      note that for a short list like my example, pprint will in fact print it all on\n
      one line. however, for more complex structures it does a pretty good job of pretty\n
      printing data.\n
    - i''d suggest writing a non-trivial webapp using either django or pylons,\n
      something that does some number crunching. no better way to learn a new language\n
      than commiting yourself to a problem and learning as you go!\n
    - in addition to pprint.pprint, pprint.pformat is really useful for making\n
      readable __repr__s. my complex __repr__s usually look like so def __repr__(self)\n
      from pprint import pformat return "classname %s" % pformat({"attrs"self.attrs,\n
      "that_i"self.that_i, "care_about"self.care_about})\n
    - something great to play around with, though not a project, is the python\n
      challenge. i''ve found it quite useful in improving my python skills, and it gives\n
      your brain a good workout at the same time.\n
    - django has been run on ironpython before, but as a proof-of-concept. i\n
      know the ironpython team are interested in django support as a metric for python-compatibility.\n
      somewhat related is the possibility to use ironpython with asp.net and asp.net\n
      mvc, which is probably more mature.\n
    - i''m guessing that the lambda you''re creating in the list comprehension\n
      is bound to the variable i which eventually ends up at 5. thus, when you evaluate\n
      the lambdas after the fact, they''re all bound to 5 and end up calculating 25.\n
      the same thing is happening with num in your second example. when you evaluate\n
      the lambda inside the loop it''s num hasn''t changed so you get the right value.\n
      after the loop, num is 5... i''m not quite sure what you''re going for, so i''m\n
      not sure how to suggest a solution. how about this? def square(x) return lambda\n
     x*x listoflambdas = [square(i) for i in [1,2,3,4,5]] for f in listoflambdas\n
      print f() this gives me the expected output 1 4 9 16 25 another way to think\n
      of this is that a lambda "captures" its lexical environment at the point where\n
      it is created. so, if you give it num it doesn''t actually resolve that value\n
      until its invoked. this is both confusing and powerful.\n
    - you process each form as you normally would, ensuring that you create instances\n
      which have the same prefixes as those used to generate the form initially. here''s\n
      a slightly awkward example using the form you''ve given, as i don''t know what\n
      the exact use case is def some_view(request) if request.method =='post''\n
      form1 = generalform(request.post, prefix=''form1'') form2 = generalform(request.post,\n
      prefix=''form2'') if all([form1.is_valid(), form2.is_valid()]) pass # do stuff\n
      with the forms else form1 = generalform(prefix=''form1'') form2 = generalform(prefix=''form2'')\n
      return render_to_response(''some_template.html'', {'form1'' form1,'form2''\n
      form2, }) here''s some real-world sample code which demonstrates processing forms\n
      using the prefix\n
    - i sometimes find that defining actual classes for function objects makes\n
      it easier to understand what''s going on  class square(object) ... def __init__(self,\n
      val) ... self.val = val ... def __call__(self) ... return self.val * self.val\n
      ...  l = [1,2,3,4,5]  funcs = [square(i) for i in l]  for f in funcs ... print\n
      f() ... 1 4 9 16 25  granted, it''s a bit more verbose than using lambdas or closures,\n
      but i find this easier to understand when i''m trying to do non-obvious things\n
      with functions.\n
    - you have listoflambdas = [lambda i*i for i in range(6)] for f in listoflambdas\n
      print f() output 25 25 25 25 25 25 you need currying! aside from being delicious,\n
      use this default value "hack". listoflambdas = [lambda i=i i*i for i in range(6)]\n
      for f in listoflambdas print f() output 0 1 4 9 16 25 note the i=i. that''s\n
      where the magic happens.\n
    - when function statements are executed they are bound to their (lexically)\n
      enclosing scope. in your snippet, the lambdas are bound to the global scope, because\n
      for suites are not executed as an independently scoped unit in python. at the\n
      end of the for loop, the num is bound in the enclosing scope. demo for num in\n
      range(1, 6) pass assert num == 5 # num is now bound in the enclosing scope so\n
      when you bind identifiers in the for loop you''re actually manipulating the enclosing\n
      scope. for num in range(1, 6) spam = 12 assert num == 5 # num is now bound in\n
      the enclosing scope assert spam == 12 # spam is also bound in the enclosing scope\n
      same deal for list comprehensions [num for num in range(1, 6)] assert num ==\n
      5 mind blowing, i know. anywho, with our newfound knowledge, we can determine\n
      that the lambdas you are creating are referring to the (single) num identifier\n
      bound in the enclosing scope. that should make this make more sense functions\n
      [] for number in range(1, 6) def fun() return number functions.append(fun)\n
      assert all(fun() == 5 for fun in functions) assert all(fun() is number for fun\n
      in functions) and here''s the coolest part that demonstrates it even more # same\n
      as above -- commented out for emphasis. #functions = [] #for number in range(1,\n
      6) # def fun() # return number # functions.append(fun) #assert all(fun() ==\n
      5 for fun in functions) #assert all(fun() is number for fun in functions) number\n
      6 # rebind 6 in the scope and see how it affects the results. assert all(fun()\n
      == 6 for fun in functions) so the solution to this, of course, is to make a new\n
      enclosing scope for each number you want to bind. in python, you can create new\n
      enclosing scopes with modules, classes, and functions. it''s common to use a function\n
      just to create new enclosing scope for another function. in python, a closure\n
      is a function that returns another function. kind of like a function constructor.\n
      check out get_fun in the following example def get_fun(value) """return a\n
      function that returns param`value`.""" def fun() # bound to get_fun''s scope\n
      return value return fun functions = [] for number in range(1, 6) functions.append(get_fun(number))\n
      assert [fun() for fun in functions] == range(1, 6) since get_fun is a function,\n
      it gets to have its own internal scope. every time you call get_fun with a value,\n
      a little table is created to keep track of bindings within it; i.e. it says, "within\n
      this scope, the value identifier points to the thing that was passed." that scope\n
      goes away at the end of the function execution, unless there''s a reason for it\n
      to hang around. if you''re returning a function from within a scope, that''s a\n
      good reason for parts of the "scope table" to hang around -- that function you''re\n
      returning could reference things from that scope table when you call it later\n
      on. for that reason, when fun is created within get_fun python tells fun about\n
      get_fun''s scope table, which fun keeps handy for when it''s needed. you can read\n
      more about the details and technical terminology (which i softened a bit) in the\n
      python docs on the execution model. you can also look at the parts of the enclosing\n
      scope that a function refers to with print fun.__closure__. in the above, we see\n
      the reference to the value, which happens to be an int # same as before, commented\n
      out for emphasis. #functions = [] #for number in range(1, 6) # functions.append(get_fun(number))\n
      #assert [fun() for fun in functions] == range(1, 6) print functions[0].__closure__\n
      # produces (cell at 0x8dc30 int object at 0x1004188,)\n
    - even better, i think formsets is exactly what you''re looking for. class\n
      generalform(forms.form) field1 = forms.integerfield(required=false) field2 =\n
      forms. integerfield(required=false) from django.forms.formsets import formset_factory\n
      # generalset is a formset with 2 occurrences of generalform # ( as a formset allows\n
      the user to add new items, this enforces # 2 fixed items, no less, no more ) generalset\n
      formset_factory(generalform, extra=2, max_num=2) # example view def someview(request)\n
      general_set = generalset(request.post) if general_set.is_valid() for form in\n
      general_set.forms # do something with data return render_to_response("template.html",\n
      {''form'' general_set}, requestcontext(request)) you can even have a formset\n
      automatically generated from a model with modelformset_factory , which are used\n
      by the automated django admin. formset handle even more stuff than simple forms,\n
      like adding, removing and sorting items.\n
    - you may want to read this basically web2py code runs unmodified and out\n
      of the box but with ironpython but no csv module (so no database io) no third\n
      party database drivers (not even sqlite, so no databases at all) no built-in web\n
      server (unless you cripple it by removing signals and logging) this is because\n
      csv, signals, logging and sqlite are not present in ironpython. an you can see\n
      from the thread above there is work underway to find ways around. web2py also\n
      runs unmodified on jython 2.5 beta, without any known limitation, except for a\n
      bug with regular expressions in jython that makes it choke on some templates (re.compile(...).finditer\n
      goes in a loop). we are working to find a way around for this as well.\n
    - listoflambdas = [lambda i=i square(i) for i in listofnumbers] or listoflambdas\n
      map(lambda i lambda square(i), listofnumbers)\n
    - classes are "first class" objects in python, meaning they can be passed\n
      around and manipulated just like all other objects. models are classes -- you\n
      can tell from the fact that you create new models using class statements class\n
      person(models.model) last_name = models.charfield(max_length=64) class anthropomorphicbear(models.model)\n
      last_name = models.charfield(max_length=64) both the person and anthropomorphicbear\n
      identifiers are bound to django classes, so you can pass them around. this can\n
      useful if you want to create helper functions that work at the model level (and\n
      share a common interface) def print_obj_by_last_name(model, last_name) model_name\n
      model.__name__ matches = model.objects.filter(last_name=last_name).all() print(''{0}\n
      {1!r}''.format(model_name, matches)) so print_obj_by_last_name will work with\n
      either the person or anthropomorphicbear models. just pass the model in like so\n
      print_obj_by_last_name(model=person, last_name=''dole'') print_obj_by_last_name(model=anthropomorphicbear,\n
      last_name=''fozzy'')\n
    - i assert what''s absolutely essential. important what''s absolutely essential.\n
      some people over-test things. def factorial(num) assert int(num) assert num  0\n
      isn''t completely correct. long is also a legal possibility. def factorial(num)\n
      assert type(num) in ( int, long ) assert num  0 is better, but still not perfect.\n
      many python types (like rational numbers, or number-like objects) can also work\n
      in a good factorial function. it''s hard to assert that an object has basic integer-like\n
      properties without being too specific and eliminating future unthought-of classes\n
      from consideration. i never define unique exceptions for individual functions.\n
      i define a unique exception for a significant module or package. usually, however,\n
      just an error class or something similar. that way the application says except\n
      somelibrary.error,e which is about all you need to know. fine-grained exceptions\n
      get fussy and silly. i''ve never done this, but i can see places where it might\n
      be necessary. assert all( type(i) in (int,long) for i in somelist ) generally,\n
      however, the ordinary python built-in type checks work fine. they find almost\n
      all of the exceptional situations that matter almost all the time. when something\n
      isn''t the right type, python raises a typeerror that always points at the right\n
      line of code. btw. i only add asserts at design time if i''m absolutely certain\n
      the function will be abused. i sometimes add assertions later when i have a unit\n
      test that fails in an obscure way.\n
    - or, a python version of wc and split lines = 0 for l in open(filename)\n
      lines += 1 then some code to read the first lines3 into one file, the next lines3\n
      into another , etc.\n
    - i think you''re looking for this from django.db.models.loading import\n
      get_model model = get_model(''app_name'','model_name'') there are other methods,\n
      of course, but this is the way i''d handle it if you don''t know what models file\n
      you need to import into your namespace. (note there''s really no way to safely\n
      get a model without first knowing what app it belongs to. look at the source code\n
      to loading.py if you want to test your luck at iterating over all the apps'' models.)\n
      update according to django''s deprecation timeline, django.db.models.loading\n
      has been deprecated in django 1.7 and will be removed in django 1.9. as pointed\n
      out in alasdair''s answer, a new api for dynamically loading models was added\n
      to django 1.7.\n
    -  model = django.authx.models.user ? django returns an error, "global name\n
      django is not defined." django does not return the error. python does. first,\n
      you must import the model. you must import it with from django.authx.models import\n
      user second, if you get an error that django is not defined, then django is not\n
      installed correctly. you must have django on your pythonpath or installed in your\n
      python libsite-packages. to install django correctly, see\n
    - you can use wc and split (see the respective manpages) to get the desired\n
      effect. in bash split -dl\n((`wc -l'filename''|sed's .*\n''`  3 + 1)) filename\n
      filename-chunk. produces 3 parts of the same linecount (with a rounding error\n
      in the last, of course), named filename-chunk.00 to filename-chunk.02.\n
    - check out os.stat() for file size and file.readlines([sizehint]). those\n
      two functions should be all you need for the reading part, and hopefully you know\n
      how to do the writing )\n
    - if you have the model name passed as a string i guess one way could be\n
      modelname = "user" model = globals()[modelname] but mucking about with globals()\n
      might be a bit dangerous in some contexts. so handle with care )\n
    - it rather depends on what i''m writing, and how the output gets there.\n
      python doesn''t have the publicprivate protections of other oo-languages. instead\n
      there are conventions. for example, external code should only call object methods\n
      that are not prefixed by an underscore. therefore, if i''m writing a module, i''d\n
      validate anything that is not generated from my own code, i.e. any calls to publicly-accessible\n
      methodsfunctions. sometimes, if i know the validation is expensive, i make it\n
      togglable with a kwarg def publicly_accessible_function(arg1, validate=false)\n
      if validate do_validation(arg1) do_work internal methods can do validation via\n
      the assert statement, which can be disabled altogether when the code goes out\n
      of development and into production.\n
    - i''ve written the program and it seems to work fine. so thanks to kamil\n
      kisiel for getting me started. (note that filesizeparts() is a function not shown\n
      here) later i may get round to doing a version that does a binary read to see\n
      if its any quicker. def split(inputfile,numparts,outputname) filesize=os.stat(inputfile).st_size\n
      parts=filesizeparts(filesize,numparts) openinputfile = open(inputfile,'r'')\n
      outpart=1 for part in parts if openinputfile.tell()filesize fulloutputname=outputname+os.extsep+str(outpart)\n
      outpart+=1 openoutputfile=open(fulloutputname,''w'') openoutputfile.writelines(openinputfile.readlines(part))\n
      openoutputfile.close() openinputfile.close() return outpart-1\n
    - for calculations like sum, factorial etc, pythons built-in type checks\n
      will do fine. the calculations will end upp calling add, mul etc for the types,\n
      and if they break, they will throw the correct exception anyway. by enforcing\n
      your own checks, you may invalidate otherwise working input.\n
    - i''m trying to write docstring stating what type of parameter is expected\n
      and accepted, and i''m not checking it explicitly in my functions. if someone\n
      wants to use my function with any other type its his responsibility to check if\n
      his type emulates one i accept well enough. maybe your factorial can be used with\n
      some custom long-like type to obtain something you wouldn''t think of? or maybe\n
      your sum can be used to concatenate strings? why should you disallow it by type\n
      checking? it''s not c, anyway.\n
    - the first parameter of a classmethod is named cls by convention and refers\n
      to the the class object on which the method it was invoked.  class a(object)\n
      ... ... def m(cls) ... print cls is a ... print issubclass(cls, a)  class b(a)\n
      pass  a = a()  a.m() true true  b = b()  b.m() false true\n
    - i almost never enforce any kind of a check, unless i think there''s a possibility\n
      that someone might think they can pass some x which would produce completely crazy\n
      results. the other time i check is when i accept several types for an argument,\n
      for example a function that takes a list, might accept an arbitrary object and\n
      just wrap it in a list (if it''s not already a list). so in that case i check\n
      for the type -not to enforce anything- just because i want the function to be\n
      flexible in how it''s used.\n
    - class itself a class method receives the class as implicit first argument,\n
      just like an instance method receives the instance. class c def f(cls) print(cls.__name__,\n
      type(cls))  c.f() c class'type'' and it''s cls canonically, btw\n
    - the class object gets passed as the first parameter. for example class\n
      foo(object) def bar(self) return self() would return an instance of the foo\n
      class. edit note that the last line would be self() not self. self would return\n
      the class itself, while self() returns an instance.\n
    - there are currently two forms of inheritance in django - mti (model table\n
      inheritance) and abc (abstract base classes). i wrote a tutorial on what''s going\n
      on under the hood. you can also reference the official docs on model inheritance.\n
    - i basically try to convert the variable to what it should be and pass up\n
      or throw the appropriate exception if that fails. def factorial(num) """computes\n
      the factorial of num.""" try num = int(num) except valueerror, e print e else\n
      ...\n
    - from django.authx.models import user model = user model.objects.all()\n
    - my python is a little bit rusty (anyone can feel free to edit this code\n
      to make corrections, if i''ve messed up the syntax somehow), but here goes....\n
      def movingaverageexponential(values, alpha, epsilon = 0) if not 0  alpha  1\n
      raise valueerror("out of range, alpha=''%s''" % alpha) if not 0 = epsilon  alpha\n
      raise valueerror("out of range, epsilon=''%s''" % epsilon) result = [none] * len(values)\n
      for i in range(len(result)) currentweight = 1.0 numerator = 0 denominator = 0\n
      for value in values[i-1] numerator += value * currentweight denominator +=\n
      currentweight currentweight *= alpha if currentweight  epsilon break result[i]\n
      numerator  denominator return result this function moves backward, from the\n
      end of the list to the beginning, calculating the exponential moving average for\n
      each value by working backward until the weight coefficient for an element is\n
      less than the given epsilon. at the end of the function, it reverses the values\n
      before returning the list (so that they''re in the correct order for the caller).\n
      (side note if i was using a language other than python, i''d create a full-size\n
      empty array first and then fill it backwards-order, so that i wouldn''t have to\n
      reverse it at the end. but i don''t think you can declare a big empty array in\n
      python. and in python lists, appending is much less expensive than prepending,\n
      which is why i built the list in reverse order. please correct me if i''m wrong.)\n
      the'alpha'' argument is the decay factor on each iteration. for example, if\n
      you used an alpha of 0.5, then today''s moving average value would be composed\n
      of the following weighted values today 1.0 yesterday 0.5 2 days ago 0.25 3\n
      days ago 0.125 ...etc... of course, if you''ve got a huge array of values, the\n
      values from ten or fifteen days ago won''t contribute very much to today''s weighted\n
      average. the'epsilon'' argument lets you set a cutoff point, below which you\n
      will cease to care about old values (since their contribution to today''s value\n
      will be insignificant). you''d invoke the function something like this result\n
      movingaverageexponential(values, 0.75, 0.0001)\n
    - i did a bit of googling and i found the following sample code ( def ema(s,\n
      n) """ returns an n period exponential moving average for the time series s s\n
      is a list ordered from oldest (index 0) to most recent (index -1) n is an integer\n
      returns a numeric array of the exponential moving average """ s = array(s) ema\n
      [] j = 1 #get n sma first and calculate the next n period ema sma = sum(s[n])\n
     n multiplier = 2  float(1 + n) ema.append(sma) #ema(current) = ( (price(current)\n
       ema(prev) ) x multiplier) + ema(prev) ema.append(( (s[n] - sma) * multiplier)\n
      + sma) #now calculate the rest of the values for i in s[n+1] tmp = ( (i - ema[j])\n
      * multiplier) + ema[j] j = j + 1 ema.append(tmp) return ema\n
    - edit it seems that mov_average_expw() function from scikits.timeseries.lib.moving_funcs\n
      submodule from scikits (add-on toolkits that complement scipy) better suits the\n
      wording of your question. to calculate an exponential smoothing of your data with\n
      a smoothing factor alpha (it is (1 - alpha) in wikipedia''s terms)  alpha = 0.5  assert\n
      0  alpha = 1.0  av = sum(alpha**n.days * iq ... for n, iq in map(lambda (day,\n
      iq), today=max(days) (today-day, iq), ... sorted(zip(days, iq), key=lambda p\n
      p[0], reverse=true))) 95.0 the above is not pretty, so let''s refactor it a bit\n
      from collections import namedtuple from operator import itemgetter def smooth(iq_data,\n
      alpha=1, today=none) """perform exponential smoothing with factor `alpha`. time\n
      period is a day. each time period the value of `iq` drops `alpha` times. the most\n
      recent data is the most valuable one. """ assert 0  alpha = 1 if alpha == 1 #\n
      no smoothing return sum(map(itemgetter(1), iq_data)) if today is none today =\n
      max(map(itemgetter(0), iq_data)) return sum(alpha**((today - date).days) * iq\n
      for date, iq in iq_data) iqdata = namedtuple("iqdata", "date iq") if __name__\n
      == "__main__" from datetime import date days = [date(2008,1,1), date(2008,1,2),\n
      date(2008,1,7)] iq = [110, 105, 90] iqdata = list(map(iqdata, days, iq)) print("\n".join(map(str,\n
      iqdata))) print(smooth(iqdata, alpha=0.5)) example \n python26 smooth.py iqdata(date=datetime.date(2008,\n
      1, 1), iq=110) iqdata(date=datetime.date(2008, 1, 2), iq=105) iqdata(date=datetime.date(2008,\n
      1, 7), iq=90) 95.0\n
    - as far as i can tell, the standard library doesn''t have a function, though\n
      it''s not too difficult to write one as suggested above. i think the real thing\n
      i was looking for was a way to decode a string and guarantee that it wouldn''t\n
      throw an exception. the errors parameter to string.decode does that. def decode(s,\n
      encodings=(''ascii'','utf8'','latin1'')) for encoding in encodings try\n
      return s.decode(encoding) except unicodedecodeerror pass return s.decode(''ascii'',\n
     'ignore'')\n
    - +1 for the chardet module (suggested by ). it is not in the standard library,\n
      but you can easily install it with the following command \n pip install chardet\n
      example  import chardet  import urllib  detect = lambda url chardet.detect(urllib.urlopen(url).read())  detect(''\n
      {''confidence'' 0.85663169917190185,'encoding'''iso-8859-2''}  detect(''\n
      {''confidence'' 0.98999999999999999,'encoding'''utf-8''} see installing\n
      pip if you don''t have one.\n
    - you may be interested in universal encoding detector.\n
    - whether you seperate or mix tests and modules is probably a matter of taste,\n
      although i would strongly advocate for keeping them apart (setup reasons, code\n
      stats etc). when you''re using nosetests, make sure that all directories with\n
      tests are real packages src module1.py module2.py subpackage1 __init__.py modulea.py\n
      moduleb.py tests __init__.py test_module1.py test_module2.py subpackage1 __init__.py\n
      test_modulea.py test_moduleb.py this way, you can just run nosetests in the toplevel\n
      directory and all tests will be found. you need to make sure that src is on the\n
      pythonpath, however, otherwise all the tests will fail due to missing imports.\n
    - i don''t know about nosetests, but you can achieve that with the standard\n
      unittest module. you just need to create a test_all.py file under your root directory,\n
      then import all your test modules. in your case import unittest import test_module1\n
      import test_module2 import subpackage1 if __name__ == "__main__" allsuites =\n
      unittest.testsuite([test_module1.suite(), \ test_module2.suite(), \ subpackage1.test_modulea.suite(),\n
      subpackage1.test_moduleb.suite()]) each module should provide the following\n
      function (example with a module with two unit tests class1 and class2) def suite()\n
      """ this defines all the tests of a module""" suite = unittest.testsuite() suite.addtest(unittest.makesuite(class1))\n
      suite.addtest(unittest.makesuite(class2)) return suite if __name__ =='__main__''\n
      unittest.texttestrunner(verbosity=2).run(suite())\n
    - i don''t know python, but for the averaging part, do you mean an exponentially\n
      decaying low-pass filter of the form y_new = y_old + (input - y_old)*alpha where\n
      alpha = dttau, dt = the timestep of the filter, tau = the time constant of the\n
      filter? (the variable-timestep form of this is as follows, just clip dttau to\n
      not be more than 1.0) y_new = y_old + (input - y_old)*dttau if you want to filter\n
      something like a date, make sure you convert to a floating-point quantity like\n
      # of seconds since jan 1 1970.\n
    - if they all begin with test then just nosetest should work. nose automatically\n
      searches for any files beginning with'test''.\n
    - i''ll give a testoob answer. running tests in a single file is like nose\n
      testoob test_foo.py to run tests in many files you can create suites with the\n
      testoob collectors (in each subpackage) # srcsubpackage?__init__.py def suite()\n
      import testoob return testoob.collecting.collect_from_files("test_*.py") and #\n
      srcalltests.py test_modules = ['subpackage1.suite'','subpackage2.suite'',\n
      ] def suite() import unittest return unittest.testloader().loadtestsfromnames(test_modules)\n
      if __name__ == "__main__" import testoob testoob.main(defaulttest="suite") i\n
      haven''t tried your specific scenario.\n
    - this is probably a hotly-contested topic, but i would suggest that you\n
      separate your tests out from your modules. set up something like this... use setup.py\n
      to install these into the system path (or you may be able to modify environment\n
      variables to avoid the need for an "install" step). foo module1.py module2.py\n
      subpackage1 __init__.py modulea.py moduleb.py now any python script anywhere\n
      can access those modules, instead of depending on finding them in the local directory.\n
      put your tests all off to the side like this tests test_module1.py test_module2.py\n
      test_subpackage1_modulea,py test_subpackage2_moduleb.py i''m not sure about your\n
      nosetests command, but now that your tests are all in the same directory, it becomes\n
      much easier to write a wrapper script that simply imports all of the other tests\n
      in the same directory. or if that''s not possible, you can at least get away with\n
      a simple bash loop that gets your test files one by one #!binbash cd tests\n
      for test_script in test_*.py ; do nosetests -m \ntest_script done\n
    - you might consider sphinx, a package that translates restructuredtext files\n
      into various output formats, including html, and latex, for printable pdf. it''s\n
      licensed under bsd and is now the official python documentation tool.\n
    - will this work instead of assertequals? self.assertraises(systemexit, sut.main,\n
      2) this should catch the systemexit exception and prevent the script from terminating.\n
    - probably this question contains some new information\n
    - as noted in my updates to my question, i had to modify df''s answer to\n
      self.assertraises(systemexit, sut.main) ...and i came up with a few longer snippet\n
      to test for the exit code. [note i accepted my own answer, but i will delete\n
      this answer and accept df''s if he updates his.]\n
    - import csv input = [''abc,"a string, with a comma","another, one"''] parser\n
      csv.reader(input) for fields in parser for i,f in enumerate(fields) print\n
      i,f # in python 3 and up, print is a function; use print(i,f) result 0 abc 1\n
      a string, with a comma 2 another, one\n
    - the csv module should be able to do that for you\n
    - there''s latex. not sure if that falls into the "as easy to use as html"\n
      category, but it''s not hard.\n
    - by print do you mean a printer? if so, check reportlab''s pdf tools. from\n
      reportlab.pdfgen import canvas from reportlab.lib.units import cm c = canvas.canvas("hello.pdf")\n
      c.drawstring(9*cm, 22*cm, "hello world!") c.showpage() c.save()\n
    - what''s wrong with just using qt''s native printing?\n
    - i have been fighting with printed (or pdf) output from python for 8 years\n
      now and so far i came across the following approaches (in order of personal preference)\n
      using jasperreports via pyjasper (written by me) or jasperserver. you can use\n
      the wysiwyg design tool ireport to define your layout. your python code will contact\n
      the java based jasper engine via http and make it render a pdf (pyjasper handles\n
      that). we use that for a few thousand pages a day. use plain text output. you\n
      can''t get any faster. we use that for a few hundred pages per day. use xslt-fo.\n
      you also have to call a java based rendering engine like fob. might result in\n
      performance issues but can be mitigated by having a long running java server process\n
       same approach than with jasper. we use that for a few hundred pages per day\n
      but writing xslt-fo documents made my head hurt. not used for new code. generate\n
      latex source and use a latex software package to render to pdf. getting latex\n
      to look like you like is quite difficult. but as long as you go with the provided\n
      latex styles, you are fine. not used in production at my shop. pdf generation\n
      with the reportlab toolkit. somewhat low level. even more low level fpdf. we\n
      use fpdf-ruby for a few hundred pages a day. took a lot of fiddeling to get the\n
      layout we wanted. directly generate postscript. strange but you nearly can''t\n
      get more in terms of speed and control. we used that to generate contact sheets\n
      with a few hundred thousand jpegs per day. takes fiddling but is fun. use troffgroff\n
      to generate postscriptpdf. very low level bute nice to do simple, high volume\n
      things. never used it thus in production. for orders, invoices and the like i\n
      highly recommend jasperreports. the ability to use a visual editor to define the\n
      layout is a huge time saver.\n
    - or if you''re on a mac, you could check out quartz bindings for python,\n
      but it''s obviously not gpl.\n
    - xsl formatting objects (part of the the extensible stylesheet language\n
      family (xsl)) if you need total control over printed documents. then, you''ll\n
      need a formatting objects processor, like fop or antenna house, to transform the\n
      xsl-fo document into pdf, or postscript.\n
    - the best way to do this that i''ve found is to iteratively try decoding\n
      a prospective with each of the most common encodings inside of a try except block.\n
    - not easily. you could have two threadinghttpserver instances, write your\n
      own serve_forever() function (don''t worry it''s not a complicated function).\n
      the existing function def serve_forever(self, poll_interval=0.5) """handle one\n
      request at a time until shutdown. polls for shutdown every poll_interval seconds.\n
      ignores self.timeout. if you need to do periodic tasks, do them in another thread.\n
      """ self.__serving = true self.__is_shut_down.clear() while self.__serving #\n
      xxx consider using another file descriptor or # connecting to the socket to wake\n
      this up instead of # polling. polling reduces our responsiveness to a # shutdown\n
      request and wastes cpu at all other times. r, w, e = select.select([self], [],\n
      [], poll_interval) if r self._handle_request_noblock() self.__is_shut_down.set()\n
      so our replacement would be something like def serve_forever(server1,server2)\n
      while true r,w,e = select.select([server1,server2],[],[],0) if server1 in r\n
      server1.handle_request() if server2 in r server2.handle_request()\n
    - sure; just start two different servers on two different ports in two different\n
      threads that each use the same handler. here''s a complete, working example that\n
      i just wrote and tested. if you run this code then you''ll be able to get a hello\n
      world webpage at both and from threading import thread from socketserver import\n
      threadingmixin from basehttpserver import httpserver, basehttprequesthandler class\n
      handler(basehttprequesthandler) def do_get(self) self.send_response(200) self.send_header("content-type",\n
      "textplain") self.end_headers() self.wfile.write("hello world!") class threadinghttpserver(threadingmixin,\n
      httpserver) pass def serve_on_port(port) server = threadinghttpserver(("localhost",port),\n
      handler) server.serve_forever() thread(target=serve_on_port, args=[1111]).start()\n
      serve_on_port(2222)\n
    - i would say that threading for something this simple is overkill. you''re\n
      better off using some form of asynchronous programming. here is an example using\n
      twisted from twisted.internet import reactor from twisted.web import resource,\n
      server class myresource(resource.resource) isleaf = true def render_get(self,\n
      request) return'gotten'' site = server.site(myresource()) reactor.listentcp(8000,\n
      site) reactor.listentcp(8001, site) reactor.run() i also thinks it looks a lot\n
      cleaner to have each port be handled in the same way, instead of having the main\n
      thread handle one port and an additional thread handle the other. arguably that\n
      can be fixed in the thread example, but then you''re using three threads.\n
    - .bashrc only gets read when a shell starts; it won''t affect carbon emacs.\n
      instead, use setenv in your .emacs (setenv "pythonpath" "path_string_here") you\n
      can set pythonpath for the entire mac os session, by adding it to ~.macosxenvironment.plist\n
      (more here). you probably don''t want to do this unless you have xcode (and its\n
      property list editor) installed. (via procrastiblog)\n
    - you asked about the python developers'' reasoning. i can''t speak for them,\n
      but no other behavior makes sense. a function can either return a value, or it\n
      can raise an exception; it can''t do both. the purpose of a "finally" clause is\n
      to provide cleanup code that is "guaranteed" to be run, regardless of exceptions.\n
      by putting a return statement in a finally clause, you have declared that you\n
      want to return a value, no matter what, regardless of exceptions. if python behaved\n
      as you are asking and raised the exception, it would be breaking the contract\n
      of the "finally" clause (because it would fail to return the value you told it\n
      to return).\n
    - yes, this is a good strategy for readable but unique filenames. one important\n
      change you should replace os.path.isfile with os.path.lexists! as it is written\n
      right now, if there is a directory named foobar.baz, your program will try to\n
      overwrite that with the new file (which won''t work)... since isfile only checks\n
      for files and not directories. lexists checks for directories, symlinks, etc...\n
      basically if there''s any reason that filename could not be created. edit gave\n
      a better answer, which is more secure and robust in terms of race conditions.\n
    - two small changes... base_name, ext = os.path.splitext(file_name) you get\n
      two results with distinct meaning, give them distinct names. file_name = "%s_%d%s"\n
      % (base_name, str(counter), ext) it isn''t faster or significantly shorter. but,\n
      when you want to change your file name pattern, the pattern is on one place, and\n
      slightly easier to work with.\n
    - if you want readable names this looks like a good solution. there are routines\n
      to return unique file names for eg. temp files but they produce long random looking\n
      names.\n
    - erm, i am not sure as i a haven''t used them at all in real life, but it\n
      could be used to simulate a nested data structure? see this link\n
    - one example would be a linked list where the last item points the first.\n
      this would allow you to create a fixed number of items but always be able to get\n
      a next item.\n
    - when doing lattice simulations cyclictoroidal boundary conditions are\n
      often used. usually a simple lattice[i%l] would suffice, but i suppose one could\n
      create the lattice to be cyclic.\n
    - a nested structure could be used in a test case for a garbage collector.\n
    - i recently created a cyclic data structure to represent the eight cardinal\n
      and ordinal directions. its useful for each direction to know its neighbors. for\n
      instance, direction.north knows that direction.northeast and direction.northwest\n
      are its neighbors. this is cyclic because each neighor knows its neighbors until\n
      it goes full swing around (the "->" represents clockwise) north -> northeast\n
      > east -> southeast -> south -> southwest -> west -> northwest -> north -> ...\n
      notice we came back to north. that allows me to do stuff like this (in c#) public\n
      class direction { ... public ienumerabledirection withtwoneighbors { get { yield\n
      return this; yield return this.counterclockwise; yield return this.clockwise;\n
      } } } ... public void trytomove (direction dir) { dir = dir.withtwoneighbors.where\n
      (d = canmove (d)).first () move (dir); } this turned out to be quite handy and\n
      made a lot of things much less complicated.\n
    - suppose you have limited storage, and data constantly accumulates. in many\n
      real life cases, you don''t mind getting rid of old data, but you don''t want\n
      to move data. you can use a cyclic vector; implemented using a vector v of size\n
      n with two special indices begin and end, which initiate on 0. insertion of "new"\n
      data now goes like this v[end] = a; end = (end+1) % n; if (begin == end) begin\n
      (begin+1) % n; you can insert "old" data and erase "old" or "new" data in a\n
      similar way. scanning the vector goes like this for (i=begin; i != end; i = (i+1)\n
      % n) {  do stuff }\n
    - here is an interesting comparison for return in finally block, among -\n
      javac#pythonjavascript\n
    - the first thing i would check is whether you need to connect via an http\n
      proxy (in which case direct connections bypassing the proxy will likely time out).\n
      run wireshark and see what happens.\n
    - i learned most of my initial pythonese from this super-handy quick reference\n
    - A_Body " the exception disappears when you use return inside a finally clause.\\n
      .. is that documented anywhere? it is if finally is present, it specifies a\\n
      \xE2\x80\x98cleanup\xE2\x80\x99 handler. the try clause is executed, including\\n
      any except and else clauses. if an exception occurs in any of the clauses and\\n
      is not handled, the exception is temporarily saved. the finally clause is executed.\\n
      if there is a saved exception, it is re-raised at the end of the finally clause.\\n
      if the finally clause raises another exception or executes a return or break\\n
      statement, the saved exception is lost. "\n
    - returning from a finally is not a good idea. i know c# specifically forbids\n
      doing this.\n
    - import socket socket.setdefaulttimeout(30000) sock = socket.socket() sock.connect((''\n
      443)) ssl = socket.ssl(sock) ssl.server() --'c=usst=californial=mountain\n
      viewo=google inccn= it works just fine. i can''t reproduce your error.\n
    -  is not accessible by https. it redirects to insecure http. to get to mail,\n
      you should be going go\n
    - the problem is csv.reader doesn''t really manage a context. it can accept\n
      any iterable, not just a file. therefore it doesn''t call close on its input (incidentally\n
      if it did you could use contextlib.closing). so it''s not obvious what context\n
      support for csv.reader would actually do.\n
    - it''s easy to create what you want using a generator function import csv\n
      from contextlib import contextmanager def opencsv(path) yield csv.reader(open(path))\n
      with opencsv("myfile.csv") as reader # do stuff with your csvreader\n
    - the primary use of with statement is an exception-safe cleanup of an object\n
      used in the statement. with makes sure that files are closed, locks are released,\n
      contexts are restored, etc. does csv.reader have things to cleanup in case of\n
      exception? i''d go with with open("myfile.csv") as f for row in csv.reader(f)\n
      # process row you don''t need to submit the patch to use csv.reader and with statement\n
      together. import contextlib help on function contextmanager in module contextlib\n
      contextmanager(func) decorator. typical usage def some_generator(arguments)\n
      setup try yield value finally cleanup this makes this with some_generator(arguments)\n
      as variable body equivalent to this setup try variable = value body finally\n
      cleanup here''s a concrete example how i''ve used it curses_screen.\n
    - yes. the second way is correct. as to why? who ever knows. you''re right,\n
      it''s probably an easy change. it''s not as high priority as other things. you\n
      can easily make your own patch kit and submit it.\n
    - i tried learning from programming python and i didn''t like it. i''m going\n
      to give python in a nutshell a try as per suggestions below.\n
    - lots of things. circular buffer, for example you have some collection\n
      of data with a front and a back, but an arbitrary number of nodes, and the "next"\n
      item from the last should take you back to the first. graph structures are often\n
      cyclic; acyclicity is a special case. consider, for example, a graph containing\n
      all the cities and roads in a traveling salesman problem. okay, here''s a particular\n
      example for you. i set up a collection of towns here in colorado v=["boulder",\n
      "denver", "colorado springs", "pueblo", "limon"] i then set up pairs of cities\n
      where there is a road connecting them. e=[["boulder", "denver"], ["denver", "colorado\n
      springs"], ["colorado springs", "pueblo"], ["denver", "limon"], ["colorado springs",\n
      "limon"]] this has a bunch of cycles. for example, you can drive from colorado\n
      springs, to limon, to denver, and back to colorado springs. if you create a data\n
      structure that contains all the cities in v and all the roads in e, that''s a\n
      graph data structure. this graph would have cycles.\n
    - i think that think python is very good for first-time programmers. pleasant\n
      writing style too..\n
    - dive into python is an excellent book geared toward programmers wanting\n
      to pick up python. the best part is that it''s freely available online. i started\n
      learning a little python a few months ago and i''ve worked through about half\n
      of the book. it''s a very comprehensive tool that''s good for learning the language\n
      and also for a reference down the road. edit kamens is a faster typer than i\n
      am.\n
    - python pocket reference. i have both learning python &amp; programming\n
      python and i almost always go to the pocket reference first.\n
    - many people have suggested dive into python, which is probably the best\n
      python book out there for someone who''s already a good programmer. however, if\n
      you''re new to programming, the best book is probably "how to think like a computer\n
      scientist learning with python" (\n
    - i''ll second daniel''s recommendation of python in a nutshell. if you''re\n
      quick to pick up new languages, it''s probably exactly what you''re looking for.\n
      there''s a nice overview of how the language works, and then a discussion of most\n
      of the standard library. it''s concise and clear, and doesn''t assume that you\n
      don''t know basic programming things already.\n
    - two good online-books, that also describes the basics of the environment\n
      is diveintopython.net and the "official" tutorial.\n
    - since you''re already familiar with other languages and a quick study,\n
      i''d recommend python in a nutshell by alex martelli, very concise and also useful\n
      later on for reference.\n
    - i loved dive into python, especially if you''re a quick study. the beginning\n
      basics are all covered (and may move slowly for you), but the latter few chapters\n
      are great learning tools. plus, pilgrim is a pretty good writer.\n
    - django''s built-in prepopulated_fields functionality is hardcoded to slugify,\n
      it can''t really be used for more general purposes. you''ll need to write your\n
      own javascript function to do the prepopulating. the best way to get it included\n
      in the admin page is to include it in the inner media class of a custom form or\n
      widget. you''ll then need to customize your modeladmin subclass to use the custom\n
      form or widget. last, you''ll need to render some inline javascript along with\n
      each prepopulated field to register the onchange handler and tell it which other\n
      field to populate from; i would render this via the custom widget. to make it\n
      nice and declarative you could use a custom modeladmin attribute (similar to prepopulated_fields),\n
      and override modeladmin.formfield_for_dbfield to create the widget and pass in\n
      the information about what field it should prepopulate from. this kind of admin\n
      hacking is almost always possible, but (as you can tell from this convoluted summary)\n
      rarely simple, especially if you''re making an effort to keep your code nicely\n
      encapsulated.\n
    - you can override the default django admin field by replacing it with a\n
      form field of your choice. check this  add custom validation to the admin\n
    -  i would also like to have a text field that automatically starts with\n
      something like "hello my name is author". check out the docs at you could have\n
      a charfield() or textfield() in your model, and set this option, which will set\n
      the default text.'default'' can also be a callable function. something like\n
      models.charfield(max_length=250, default="default text")\n
    - the slug handling is done with javascript. so you have to override the\n
      templates in the admin and then populate the fields with javascript. the date\n
      thing should be trivial, but i dont know how you should get the logged in users\n
      name to the script (not that i have thought very hard but you get the drift ).\n
    - learning python is how i learned the language. it''s a quick read, and\n
      very well organized around fundamental concepts.\n
    - one issue is that there is a race condition in your above code, since there\n
      is a gap between testing for existance, and creating the file. there may be security\n
      implications to this (think about someone maliciously inserting a symlink to a\n
      sensitive file which they wouldn''t be able to overwrite, but your program running\n
      with a higher privilege could) attacks like these are why things like os.tempnam()\n
      are deprecated. to get around it, the best approach is to actually try create\n
      the file in such a way that you''ll get an exception if it fails, and on success,\n
      return the actually opened file object. this can be done with the lower level\n
      os.open functions, by passing both the os.o_creat and os.o_excl flags. once opened,\n
      return the actual file (and optionally filename) you create. eg, here''s your\n
      code modified to use this approach (returning a (file, filename) tuple) def unique_file(file_name)\n
      counter = 1 file_name_parts = os.path.splitext(file_name) # returns (''pathfile'',\n
     '.ext'') while 1 try fd = os.open(file_name, os.o_creat | os.o_excl | os.o_rdrw)\n
      return os.fdopen(fd), file_name except oserror pass file_name = file_name_parts[0]\n
      +'_'' + str(counter) + file_name_parts[1] counter += 1 [edit] actually, a better\n
      way, which will handle the above issues for you, is probably to use the tempfile\n
      module, though you may lose some control over the naming. here''s an example of\n
      using it (keeping a similar interface) def unique_file(file_name) dirname, filename\n
      os.path.split(file_name) prefix, suffix = os.path.splitext(filename) fd, filename\n
      tempfile.mkstemp(suffix, prefix+"_", dirname) return os.fdopen(fd), filename  f,\n
      filename=unique_file(''homesome_dirfoo.txt'')  print filename homesome_dirfoo_z8f_2z.txt\n
      the only downside with this approach is that you will always get a filename with\n
      some random characters in it, as there''s no attempt to create an unmodified file\n
      (homesome_dirfoo.txt) first. you may also want to look at tempfile.temporaryfile\n
      and namedtemporaryfile, which will do the above and also automatically delete\n
      from disk when closed.\n
    - i found learning python really good. it''s pretty long (>700 pages) but\n
      extremely readable and you can rip through it very quickly given you''re a quick\n
      study -)\n
    - i expect that learning python is useful, and quick to read.\n
    - if you don''t care about readability, uuid.uuid4() is your friend. import\n
      uuid def unique_filename(prefix=none, suffix=none) fn = [] if prefix fn.extend([prefix,\n
     '-'']) fn.append(str(uuid.uuid4())) if suffix fn.extend([''.'', suffix.lstrip(''.'')])\n
      return'''.join(fn)\n
    - most python gui apis will be wrappers around the most common cc++ gui\n
      apis. you''ve got a python wrapper for gtk, a python wrapper for qt, a python\n
      wrapper for .net, etc etc. so really it depends on what your needs are. if you\n
      are looking for the easiest way to draw native-looking widgets on linux, mac,\n
      and windows, then go with wxpython (python wrapper for wx widgets). if cross-platform\n
      isn''t one of your needs though, other libraries might be more useful.\n
    - here''s a good list.\n
    - second vote for elementtree (celementtree is a c implementation that is\n
      a little faster, like cpickle vs pickle). there''s some short example code here\n
      that you can look at to give you an idea of how it works (this is fredrik lundh,\n
      who wrote the module in the first place. it''s so good it got drafted into the\n
      standard library with 2.5 -) )\n
    - i''ve been working with wxpython for a few years now and i like it quite\n
      a bit. the best thing about wxpython is that the ui feels native on the different\n
      platforms it runs on (excellent on windows and linux though not as good on osx).\n
      the api lacks some consistency, but you quickly get used to it. you can check\n
      out testuff (shameless plug, as it''s my own product) to get a feeling of what\n
      can be done with wxpython (although i must say, with quite a bit of effort).\n
    - as other answers have suggested, you can provide your function with a copy\n
      of the list. as an alternative, your function could take a copy of the argument\n
      def burninate(b) c = [] b = list(b) for i in range(3) c.append(b.pop()) return\n
      c basically, you need to be clear in your mind (and in your documentation) whether\n
      your function will change its arguments. in my opinion, functions that return\n
      computed values should not change their arguments, and functions that change their\n
      arguments should not return anything. see python''s [].sort(), [].extend(), {}.update(),\n
      etc. for examples. obviously there are exceptions (like .pop()). also, depending\n
      on your particular case, you could rewrite the function to avoid using pop() or\n
      other functions that modify the argument. e.g. def burninante(b) return b[-4-1]\n
      # return the last three elements in reverse order\n
    - A_Body "i've used tkinter and wxpython. tkinter is quite basic, and doesn't use\\n
      native widgets. this means that tkinter applications will look the same on any\\n
      platform \xE2\x80\x93 this might sound appealing, but in practice, it means\\n
      they look ugly on any platform - nevertheless, it's pretty easy to use. i\\n
      found thinking in tkinter very helpful when i was learning, because i'd never\\n
      done any gui programming before. if things like frames and layout algorithms\\n
      and buttons and bindings are familiar to you, though, you can skip that step.\\n
      you can augment tkinter with tix (but be warned, tix doesn't play well with\\n
      py2exe). also check out python megawidgets, which builds some more advanced\\n
      controls using the tkinter basics. finally, tkinter plays nice with the shell\\n
      you can start the interpreter, do things likeimport tkinter'tk = tkinter.tk()'\\n
      etc. and build your gui interactively (and it will be responsive). (i think\\n
      this doesn't work if you use idle, though) wxpython is much better looking,\\n
      and ships with a much greater range of controls. it's cross-platform (though\\n
      it seems a bit finicky on my mac) and uses native controls on each platform.\\n
      it's a bit confusing, though. it also ships with a demo application that shows\\n
      off most of its features, and provides a test-bed for you to experiment. some\\n
      specific thoughts on wxpython there are three (?) different ways to lay widgets\\n
      out. ignore two of them; just use sizers. and even then, you can do just about\\n
      any layout using only boxsizer and gridbagsizer. all wx widgets have ids. you\\n
      don't need to care what the ids are, but in the old days (i think) you did need\\n
      to know, so some old code will be littered with explicit id assignments. and\\n
      most demo code will have -1 everywhere as the id parameter (despite the fact\\n
      that the methods all have id as a keyword parameter that defaults to -1 anyway).\\n
      make sure you get the standard wxwidgets docs as well as the wxpython demo \xE2\\n
      \x80\x93 you need them both. if you want to use wxpython with py2exe and you want\\n
      it to look good on windows xp, you need a bit of trickery in your setup.py.\\n
      see here "\n
    - burninate = lambda x x[-4-1]\n
    - combine itertools.groupby with operator.itemgetter to get a pretty nice\n
      solution from operator import itemgetter from itertools import groupby key =\n
      itemgetter(''gender'') iter = groupby(sorted(people, key=key), key=key) for gender,\n
      people in iter print'==='', gender,'==='' for person in people print person\n
    - wxpython, and i''m assuming pygtk also, can use wxglade to help you design\n
      most uis you will create. that is a big plus. you don''t have to learn how to\n
      hand-code the gui until you''re ready. i made several gui programs straight from\n
      wxglade before i was comfortable enough in how wxpython worked to take a shot\n
      at hand-coding. pyqt has a similar graphic layout device but i''ve never had good\n
      luck getting pyqt to compile correctly. there was also a lack of tutorials and\n
      documentation that showed how to create the final python code; many of the documents\n
      i found referred to the c++ version of qt. tkinter is good for quick and dirty\n
      programs but, realistically, if you use wxglade it may be faster to make the program\n
      with wxpython. at a minimum, you can use wxglade to show a visual representation\n
      of the program to a client rather than take the time to hand-code the "dummy"\n
      program.\n
    - you can use copy.deepcopy()\n
    - other versions def burninate(b) c = [] for i in range(1, 4) c.append(b[-i])\n
      return c def burninate(b) c = b[-4-1] c.reverse() return c and someday you will\n
      love list comprehensions def burninate(b) return [b[-i] for i in range(1,4)]\n
    - a slightly more readable way to do the same thing is d = burninate(list(a))\n
      here, the list() constructor creates a new list based on a.\n
    - you can call burninate() with a copy of the list like this d = burninate(a[])\n
      or, d = burninate(list(a)) the other alternative is to make a copy of the list\n
      in your method def burninate(b) c=[] b=b[] for i in range(3) c.append(b.pop())\n
      return c  a = range(6)  b = burninate(a)  print a, b  [0, 1, 2, 3, 4, 5] [5, 4,\n
      3]\n
    - i prefer pygtk, because i am a gnome guy. using pygtk feels very pythonic\n
      to me. the code organization feels consistent, the documentation is clean and\n
      thorough, and it''s a very easy toolkit to get used to (except for maybe treeviews).\n
    -  easygui is different from other guis in that easygui is not event-driven.\n
      it allows you to program in a traditional linear fashion, and to put up dialogs\n
      for simple input and output when you need to. if you have not yet learned the\n
      event-driven paradigm for gui programming, easygui will allow you to be productive\n
      with very basic tasks immediately. later, if you wish to make the transition to\n
      an event-driven gui paradigm, you can do so with a more powerful gui package such\n
      as anygui, pythoncard, tkinter, wxpython, etc. easygui website\n
    - i think i have your poison  cheers\n
    - just use virtualenv - it is a tool to create isolated python environments.\n
      you can create a set-up script and distribute the whole bunch if you want.\n
    - i think that a combination of pycrust with matplotlib can do exactly what\n
      you need. pycrust is part of the wxpython installation, and matplotlib should\n
      be insalled separately. both are simple to install in about 5 minutes. read this\n
      about integrating matplotlib with pycrust to produce dynamic plots like the ones\n
      in the link you posted.\n
    - "i dislike the fact that developers (or me starting on a clean new machine)\n
      have to jump through the distutils hoops of having to install the libraries locally\n
      before they can get started" why? what -- specifically -- is wrong with this?\n
      you did it to create the project. your project is so popular others want to do\n
      the same. i don''t see a problem. please update your question with specific problems\n
      you need solved. disliking the way open source is distributed isn''t a problem\n
      - it''s the way that open source works. edit. the "walled garden" doesn''t matter\n
      very much. choice 1. you could, btw, build an "installer" that runs easy_install\n
      6 times for them. choice 2. you can save all of the installer kits that easy_install\n
      would have used. then you can provide a script that does an unzip and a python\n
      setup.py install for all six. choice 3. you can provide a zipped version of your\n
      site-packages. after they install python, they unzip your site-packages directory\n
      into `c\python2.5\lib\site-packages``. choice 4. you can build your own msi installer\n
      kit for your python environment. choice 5. you can host your own pypi-like server\n
      and provide an easy_install that checks your server first.\n
    - i agree with the answers by nosklo and s.lott. (+1 to both) can i just\n
      add that what you want to do is actually a terrible idea. if you genuinely want\n
      people to hack on your code, they will need some understanding of the libraries\n
      involved, how they work, what they are, where they come from, the documentation\n
      for each etc. sure provide them with a bootstrap script, but beyond that you will\n
      be molly-coddling to the point that they are clueless. then there are specific\n
      issues such as "what if one user wants to install a different version or implementation\n
      of a library?", a glaring example here is elementtree, as this has a number of\n
      implementations.\n
    - i think you''ll find xmlgenerator from xml.sax.saxutils is the closest\n
      thing to what you want. import time from xml.sax.saxutils import xmlgenerator\n
      from xml.sax.xmlreader import attributesnsimpl log_levels = [''debug'','warning'',\n
     'error''] class xml_logger def __init__(self, output, encoding) """ set up\n
      a logger object, which takes sax events and outputs an xml log file """ logger\n
      xmlgenerator(output, encoding) logger.startdocument() attrs = attributesnsimpl({},\n
      {}) logger.startelementns((none, u''log''), u''log'', attrs) self._logger = logger\n
      self._output = output self._encoding = encoding return def write_entry(self, level,\n
      msg) """ write a log entry to the logger level - the level of the entry msg -\n
      the text of the entry. must be a unicode object """ #note in a real application,\n
      i would use iso 8601 for the date #asctime used here for simplicity now = time.asctime(time.localtime())\n
      attr_vals = { (none, u''date'') now, (none, u''level'') log_levels[level], }\n
      attr_qnames = { (none, u''date'') u''date'', (none, u''level'') u''level'',\n
      } attrs = attributesnsimpl(attr_vals, attr_qnames) self._logger.startelementns((none,\n
      u''entry''), u''entry'', attrs) self._logger.characters(msg) self._logger.endelementns((none,\n
      u''entry''), u''entry'') return def close(self) """ clean up the logger object\n
      """ self._logger.endelementns((none, u''log''), u''log'') self._logger.enddocument()\n
      return if __name__ == "__main__" #test it out import sys xl = xml_logger(sys.stdout,\n
     'utf-8'') xl.write_entry(2, u"vanilla log entry") xl.close() you''ll probably\n
      want to look at the rest of the article i got that from at\n
    - i like wxpython or tk. tk comes with the standard python distribution so\n
      you don''t need install anything else. wxpython (wxwigets) seems much more powerful\n
      and looks a lot nicer. it also works well cross-platform (though not perfectly\n
      because it uses different underlying graphic api''s on diff system types)\n
    - i sometimes use the approach i describe below, for the exact same reason\n
      that states i would prefer that the use of some code is as easy as a) svn checkoutupdate\n
       b) go. but for the record i use virtualenveasy_install most of the time. i\n
      agree to a certain extent to the critisisms by a and .lott anyway, the approach\n
      i use depends on modifying sys.path, and works like this require python and setuptools\n
      (to enable loading code from eggs) on all computers that will use your software.\n
      organize your directory structure this project *.py scriptcustomize.py file.pth\n
      thirdparty eggs mako-vnnn.egg ... .egg code elementtree\ *.py ... in your top-level\n
      script(s) include the following code at the top from scriptcustomize import apply_pth_files\n
      apply_pth_files(__file__) add scriptcustomize.py to your project folder import\n
      os from glob import glob import fileinput import sys def apply_pth_files(scriptfilename,\n
      at_beginning=false) """at the top of your script from scriptcustomize import\n
      apply_pth_files apply_pth_files(__file__) """ directory = os.path.dirname(scriptfilename)\n
      files = glob(os.path.join(directory,'*.pth'')) if not files return for line\n
      in fileinput.input(files) line = line.strip() if line and line[0] !='#'' path\n
      os.path.join(directory, line) if at_beginning sys.path.insert(0, path) else\n
      sys.path.append(path) add one or more *.pth file(s) to your project folder. on\n
      each line, put a reference to a directory with packages. for instance # contents\n
      of *.pth file thirdpartycode thirdpartyeggsmako-vnnn.egg i "kind-of" like this\n
      approach. what i like it is similar to how *.pth files work, but for individual\n
      programs instead of your entire site-packages. what i do not like having to add\n
      the two lines at the beginning of the top-level scripts. again i use virtualenv\n
      most of the time. but i tend to use virtualenv for projects where i have tight\n
      control of the deployment scenario. in cases where i do not have tight control,\n
      i tend to use the approach i describe above. it makes it really easy to package\n
      a project as a zip and have the end user "install" it (by unzipping).\n
    - as far as i know there is nothing out there that offers the sort of whiz-bang\n
      features that the mono guys have implemented in their new shell, but that is not\n
      to say that the "basic" python interactive shell isn''t a feature-complete and\n
      powerful application. i could see something like the c# shell being developed\n
      at some point, but i think as of today those features you''re pointing to are\n
      reasonably unique. one might argue that this is because nobody thought of them\n
      or, alternatively, because nobody has really had a need for them. i tend to subscribe\n
      to the latter, although i suppose both are plausible.\n
    - have you looked at ipython? it''s not quite as "gui". no smileys, sorry.\n
      ;-) it is a pretty good interactive shell for python though. edit i see you revised\n
      your question to emphasize the importance gui. in that case, ipython wouldn''t\n
      be a good match. might as well save you another blind alley i went looking at\n
      drpython hoping it would be similar to plt''s drscheme, which looks comparable\n
      to example you''ve linked too. unfortunately drpython isn''t all that much like\n
      drscheme.\n
    - one project i''m aware of that provides similar features (inline plotting,\n
      customisable rendering) is reinteract. another (though possibly a bit heavyweight\n
      for general usage) is sage which provides functionality for web-based notebooks.\n
      these aren''t quite shells - they''re designed more as a mathematical notebook\n
      (so for instance, you can modify an earlier result and have the change propogate\n
      to later calculations), but they''re close to what you''re looking for, and could\n
      probably be modified to be used as such.\n
    - interactive pylab console.\n
    - you''re looking for reinteract, which is a python-based shell that at least\n
      partially inspired the c# shell you found. it''s definitely still in-development,\n
      but already very useful.\n
    - xml.etree.celementtree, included in the default distribution of cpython\n
      since 2.5. lightning fast for both reading and writing xml.\n
    - i''m not suggesting that this is a great idea, but usually what i do in\n
      situations like these is that i have a makefile, checked into subversion, which\n
      contains make rules to fetch all the dependent libraries and install them. the\n
      makefile can be smart enough to only apply the dependent libraries if they aren''t\n
      present, so this can be relatively fast. a new developer on the project simply\n
      checks out from subversion and then types "make". this approach might work well\n
      for you, given that your audience is already used to the idea of using subversion\n
      checkouts as part of their fetch process. also, it has the nice property that\n
      all knowledge about your program, including its external dependencies, are captured\n
      in the source code repository.\n
    - a more general solution would be to import copy, and use copy.copy() on\n
      the parameter.\n
    - this should work #!usrbinpython from appkit import nsworkspace activeappname\n
      nsworkspace.sharedworkspace().activeapplication()[''nsapplicationname''] print\n
      activeappname only works on leopard, or on tiger if you have pyobjc installed\n
      and happen to point at the right python binary in line one (not the case if you''ve\n
      installed universal macpython, which you''d probably want to do on tiger). but\n
      peter''s answer with the carbon way of doing this will probably be quite a bit\n
      faster, since importing anything from appkit in python takes a while, or more\n
      accurately, importing something from appkit for the first time in a python process\n
      takes a while. if you need this inside a pyobjc app, what i describe will work\n
      great and fast, since you only experience the lag of importing appkit once. if\n
      you need this to work as a command-line tool, you''ll notice the performance hit.\n
      if that''s relevant to you, you''re probably better off building a 10 line foundation\n
      command line tool in xcode using peter''s code as a starting point.\n
    - A_Body "first off, do you want the window or the application name? this isn't windows\xE2\\n
      \x80\x94an application process on mac os x can have multiple windows. (furthermore,\\n
      this has also been true of windows for a few years now, although i have no idea\\n
      what the api looks like for that.) second, carbon or cocoa? to get the active\\n
      window in cocoa window = nsapp.mainwindow() to get the name of your process\\n
      in cocoa appname = nsprocessinfo.processinfo().processname() edit oh, i think\\n
      i know what you want. the name of the frontmost process, right? i don't think\\n
      there's a way to do it in cocoa, but here's how to do it in carbon in c processserialnumber\\n
      psn = { 0l, 0l }; osstatus err = getfrontprocess(&amp;psn); *error check*\\n
      cfstringref processname = null; err = copyprocessname(&amp;psn, &amp;processname);\\n
      *error check* remember to cfrelease(processname) when you're done with it.\\n
      i'm not sure what that will look like in python, or if it's even possible. python\\n
      doesn't have pointers, which makes that tricky. i know pyobjc would translate\\n
      the latter argument to copyprocessname into err, processname = copyprocessname(\xE2\\n
      \x80\xA6), but the carbon bindings don't rely on pyobjc (they're part of core\\n
      python 2), and i'm not sure what you do about the psn either way. "\n
    - instead of posting a list of your options i will give my humble opinion\n
      i am in love with wxpython. i have used qt in c++ and tk way back in the tcl days\n
      but what really makes me like wxpython is the demo that you get with it. in the\n
      demo you can browse through all the different widgets frames etc that are part\n
      of the framework see the source code and actually see how it looks while it is\n
      running. i had some problems getting the linux version build and installed but\n
      now that i have it available i use it all the time. i have used wxpython for small\n
      data analysis applications and i have written several internal tools related to\n
      comparing test results, merging source code etc.\n
    - i found this link a long time a go it suggests a tookit based on your\n
      criteria. for me it suggests wxpython all the time. anyway it gives you a bunch\n
      of scores on the various toolkits. what is right for me may not be right for you.\n
      but it gives you how all the tookits scored according to your criteria, so if\n
      you don''t like the top toolkit for some reason you can see which ones are closest\n
      to your criteria. qtgtkwxwidgets (formerly wxwindows) seem to be among the most\n
      mature cross platform gui toolkits. the only issue is that none is installed with\n
      the default installation of python, so you may have to compile the libraries.\n
      if you want something with no installation required that just runs, then go with\n
      tkinter because as has been mentioned it is installed by default with python.\n
      anyway my criteria were 9 on ease of use, 10 on maturity of documentationwidgets,\n
      10 on installed base, 5 on gui code generators, 10 on native look and feel for\n
      both windowslinux and 1 and 5 for the last two, i''m not big into mac osx (even\n
      with a 10 here it suggests wxpython).\n
    - some years ago i used markupwriter from 4suite general-purpose utility\n
      class for generating xml (may eventually be expanded to produce more output types)\n
      sample usage from ft.xml import markupwriter writer = markupwriter(indent=u"yes")\n
      writer.startdocument() writer.startelement(u''xsa'') writer.startelement(u''vendor'')\n
      #element with simple text (#pcdata) content writer.simpleelement(u''name'', content=u''centigrade\n
      systems'') #note writer.text(content) still works writer.simpleelement(u''email'',\n
      content=u"info.bogus") writer.endelement(u''vendor'') #element with an attribute\n
      writer.startelement(u''product'', at #note writer.attribute(name,\n
      value, namespace=none) still works writer.simpleelement(u''name'',  #xml fragment writer.xmlfragment(''version1.0versionlast-release20030401last-release'')\n
      #empty element writer.simpleelement(u''changes'') writer.endelement(u''product'')\n
      writer.endelement(u''xsa'') writer.enddocument() note on the difference between\n
      4suite writers and printers writer - module that exposes a broad public api for\n
      building output bit by bit printer - module that simply takes a dom and creates\n
      output from it as a whole, within one api invokation recently i hear a lot about\n
      how lxml is great, but i don''t have first-hand experience, and i had some fun\n
      working with gnosis.\n
    - i''ve always had good results with lxml. it''s a pain to install, as it''s\n
      mostly a wrapper around libxml2, but lxml.etree tree objects have a .write() method\n
      that takes a file-like object to stream to. from lxml.etree import xml tree =\n
      xml(''rootabaroot'') tree.write(your_file_object)\n
    - pythoncard is really easy to use. that''s what i would recommend. here''s\n
      their writeup pythoncard is a gui construction kit for building cross-platform\n
      desktop applications on windows, mac os x, and linux, using the python language.\n
      the pythoncard motto is "simple things should be simple and complex things should\n
      be possible." pythoncard is for you if you want to develop graphical applications\n
      quickly and easily with a minimum of effort and coding. apple''s hypercard is\n
      one of our inspirations; simple, yet powerful. pythoncard uses wxpython. if you\n
      are already familiar with wxpython, just think of pythoncard as a simpler way\n
      of doing wxpython programs with a whole lot of samples and tools already in place\n
      for you to copy and subclass and tools to help you build cross-platform applications.\n
    - pyqt is excellent if you have experience or interest in qt.\n
    - create a new launch configuration (python run) main tab use paster-script.py\n
      as main module (you can find it in the scripts sub-directory in your python installation\n
      directory) don''t forget to add the root folder of your application in the pythonpath\n
      zone arguments set the base directory to the root folder also. as program arguments\n
      use "serve development.ini" (or whatever you use to debug your app") common tab\n
      check allocate console and launch in background\n
    - my automatic response would be webfaction. i haven''t personally hosted\n
      with them, but they are primarily python-oriented (founded by the guy who wrote\n
      cherrypy, for example, and as far as i know they were the first to roll out python\n
      3.0 support).\n
    - i have been using webfaction for years and very happy with the service.\n
      they are not only python oriented. you should be able to run anything within the\n
      limitations of shared hosting (unless of course you have a dedicated server).\n
      they are probably not the cheapest hosting service though. i don''t know the prices.\n
      but i can still remember very well my previous hosting provider was unreachable\n
      for a week (not their servers, i mean the people).\n
    - this snippet will do so. if you''re going to do it frequently, you might\n
      want to make a'sortkeys'' method or somesuch to make it easier on the eyes.\n
      keys = list(d.keys()) keys.sort() for key in keys print d[key] edit df''s solution\n
      is better -- i forgot all about sorted().\n
    - you might want to have a look at the pwd module in the python stdlib, for\n
      example import pwd pw = pwd.getpwnam("nobody") uid = pw.pw_uid it uses etcpasswd\n
      (well, technically it uses the posix c api, so i suppose it might work on an os\n
      if it didn''t use etcpasswd but exposed the needed functions) but is cleaner\n
      than parsing it manually\n
    - never directly scan etcpasswd. for instance, on a linux system i administer,\n
      the user accounts are not on etcpasswd, but on a ldap server. the correct way\n
      is to use getpwentgetgrent and related c functions (as in's answer), which\n
      will get the information on the correct way for each system (on linux glibc, it\n
      reads etcnsswitch.conf to know which nss dynamic libraries to load to get the\n
      information).\n
    - do you mean that you need the values sorted by the value of the key? in\n
      that case, this should do it for key in sorted(d) print d[key] edit changed\n
      to use sorted(d) instead of sorted(d.keys()), thanks eli!\n
    - you can also sort a dictionary by value and control the sort order import\n
      operator d = {''b'' 'this is 3'','a'''this is 2'' ,'c'' 'this is\n
      1''} for key, value in sorted(d.iteritems(), key=operator.itemgetter(1), reverse=true)\n
      print key, " ", value output b this is 3 a this is 2 c this is 1\n
    - i''ve been pretty happy with dreamhost, and of course google appengine.\n
    - class recipecontent(models.model) ... def __unicode__(self) # you can\n
      access foreignkey properties through the field name! return self.recipe.name\n
    - i am a big fan of slicehost -- you get root access to a virtual server\n
      that takes about 2 minutes to install from stock os images. the 256m slice, which\n
      has been enough for me, is us\n20mo -- it is cheaper than keeping an old box plugged\n
      in, and easy to back up. very easy to recommend.\n
    - google app engine and openhosting.com have virtual server by openhosting,\n
      they are ultra fast with support and have very high uptime.\n
    - yes, you can (as bishanty points), but be prepared for situation when __unicode__()\n
      is called but fk is not set yet. i came into this few times.\n
    - or shorter, for key, value in sorted(d.items()) print value\n
    -  d = {''b'' 'this is b'','a'''this is a'' ,'c'' 'this is c''}  for\n
      k,v in sorted(d.items()) ... print v, k ... this is a a this is b b this is c\n
      c\n
    - for key in sorted(d) print d[key]\n
    - d = {''b'' 'this is b'','a'''this is a'' ,'c'' 'this is c''}\n
      ks = d.keys() ks.sort() for k in ks print "this is " + k\n
    - import sqlite3 sqlite3 - db-api 2.0 interface for sqlite databases. you\n
      are missing the .so (shared object) - probably an installation step. in my linux\n
      python installation, _sqlite3 is at \n{somewhere}libpython2.6lib-dynload_sqlite3.so\n
    - try this from pysqlite2 import dbapi2 as sqlite\n
    - the only purpose of entity groups (defined by the parent attribute) is\n
      to enable transactions among different entities. if you don''t need the transactions,\n
      don''t use the entity group relationships. i suggest you re-reading the keys and\n
      entity groups section of the docs, it took me quite a few reads to grasp the idea.\n
      also watch these talks, among other things they discuss transactions and entity\n
      groups building scalable web applications with google app engine under the covers\n
      of the google app engine datastore\n
    - there are several differences all entities with the same ancestor are\n
      in the same entity group. transactions can only affect entities inside a single\n
      entity group. all writes to a single entity group are serialized, so throughput\n
      is limited. the parent entity is set on creation and is fixed. references can\n
      be changed at any time. with reference properties, you can only query for direct\n
      relationships, but with parent properties you can use the .ancestor() filter to\n
      find everything (directly or indirectly) descended from a given ancestor. each\n
      entity has only a single parent, but can have multiple reference properties.\n
    - when i started working on my gedit plugin, i used the howto you gave a\n
      link to, also startign with this url. then it was looking at other plugins code...\n
      i''m sorry to say that, but for me this topic is poorly documented and best and\n
      fastest way is to get a pluging done that actually does something.\n
    - the error importerror no module named _sqlite3 means that sqlite 3 does\n
      not find the associated shared library. on mac os x it''s _sqlite3.so and it should\n
      be the same on other unix systems. to resolve the error you have to locate the\n
      _sqlite3.so library on your computer and then check your pythonpath for this directory\n
      location. to print the python search path enter the following in the python shell\n
      import sys print sys.path if the directory containing your library is missing\n
      you can try adding it interactively with sys.path.append(''yourdirhere'') and\n
      try import sqlite3 again. if this works you have to add this directory permanently\n
      to your pythonpath environment variable. ps if the library is missing you should\n
      (re-)install the module.\n
    - have you checked out ? i think this is as thorough as you''re going to\n
      get, without poring through other people''s code.\n
    - armin how come? the python documentation said the minimum size for that\n
      array of short integer is 2 bytes and the actual representation of values is determined\n
      by the machine architecture (strictly speaking, by the c implementation). the\n
      actual size can be accessed through the itemsize attribute. arnav i suggest that\n
      your code should check the size of each type code and choose the corresponding\n
      2-byte type that is specific to the underlying system.\n
    - armin''s suggestion of the array module is probably best. two possible\n
      alternatives you can create an extension module yourself that provides the data\n
      structure that you''re after. if it''s really just something like a collection\n
      of shorts, then that''s pretty simple to do. you can cheat and manipulate bits,\n
      so that you''re storing one number in the lower half of the python int, and another\n
      one in the upper half. you''d write some utility functions to convert tofrom\n
      these within your data structure. ugly, but it can be made to work. it''s also\n
      worth realising that a python integer object is not 4 bytes - there is additional\n
      overhead. so if you have a really large number of shorts, then you can save more\n
      than two bytes per number by using a c short in some way (e.g. the array module).\n
      i had to keep a large set of integers in memory a while ago, and a dictionary\n
      with integer keys and values was too large (i had 1gb available for the data structure\n
      iirc). i switched to using a iibtree (from zodb) and managed to fit it. (the ints\n
      in a iibtree are real c ints, not python integers, and i hacked up an automatic\n
      switch to a iobtree when the number was larger than 32 bits).\n
    - vim supports scripting in python (and in perl as well, i think). you just\n
      have to make sure that the vim distribution you are using has been compiled with\n
      python support. if you are using a linux system, you can download the source and\n
      then compile it with .configure --enable-pythoninterp make sudo make install\n
      inside vim, you can type version to list the available features; if it has python\n
      support, you should see a'+python'' somewhere (a'-python'' otherwise). then,\n
      to check the usage of the python module, you can type help python p.s if you''re\n
      going to compile the vim sources, make sure to check the available configure options,\n
      you might need to specify --with-python-config-dir as well. p.p.s to create a\n
      "custom command in command mode" (if i understand correctly what you mean), you\n
      can create a function "myfunction" in a vim script (using python or the vim scripting\n
      language) and then invoke it with call myfunction() check help user-functions\n
      for details\n
    - on my system _sqlite3.so located at'usrlibpython2.6lib-dynload_sqlite3.so''\n
      check that the directory is in your sys.path  import sys; print(filter(lambda\n
      p'lib-dynload'' in p, sys.path)) [''usrlibpython2.6lib-dynload'']\n
    - if you''re doing any sort of manipulation of this huge dataset, you''ll\n
      probably want to use numpy, which has support for a wide variety of numeric types,\n
      and efficient operations on arrays of them.\n
    - thanks to armin for pointing out the'array'' module. i also found the\n
     'struct'' module that packs c-style structs in a string from the documentation\n
      (  from struct import *  pack(''hhl'', 1, 2, 3)'\x00\x01\x00\x02\x00\x00\x00\x03''  unpack(''hhl'',\n
     '\x00\x01\x00\x02\x00\x00\x00\x03'') (1, 2, 3)  calcsize(''hhl'') 8\n
    - nope. but you can use short integers in arrays from array import array\n
      a = array("h") # h = signed short, h = unsigned short as long as the value stays\n
      in that array it will be a short integer. documentation for the array module\n
    - yes it is. there are several extensions on it can be done with python as\n
      well if the support for python is compiled in. article about it google is our\n
      friend. hth\n
    - A_Body "just ran across this on python reddit tonight pysmell. looks like what\\n
      you're looking for. pysmell is a python ide completion helper. it tries to statically\\n
      analyze python source code, without executing it, and generates information\\n
      about a project\xE2\x80\x99s structure that ide tools can use. "\n
    - i think your after the pydiction script. it lets you add your own stuff\n
      and site-packages to omni complete. while your at it, add the following to your\n
      python.vim file... set iskeyword+=. this will let you auto-complete package functions\n
      e.g. if you enter... os.path. and then [ctrl][n], you''ll get a list of the functions\n
      for os.path.\n
    - i''d be very surprised if the get_nowait() call caused the pause by not\n
      returning if the list was empty. could it be that you''re posting a large number\n
      of (maybe big?) items between checks which means the receiving thread has a large\n
      amount of data to pull out of the queue? you could try limiting the number you\n
      retrieve in one batch def queue_get_all(q) items = [] maxitemstoretreive = 10\n
      for numofitemsretrieved in range(0, maxitemstoretreive) try if numofitemsretrieved\n
      == maxitemstoretreive break items.append(q.get_nowait()) except empty, e break\n
      return items this would limit the receiving thread to pulling up to 10 items at\n
      a time.\n
    - why not do the following? this accomplishes what you need without a significant\n
      change to your code. class testoneformanager(unittest.testcase) def testaddingblah(self)\n
      manager = manager() self.assertequals(manager.getblahs(), 0) manager.addblah(...)\n
      self.assertequals(manager.getblahs(), 1) class testtwoformanager(unittest.testcase)\n
      def testaddingblahindifferentway(self) manager = manager() self.assertequals(manager.getblahs(),\n
      0) manager.addblahindifferentway(...) self.assertequals(manager.getblahs(), 1)\n
      edit. the "reset on testcase" feature gives you complete control. many test methods\n
      in a single testcase are good when you have test cases that don''t interfere with\n
      each other. few test methods in a single testcase are good when you have test\n
      cases that interfere with each other. you can choose which model applies to your\n
      tests by grouping your test methods in one or many testcases. you have total and\n
      complete control.\n
    - if you''re always pulling all available items off the queue, is there any\n
      real point in using a queue, rather than just a list with a lock? ie from __future__\n
      import with_statement import threading class itemstore(object) def __init__(self)\n
      self.lock = threading.lock() self.items = [] def add(self, item) with self.lock\n
      self.items.append(item) def getall(self) with self.lock items, self.items =\n
      self.items, [] return items if you''re also pulling them individually, and making\n
      use of the blocking behaviour for empty queues, then you should use queue, but\n
      your use case looks much simpler, and might be better served by the above approach.\n
      [edit2] i''d missed the fact that you''re polling the queue from an idle loop,\n
      and from your update, i see that the problem isn''t related to contention, so\n
      the below approach isn''t really relevant to your problem. i''ve left it in in\n
      case anyone finds a blocking variant of this useful for cases where you do want\n
      to block until you get at least one result, you can modify the above code to wait\n
      for data to become available through being signalled by the producer thread. eg.\n
      class itemstore(object) def __init__(self) self.cond = threading.condition()\n
      self.items = [] def add(self, item) with self.cond self.items.append(item) self.cond.notify()\n
      # wake 1 thread waiting on cond (if any) def getall(self, blocking=false) with\n
      self.cond # if blocking is true, always return at least 1 item while blocking\n
      and len(self.items) == 0 self.cond.wait() items, self.items = self.items, []\n
      return items\n
    - i see you are using get_nowait() which according to the documentation,\n
      "return[s] an item if one is immediately available, else raise the empty exception"\n
      now, you happen to break out of the loop when an empty exception is thrown. thus,\n
      if there is no result immediately available in the queue, your function returns\n
      an empty items list. is there a reason why you are not using the get() method\n
      instead? it may be the case that the get_nowait() fails because the queue is servicing\n
      a put() request at that same moment.\n
    - there are couple of open source apps that might give you some pointers\n
      pykeylogger is python keylogger for windows and linux logkext is a c++ keylogger\n
      for mac\n
    - here''s how i did it (grabbing all files ending in ".ranks") import urllib2,\n
      cstringio, zipfile try remotezip = urllib2.urlopen(url) zipinmemory = cstringio.stringio(remotezip.read())\n
      zip = zipfile.zipfile(zipinmemory) for fn in zip.namelist() if fn.endswith(".ranks")\n
      ranks_data = zip.read(fn) for line in ranks_data.split("\n") # do something with\n
      each line except urllib2.httperror # handle exception\n
    - bear in mind that merely decompressing a zip file may result in a security\n
      vulnerability.\n
    - as always, solution is trivial use django.test.testcase not unittest.testcase.\n
      and it works in all major versions of django!\n
    -  virtualenv to create a contained virtual environment (prevent different\n
      versions of python or python packages from stomping on each other). there is increasing\n
      buzz from people moving to this tool. the author is the same as the older working-env.py\n
      mentioned by aaron. pip to install packages inside a virtualenv. the traditional\n
      is easy_install as answered by s. lott, but pip works better with virtualenv.\n
      easy_install still has features not found in pip though. scons as a build tool,\n
      although you won''t need this if you stay purely python. fabric paste, or paver\n
      for deployment. buildbot for continuous integration. bazaar, mercurial, or git\n
      for version control. nose as an extension for unit testing. pyfit for fit testing.\n
    - in perl, p5nci will also do that, at least in some cases. but it seems\n
      to me that anything you use that directly manages interfacing with the dll is\n
      going to be user-unfriendly, and if you are going to have a user (scriptor?) friendly\n
      wrapper, it might as well be an xs module. i guess i don''t see a meaningful distinction\n
      between "compile and send out executables" and "compile and send out scripts".\n
    - i get completion for my own modules in my pythonpath or site-packages.\n
      i''m not sure what version of the pythoncomplete.vim script you''re using, but\n
      you may want to make sure it''s the latest. edit here''s some examples of what\n
      i''m seeing on my system... this file (mymodule.py), i puth in a directory in\n
      pythonpath, and then in site-packages. both times i was able to get the screenshot\n
      below. myvar ='test'' def myfunction(foo=''test'') pass class myclass(object)\n
      pass\n
    - it seems that this isn''t supported, since there wouldn''t be a good way\n
      to deal with overflows in datetime.time. i know this isn''t an answer directly,\n
      but maybe someone with more python experience than me can take this a little further.\n
      for more info, see this\n
    - python has pytz ( module which can be used for arithmetic of'time'' objects.\n
      it takes care of dst offsets as well. the above page has a number of examples\n
      that illustrate the usage of pytz.\n
    - retrieve the times in milliseconds and then do the subtraction.\n
    - environment.tickcount seems to work well if you need something quick. int\n
      start = environment.tickcount ...dosomething() int elapsedtime = environment.tickcount\n
       start jon\n
    - i did this once before in a django server. there''s two parts - client-side\n
      and server-side. client side you will have to send out xmlhttprequests to the\n
      server as the user is typing, and then when the information comes back, display\n
      it. this part will require a decent amount of javascript, including some tricky\n
      parts like callbacks and keypress handlers. server side you will have to handle\n
      the xmlhttprequests which will be something that contains what the user has typed\n
      so far. like a url of and then respond with the suggestions encoded in some way.\n
      (i''d recommend json-encoding the suggestions.) you also have to actually get\n
      the suggestions from your database, this could be just a simple sql call or something\n
      else depending on your framework. but the server-side part is pretty simple. the\n
      client-side part is trickier, i think. i found this article helpful he''s writing\n
      things in php, but the client side work is pretty much the same. in particular\n
      you might find his css helpful.\n
    - also a little silly, but you could try picking an arbitrary day and embedding\n
      each time in it, using datetime.datetime.combine, then subtracting  import datetime  t1\n
      datetime.time(2,3,4)  t2 = datetime.time(18,20,59)  dummydate = datetime.date(2000,1,1)  datetime.datetime.combine(dummydate,t2)\n
       datetime.datetime.combine(dummydate,t1) datetime.timedelta(0, 58675)\n
    - firstly, note that a datetime.time is a time of day, independent of a given\n
      day, and so the different between any two datetime.time values is going to be\n
      less than 24 hours. one approach is to convert both datetime.time values into\n
      comparable values (such as milliseconds), and find the difference. t1, t2 = datetime.time(...),\n
      datetime.time(...) t1_ms = (t1.hour*60*60 + t1.minute*60 + t1.second)*1000 + t1.microsecond\n
      t2_ms = (t2.hour*60*60 + t2.minute*60 + t2.second)*1000 + t2.microsecond delta_ms\n
      max([t1_ms, t2_ms]) - min([t1_ms, t2_ms]) it''s a little lame, but it works.\n
    - the essence of your question is "how come these class variables (which\n
      i assign field objects to) suddenly become instance variables (which i assign\n
      data to) in django''s orm"? the answer to that is the magic of python metaclasses.\n
      a metaclass allows you to hook into and modify the process of creating a python\n
      class (not the creation of an instance of that class, the creation of the class\n
      itself). django''s model object (and thus also your models, which are subclasses)\n
      has a modelbase metaclass. it looks through all the class attributes of your model,\n
      and any that are instances of a field subclass it moves into a fields list. that\n
      list is assigned as an attribute of the _meta object, which is a class attribute\n
      of the model. thus you can always get to the actual field objects via mymodel._meta.fields,\n
      or mymodel._meta.get_field(''field_name''). the model.__init__ method is then\n
      able to use the _meta.fields list to determine what instance attributes should\n
      be initialized when a model instance is created. don''t be afraid to dive into\n
      the django source code; it''s a great source of education!\n
    - yes, first_name and last_name are class variables. they define fields that\n
      will be created in a database table. there is a person table that has first_name\n
      and last_name columns, so it makes sense for them to be at class level at this\n
      point. for more on models, see when it comes to accessing instances of a person\n
      in code, you are typically doing this via django''s orm, and at this point they\n
      essentially behave as instance variables. for more on model instances, see\n
    - you may want to consider using a different type of loop where that logic\n
      is applicable, because it is the most obvious answer. perhaps a i=2 while i  n\n
      if something do something i += 1 else do something else i = 2 #restart the loop\n
    - changing the index variable i from within the loop is unlikely to do what\n
      you expect. you may need to use a while loop instead, and control the incrementing\n
      of the loop variable yourself. each time around the for loop, i is reassigned\n
      with the next value from range(). so something like i = 2 while i  n if(something)\n
      do something else do something else i = 2 # restart the loop continue i += 1\n
      in my example, the continue statement jumps back up to the top of the loop, skipping\n
      the i += 1 statement for that iteration. otherwise, i is incremented as you would\n
      expect (same as the for loop).\n
    - you could try with and then parse the xml result.\n
    - you could transform both into timedelta objects and subtract these from\n
      each other, which will take care to of the carry-overs. for example  import datetime\n
      as dt  t1 = dt.time(23, 5, 5, 5)  t2 = dt.time(10, 5, 5, 5)  dt1 = dt.timedelta(hours=t1.hour,\n
      minutes=t1.minute, seconds=t1.second, microseconds=t1.microsecond)  dt2 = dt.timedelta(hours=t2.hour,\n
      minutes=t2.minute, seconds=t2.second, microseconds=t2.microsecond)  print(dt1-dt2)\n
      130000  print(dt2-dt1) -1 day, 110000  print(abs(dt2-dt1)) 130000 negative\n
      timedelta objects in python get a negative day field, with the other fields positive.\n
      you could check beforehand comparison works on both time objects and timedelta\n
      objects  dt2  dt1 true  t2  t1 true\n
    - if you want the auto-complete to use date from your own database, you''ll\n
      need to do the search yourself and update the suggestions using ajax as users\n
      type. for the search part, you might want to look at lucene.\n
    - i do exactly this with a combination of setuptools and hudson. i know hudson\n
      is a java app, but it can run python stuff just fine.\n
    - you will want easy_setup to get the eggs (roughly what maven calls an artifact).\n
      for setting up your environment, have a look at working-env.py python is not compiled\n
      but you can put all files for a project in an egg. this is done with setuptools\n
      for ci, check this answer.\n
    - i also work with both java and python. for python development the maven\n
      equivalent is setuptools ( for web application development i use this in combination\n
      with paster ( for the deployment process\n
    - other than easy_install? for our linux servers, we use easy_install and\n
      yum. for our windows development laptops, we use easy_install and a few msi''s\n
      for some projects. most of the python libraries we use are source-only, so we\n
      can use the same distribution on all boxes. if we could have a network shared\n
      device, we''d put them all there. sadly, our infrastructure is kind of scattered,\n
      so we have to either move .tar files around or redo the installs to rebuild the\n
      environments. in a few cases (e.g., pil), we have to recompile and check the version\n
      numbers.\n
    - in perl, win32api is an easy way to some interfacing to dlls. there is\n
      also inlinec, if you have access to a compiler and the windows headers. perl\n
      xsubs can also create an interface between perl and c.\n
    - once i generated ctags for one of my site-packages, it started working\n
      for that package -- so i''m guessing that the omnicomplete function depends on\n
      ctags for non-sys modules. edit not true at all. here''s the problem -- poor\n
      testing on my part -- omnicomplete was working for parts of my project, just not\n
      most of it. the issue was that i''m working on a django project, and in order\n
      to import django.db, you need to have an environment variable set. since i couldn''t\n
      import django.db, any class that inherited from django.db, or any module that\n
      imported a class that inherited from django.db wouldn''t complete.\n
    - one way to call c libraries from python is to use ctypes  from ctypes\n
      import *  windll.user32.messageboxa(none, "hello world", "ctypes", 0);\n
    - for python, you could compile an extension which links to the dll, so that\n
      in python you could just import it like a normal module. you could do this by\n
      hand, by using a library like boost.python, or by using a tool such as swig (which\n
      also supports perl and other scripting languages) to generate a wrapper automatically.\n
    - the python py_initmodule api function allows you to create a module from\n
      cc++ functions which can then be call from python. it takes about a dozen or\n
      so lines of cc++ code to achieve but it is pretty easy code to write the zeus\n
      editor that i wrote, uses this appoach to allow zeus macros to be written in python\n
      and it works very well.\n
    -  and i know one other blog where the author was developing a parser for\n
      qfxqif... lemme look it up... googling hasnt helped yet ( update found one\n
      more\n
    - a partial class is simply a class that''s contained in more than one file.\n
      sometimes it''s so that one part can be machine-generated, and another part user-edited.\n
      i use them in c# when i''m making a class that''s getting a bit too large. i''ll\n
      put the accessors and constructors in one file, and all of the interesting methods\n
      in a different file. in perl, you''d simply have two (or more) files that each\n
      declare themselves to be in a package (main program) use myclass; (in myclass.pm)\n
      use myclassotherstuff; package myclass; # [..class code here...] (in myclassotherstuff.pm)\n
      package myclass; # [...rest of code here...]\n
    - in 10 years of web development i''ve had 1 client have me write an email\n
      parsing app with it. not that it doesn''t get used, but i''ve seen rubyphp.net\n
      way more often in the wild. edit from the other posts if you plan on working\n
      at google, it sounds like the language to learn - lol!\n
    - in many large companies it is a primary scripting language. google is using\n
      it along with java and c++ and almost nothing else. also many web pages are built\n
      on top of python and django. another place is game development. many games have\n
      their engines written in c++ but all the logic in python. in other words it is\n
      one of the most valuable tools. this might be of interest for you as well is\n
      python good for big software projects (not web based)? are there any good reasons\n
      why i should not use python? what did you use to teach yourself python?\n
    - it definitely has job value. for instance google requires it. have a look\n
      at google openings in india excellent programming skills in at least one of the\n
      following languages c, c++, java or python (c++python preferred)\n
    - try looking at mark pilgrim''s excellent book "dive into python" which\n
      is available for download under gnu free documentation license. hth cheers, rob\n
    - the c# partial class has been already explained here so i''ll just cover\n
      the python part. you can use multiple inheritance to elegantly distribute the\n
      definition of a class. class a_part1 def m1(self) print "m1" class a_part2\n
      def m2(self) print "m2" class a(a_part1, a_part2) pass a = a() a.m1() a.m2()\n
    - not sure about india, but you can get a decent overview of available python\n
      jobs on the python.org jobs page here.\n
    - the concept of partial types have already been explained. this can be done\n
      in python. as an example, do the following in a python shell. class a(object)\n
      pass obj = a() def _some_method(self) print self.__class__ a.identify = _some_method\n
      obj.identify()\n
    - everywhere. it''s used extensively by google for one. see list of python\n
      software for more info, and also who uses python on the web?\n
    - because python is a dynamic language you don''t need a concept like partial\n
      class. in python is possible to extend object with functionality in runtime so\n
      it possible to break class declaration into different files\n
    - a partial type (it doesn''t have to be a class; structs and interfaces\n
      can be partial too) is basically a single type which has its code spread across\n
      multiple files. the main use for this is to allow a code generator (e.g. a visual\n
      studio designer) to "own" one file, while hand-written code is put in another.\n
      i''ve no idea whether pythonperl have the same capabilities, i''m afraid.\n
    - you could try the fnmatch module, it''s got a shell-like wildcard syntax.\n
    - a partial type is a type whose declaration is separated across multiple\n
      files. it makes sense to use them if you have a big class, which is hard to handle\n
      and read for a typical developer, to separate that class definition in separate\n
      files and to put in each file a logically separated section of code (for instance\n
      all public methods and proprieties in one file, private in other, db handling\n
      code in third and so on..) no you don''t have the same syntactical element in\n
      python.\n
    - python also has meta classes but that is more like a template class than\n
      a partial class. a good example of meta class usage is the django orm. all of\n
      your table models inherit from a base model class which also gets functionality\n
      included from a meta class. it is a pretty cool concept that enables an active\n
      record like pattern (is it full active record?).\n
    - seems to work fine for me. check out the methods in the official python\n
      documentation for random  import random  random.random() 0.69130806168332215  random.uniform(1,\n
      10) 8.8384170917436293  random.randint(1, 10) 4\n
    - you probably have a file named random.py or random.pyc in your working\n
      directory. that''s shadowing the built-in random module. you need to rename random.py\n
      to something like my_random.py andor remove the random.pyc file. to tell for\n
      sure what''s going on, do this  import random  print random.__file__ that will\n
      show you exactly which file is being imported.\n
    - ajaxterm has a terminal, with mostly felicitous terminal emulation, done\n
      on the python backend (it just pushes display updates to the client javascript).\n
      the ajaxterm website has been down for some time, but you can still find it packaged\n
      in debian.\n
    - this is happening because you have a random.py file in the python search\n
      path, most likely the current directory. python is searching for modules using\n
      sys.path, which normally includes the current directory before the standard site-packages,\n
      which contains the expected random.py. this is expected to be fixed in python\n
      3.0, so that you can''t import modules from the current directory without using\n
      a special import syntax. just remove the random.py + random.pyc in the directory\n
      you''re running python from and it''ll work fine.\n
    - is it possible that the script you run is called random.py itself?\n
    - try anyterm ajaxterm webshell\n
    - i think you need to give some more information. it''s not really possible\n
      to answer why it''s not working based on the information in the question. the\n
      basic documentation for random is at you might check there.\n
    - can you post an example of what you''re trying to do? it''s not clear from\n
      your question what the actual problem is. here''s an example of how to use the\n
      random module import random print random.randint(0,10)\n
    - python 2.5.2 (r25260911, jun 16 2008, 182758) [gcc 3.3.4 (pre 3.3.5\n
      20040809)] on linux2 type "help", "copyright", "credits" or "license" for more\n
      information.  import random  random.seed()  dir(random) [''bpf'','log4'','nv_magicconst'',\n
     'recip_bpf'','random'','sg_magicconst'','systemrandom'','twopi'','wichmannhill'',\n
     '_builtinmethodtype'','_methodtype'','__all__'','__builtins__'','__doc__'',\n
     '__file__'','__name__'','_acos'','_ceil'','_cos'','_e'','_exp'',\n
     '_hexlify'','_inst'','_log'','_pi'','_random'','_sin'','_sqrt'',\n
     '_test'','_test_generator'','_urandom'','_warn'','betavariate'','choice'',\n
     'expovariate'','gammavariate'','gauss'','getrandbits'','getstate'','jumpahead'',\n
     'lognormvariate'','normalvariate'','paretovariate'','randint'','random'',\n
     'randrange'','sample'','seed'','setstate'','shuffle'','uniform'','vonmisesvariate'',\n
     'weibullvariate'']  random.randint(0,3) 3  random.randint(0,3) 1 \n
    - it''s juste one example but i know it is widely used in large scientific\n
      institutions with high tech machinery where non-programmers (typically physicists)\n
      need quick prototypes or tools to cover their data collectionprocessing needs.\n
      the easy-to access scripting language aspect clearly plays its role here. so i\n
      don''t know about building a career out of that only but i''d definitely say that\n
      knowing python is a very valuable asset on your resume, it''ll strengthen your\n
      "smell of usefulness".\n
    - works for me python 2.5.1 (r25154863, jun 15 2008, 182451) [gcc 4.3.0\n
      20080428 (red hat 4.3.0-8)] on linux2 type "help", "copyright", "credits" or "license"\n
      for more information.  import random  brothers = [''larry'','curly'','moe'']  random.choice(brothers)\n
     'moe''  random.choice(brothers)'curly''\n
    - i''ve actually done this a long time ago, but it wasn''t petty. what we\n
      did is use the sawfish window manager and wrote a hook to recognize the flashplayer\n
      window, then strip all the decorations and snap it full screen. this may be possible\n
      without using the window manager, by registering for x window creation events\n
      from an external application, but i''m not familiar enough with x11 to tell you\n
      how that would be done. another option would be to write a pygtk application that\n
      embedded the standalone flash player inside a gtk.socket and then resized itself.\n
      after a bit of thought, this might be your best bet.\n
    - what version of python are you using? if you are using 2.5 or 2.6, then\n
      you should be doing your import like import string,time,sys,os,smtplib from email.mime.multipart\n
      import mimemultipart from email.mime.base import mimebase from email.mime.text\n
      import mimetext from email import encoders i''m pretty certain that py2exe''s\n
      modulefinder can correctly find the email package if you use it correctly (i.e.\n
      use the above names in python 2.5+, or use the old names in python 2.4-). certainly\n
      the spambayes setup script does not need to explicitly include the email package,\n
      and it includes the email modules without problem. the other answers are correct\n
      in that if you do need to specifically include a module, you use the "includes"\n
      option, either via the command-line, or passing them in when you call setup.\n
    - all pygtk extensions use autotools, so if the pygtk aspects don''t kill\n
      the whole thing for you, it might be worth having a look at the pygtk source code.\n
      additionally, here is one i wrote which is more simple.\n
    - you can use a dedicated application which sends the keystroke to the window\n
      manager, which should then pass it to flash, if the window starts as being the\n
      active window on the screen. this is quite error prone, though, due to delays\n
      between starting flash and when the window will show up. for example, your script\n
      could do something like this flashplayer *.swf sleep 3 &amp;&amp; xsendkey control+f\n
      the application xsendkey can be found here without given a specific window, it\n
      will send it to the root window, which is handled by your window manager. you\n
      could also try to figure out the window id first, using xprop or something related\n
      to it. another option is a window manager, which is able to remember your settings\n
      and automatically apply them. fluxbos for example provides this feature. you could\n
      set fluxbox to make the window decor-less and stretch it over the whole screen,\n
      if flashplayer supports being resized. this is also not-so-nice, as it would probably\n
      affect all the flashplayer windows you open ever.\n
    - use the "includes" option. see\n
    - if you don''t have to work with py2exe, bbfreeze works better, and i''ve\n
      tried it with the email module.\n
    - you could perhaps take a look at the software described here. it is a gnome\n
      applet, written in python. from the web site "the gnome wacom applet is a small\n
      gnome panel applet that shows how much pressure is being applied to your wacom\n
      tablet by the current device. clicking on the panel icon brings up a dialog allowing\n
      you to select a different device and check what pressure and tilt information\n
      is being recieved from it. this dialog also contains a small drawing test area\n
      to give your pen a quick test." google is your friend\n
    - nspluginplayer --fullscreen src=pathtoflashfile.swf which is from the\n
    - have a look at this question how-to-package-twisted-program-with-py2exe\n
      it seems to be the same problem. the answer given there is to explicitly include\n
      the modules on the command line to py2exe.\n
    - cgal-python has been inert for over a year but the code (available through\n
      the "download" link) seems to work fine, though not with python 3.\n
    - maybe pyode?\n
    - you can try .net''s own version, ironpython. it has a vs addon, ironpythonstudio.\n
      being a .net language, you can access all the available assemblies, including\n
      visual studio tools for office.\n
    - if you are looking for some game physics (collisions, deformations, gravity,\n
      etc.) which looks real and is reasonably fast consider re-using some physics engine\n
      libraries. as a first reference, you may want to look into pymunk, a python wrapper\n
      of chipmunk 2d physics library. you can find a list of various open source physics\n
      engines (2d and 3d) in wikipedia. if you are looking for physically correct simulations,\n
      no matter what language you want to use, it will be much slower (almost never\n
      real-time), and you need to use some numerical analysis software (and probably\n
      to write something yourself). exact answer depends on the problem you want to\n
      solve. it is a fairly complicated field (of math). for example, if you need to\n
      do simulations in continuum mechanics or electromagnetism, you probably need finite\n
      difference, finite volume or finite element methods. for python, there are some\n
      ready-to-use libraries, for example fipy (fvm), getfem++ (fem), fenicsdolfin\n
      (fem), and some other.\n
    - i don''t know if this will help you with 2008, but with visual studio 2005\n
      and win32com i''m able to do this  import win32com.client  b = win32com.client.dispatch(''visualstudio.dte'')  b\n
      comobject visualstudio.dte  b.name u''microsoft visual studio''  b.version u''8.0''\n
      unfortunately i don''t have 2008 to test with though.\n
    - depending on what exactly you''re trying to do, autoit may meet your needs.\n
      in fact, i''m sure it will do anything you need it to do. taken from my other\n
      post about how to use autoit with python import win32com.client oautoitx = win32com.client.dispatch(\n
      "autoitx3.control" ) oautoitx.opt("wintitlematchmode", 2) #match text anywhere\n
      in a window title width = oautoitx.wingetclientsizewidth("firefox") height = oautoitx.wingetclientsizeheight("firefox")\n
      print width, height you can of course use any of the autoitx functions (note that\n
      that link goes to the autoit function reference, the com version of autoit - autoitx\n
      has a subset of that list...the documentation is included in the download) in\n
      this way. i don''t know what you''re wanting to do, so i can''t point you towards\n
      the appropriate functions, but this should get you started.\n
    - you may also be interested in the geos library, which is available in python\n
      through shapely and the geos api included in geodjango.\n
    - django has some olap features that are nearing release. read also if you\n
      have a proper star schema design in the first place, then one-dimensional results\n
      can have the following form. from myapp.models import somefact from collections\n
      import defaultdict facts = somefact.objects.filter( dimension1__attribute=this,\n
      dimension2__attribute=that ) myaggregates = defaultdict( int ) for row in facts\n
      myaggregates[row.dimension3__attribute] += row.somemeasure if you want to create\n
      a two-dimensional summary, you have to do something like the following. facts\n
      somefact.objects.filter( dimension1__attribute=this, dimension2__attribute=that\n
      ) myaggregates = defaultdict( int ) for row in facts key = ( row.dimension3__attribute,\n
      row.dimension4__attribute ) myaggregates[key] += row.somemeasure to compute multiple\n
      sum''s and count''s and what-not, you have to do something like this. class myagg(\n
      object ) def __init__( self ) self.count = 0 self.thissum= 0 self.thatsum= 0\n
      myaggregates= defaultdict( myagg ) for row in facts myaggregates[row.dimension3__attr].count\n
      += 1 myaggregates[row.dimension3__attr].thissum += row.this myaggregates[row.dimension3__attr].thatsum\n
      += row.that this -- at first blush -- seems inefficient. you''re trolling through\n
      the fact table returning lots of rows which you are then aggregating in your application.\n
      in some cases, this may be faster than the rdbms''s native sumgroup_by. why?\n
      you''re using a simple mapping, not the more complex sort-based grouping operation\n
      that the rdbms often has to use for this. yes, you''re getting a lot of rows;\n
      but you''re doing less to get them. this has the disadvantage that it''s not so\n
      declarative as we''d like. it has the advantage that it''s pure django orm.\n
    - here is some simple astronomy related python. and here is a hardcore code\n
      from the same guy. and eagleclaw solves and plots various hyperbolic equations\n
      using some python. however, most of the code is written in fortran to do the computations\n
      and python to plot the results. if you are studying physics though you may have\n
      to get used to this kind of fortran wrapped code. it is a reality. but this isn''t\n
      really what your looking for i guess. the good thing it that it is documented\n
      in a literate programming style so it should be understandable.\n
    - i''ve heard of pybox2d, which is a port of the really nice box2d. to quote\n
      the site box2d is a feature rich 2d rigid body physics engine, written in c++\n
      by erin catto. it has been used in many games, including crayon physics deluxe,\n
      winner of the 2008 independent game festival grand prize.\n
    - the fastest would probably be just to look at the code and re-implement\n
      it yourself in python. carrying around all of cgal just for this tiny bit seems\n
      redundant. also this calculation doesn''t strike me as something that would extremely\n
      benefit by running compiled.\n
    - nice beginner reference with similar content to's answer perl tutorial\n
      using regular expressions\n
    - here is how import gobject class mygobjectclass(gobject.gobject) ...\n
      gobject.signal_new("signal-name", mygobjectclass, gobject.signal_run_first, none,\n
      (str, int)) where the second to last argument is the return type and the last\n
      argument is a tuple of argument types.\n
    -  [...] in any style command the first row index may be set to one of the\n
      special strings [...] in your first example you''re setting the second row index\n
      to a special string as well. not sure why the other two don''t work... are you\n
      sure this is where the exception is coming from?\n
    - the shelve module uses an underlying database package (such as dbm, gdbm\n
      or bsddb) . the restrictions pragraph says (my emphasis) the shelve module does\n
      not support concurrent readwrite access to shelved objects. (multiple simultaneous\n
      read accesses are safe.) when a program has a shelf open for writing, no other\n
      program should have it open for reading or writing. unix file locking can be used\n
      to solve this, but this differs across unix versions and requires knowledge about\n
      the database implementation used. conclusion it depends on os and the underlying\n
      db. to keep things portable, do not build on concurrency.\n
    - if you use kiwi available here you can just do from kiwi.utils import\n
      gsignal class myobject(gobject.gobject) gsignal(''signal-name'')\n
    - to build on chris'' response, it''s probably most relevant to encase the\n
      g regex in a while loop, like my ; while ('foobarbaz'' =~ m([aeiou])g )\n
      { push , \n1; } pasting some quick python io  import re  re.findall(r''([aeiou])([nrs])'',''i\n
      had a sandwich for lunch'') [(''a'','n''), (''o'','r''), (''u'','n'')] to\n
      get something comparable in perl, the construct could be something like my \nmatches\n
      []; while ('i had a sandwich for lunch'' =~ m([aeiou])([nrs])g ) { push\n
      \nmatches, [\n1,\n2]; } but in general, whatever function you''re iterating for,\n
      you can probably do within the while loop itself.\n
    - use the g modifier in your match. from the perlop manual the "g" modifier\n
      specifies global pattern matching--that is, matching as many times as possible\n
      within the string. how it behaves depends on the context. in list context, it\n
      returns a list of the substrings matched by any capturing parentheses in the regular\n
      expression. if there are no parentheses, it returns a list of all the matched\n
      strings, as if there were parentheses around the whole pattern. in scalar context,\n
      each execution of "mg" finds the next match, returning true if it matches, and\n
      false if there is no further match. the position after the last match can be read\n
      or set using the pos() function; see "pos" in perlfunc. a failed match normally\n
      resets the search position to the beginning of the string, but you can avoid that\n
      by adding the "c" modifier (e.g. "mgc"). modifying the target string also resets\n
      the search position.\n
    - you can also define signals inside the class definition class mygobjectclass(gobject.gobject)\n
      __gsignals__ = { "some-signal" (gobject.signal_run_first, gobject.type_none,\n
      (object, )), } the contents of the tuple are the the same as the three last arguments\n
      to gobject.signal_new.\n
    - well, it looks as if i will be answering my own question. first, the documentation\n
      flat out lies where it reads "in any style command the first row index may be\n
      set to one of the special strings'splitlast'' or'splitfirst'' to indicate\n
      that the style should be used only for the last row of a split table, or the first\n
      row of a continuation." in the current release, the "splitlast" and "splitfirst"\n
      row indices break with the aforementioned typeerrors on the textcolor and background\n
      commnds. my suspicion, based on reading the source code, is that only the tablestyle\n
      line commands (grid, box, lineabove, and linebelow) are currently compatible with\n
      the'splitfirst'' and'splitlast'' row indices. i suspect that all cell commands\n
      break with the aforementioned typeerrors. however, i was able to do what i wanted\n
      by subclassing the table class and overriding the onsplit method. here is my code\n
      class xtable(table) def onsplit(self, t, byrow=1) t.setstyle(tablestyle([ (''textcolor'',\n
      (0, 1), (1, 1), colors.black)])) what this does is apply the text color black\n
      to the first and second cell of the second row of each page. (the first row is\n
      a header, repeated by the repeatrows parameter of the table.) more precisely,\n
      it is doing this to the first and second cell of each frame, but since i am using\n
      the simpledoctemplate, frames and pages are identical.\n
    - i''d try to debug it with pdb. the issue is most likely with the easy install''s\n
      method check_site_dir, which seeks for easy-install.pth.\n
    - i am a fan of pyglet which is a completely self contained library for doing\n
      graphical work under win32, linux, and os x. it has very low overhead, and you\n
      can see this for yourself from the tutorial on the website. it should play well\n
      with wxpython, or at least i seem to recall posts to the mailing list about wxpython\n
      and pyglet being used together. it however does not offer selection of objects\n
      via mouse clicks - this you will have to handle yourself. generally speaking for\n
      a 2d application this is not too difficult to do. mactorii is an os x application\n
      of mine written in pure python+pyglet, and has some basic animation (scrolling)\n
      and click detection. it doesn''t use wxpython, but perhaps it will give you an\n
      idea of what is involved. note however mactorii is using the old pyglet api, so\n
      the run loop i have in there is obsolete. i will get around to updating it one\n
      day... p\n
    - reinstall setuptools with the command easy_install --always-unzip --upgrade\n
      setuptools. if that fixes it then the zipping was the problem.\n
    - update new version of google appengine supports data import to and export\n
      from the online application natively. in their terms this is called upload_data\n
      and download_data respectively (names of subcommands of appcfg.py). please refer\n
      to google documentation how to export and import data fromto gae. this is probably\n
      the better way to do it today. my old answer is below i use to_xml() method of\n
      the model class to export the datastore. class xmlexport(webapp.requesthandler)\n
      def get(self) objects=mymodel.all().fetch(1000) xml=''?xml version="1.0" encoding="utf-8"?\nsite\n''\n
      for o in objects xml = xml + o.to_xml() xml = xml +'site'' self.response.headers[''content-type'']=''textxml;\n
      charset=utf-8'' self.response.out.write(xml)\n
    - you can, of course, write your own handler. other than that, your options\n
      currently are limited to gae-rest, which provides a restful interface to the\n
      datastore. approcket, a tool for replicating between mysql and app engine. the\n
      amusingly named gaebar - google app engine backup and restore.\n
    - try granting the apache user (the user that the apache service is running\n
      under) r+w permissions on that file.\n
    - doesn''t apache''s error log give you a clue? maybe it has to do with selinux.\n
      check varlogauditaudit.log and adjust your selinux configuration accordingly,\n
      if the audit.log file indicates that it''s selinux which denies apache access.\n
    - the permission denied error is showing that the script is running with\n
      root credentials, because it''s looking in root''s home dir for files. i suggest\n
      you change the hook script to something that does id  tmpid so that you can\n
      check the results of that to make sure what the uidgid and euidegid are. you\n
      will probably find it''s not actually running as the user you think it is. my\n
      first guess, like troels, was also selinux, but that would only be my guess if\n
      you are absolutely sure the script through apache is running with exactly the\n
      same usergroup as your manual test.\n
    - well, thanks to all who answered the question. anyway, i think i solved\n
      the mistery. selinux is completely disabled on the machine, so the problem is\n
      definitely in'svn co'' not being able to found config_dir for the user account\n
      it runs under. apache  mod_python doesn''t read in shell environment of the user\n
      account which apache is running on. thus for examle no \nhome is seen by mod_python\n
      when apache is running under some real user ( not nobody ) now'svn co'' has\n
      a flag --config-dir which points to configuration directory to read params from.\n
      by default it is \nhome.subversion, i.e. it corresponds to the user account home\n
      directory. apparently when no \nhome exists mod_python goes to root home dir (\n
      root) and tries to fiddle with .subversion content over there - which is obviously\n
      fails miserably. putting setenv home homeqa into the etchttpdconfhttpd.conf\n
      doesn''t solve the problem because of setenv having nothing to do with shell environment\n
       it only sets apache related environment likewise pythonoption - sets only mod_python\n
      related variables which can be read with req.get_options() after that running\n
     'svn co --config-dir home ...'' definitely gives a workaround for running from\n
      within mod_python, but gets in the way of those who will try to run the script\n
      from command line. so the proposed ( and working) solution is to set home environment\n
      variable prior to starting appache. for example in etcinit.dhttpd script qahome=homeqa\n
      ... home=\nqahome lang=\nhttpd_lang daemon \nhttpd \noptions\n
    - python is designed to support more than just object-oriented programming.\n
      preserving the same interface between methods and functions lets the two styles\n
      interoperate more cleanly. ruby was built from the ground up to be object-oriented.\n
      even the literals are objects (evaluate 1.class and you get fixnum). the language\n
      was built such that self is a reserved keyword that returns the current instance\n
      wherever you are. if you''re inside an instance method of one of your class, self\n
      is a reference to said instance. if you''re in the definition of the class itself\n
      (not in a method), self is the class itself class c puts "i am a #{self}" def\n
      instance_method puts'instance_method'' end def self.class_method puts'class_method''\n
      end end at class definition time,'i am a c'' will be printed. the straight'def''\n
      defines an instance method, whereas the'def self.xxx'' defines a class method.\n
      c=c.new c.instance_method #= instance_method c.class_method #= class_method\n
    - self is used only as a convention, you can use spam, bacon or sausage instead\n
      of self and get the same result. it''s just the first argument passed to bound\n
      methods. but stick to using self as it will confuse others and some editors.\n
    - well, i don''t know much about ruby. but the obvious point about python''s\n
      "self" is that it''s not a "keyword" ...it''s just the name of an argument that''s\n
      sent to your method. you can use any name you like for this argument. "self" is\n
      just a convention. for example  class x  def __init__(a,val)  a.x = val def\n
      p(b)  print b.x x = x(6) x.p() prints the number 6 on the terminal. in the constructor\n
      the self object is actually called a. but in the p() method, it''s called b. update\n
     in october 2008, guido pointed out that having an explicit self was also necessary\n
      to allow python decorators to be general enough to work on pure functions, methods\n
      or classmethods \n
    - it sounds like the environment you apache process is running under is a\n
      little unusual. for whatever reason, svn seems to think the user configuration\n
      files it needs are in root. you can avoid having svn use the root versions of\n
      the files by specifying on the command line which config directory to use, like\n
      so svn --config-dir homemyuser.subversion checkout while not fixing your enviornment,\n
      it will at least allow you to have your script run properly...\n
    - despite webmat''s claim, guido wrote that explicit self is "not an implementation\n
      hack -- it is a semantic device". the reason for explicit self in method definition\n
      signatures is semantic consistency. if you write class c def foo(self, x, y)\n
      ... this really is the same as writing class c pass def foo(self, x, y) ...\n
      c.foo = foo this was an intentional design decision, not a result of introducing\n
      oo behaviour at a latter date. everything in python -is- an object, including\n
      literals. see also why must'self'' be used explicitly in method definitions\n
      and calls?\n
    - using the direct_to_template generic view would be a lot simpler. you could\n
      use the passed in parameters on one view to specify the actual template in urls.py,\n
      if you don''t want to add an entry for each page r''^foo(?ptemplate_name.+)\n'',''direct_to_template'',\n
      {''template'''foo_index.html''}), then import the template in your foo_index.html\n
      {% include template_name %}\n
    - actually, i tried many of these alternatives, and neither worked. calling\n
      close() or terminate() hangs (both with true and false as parameters) calling\n
      wait() or read(-1) or expect(pexpect.eof) hangs calling spawn again without caring\n
      about the previous spawn command hangs i made some tests with other commands (like\n
     'ftp'', and they work as i''d expect, for example, if you call .expect(''something''),\n
      and something is not found before eof, they don''t wait forever, they throw an\n
      exception, so i believe this is related to the ssh-copy-id command specifically.\n
    - reading pexpect documentation for spawn, i think it is waiting for the\n
      command to terminate. i would suggest a couple of different possibilities, depending\n
      on your needs 1) kill the spawned process. however, this may lead to corruption\n
      in your operation, so i do not know if it is what you want. child = pexpect.spawn(''command'')\n
      child.expect(''password'') child.sendline(''the password'') child.close(true)\n
      2) wait for completion of the initial task before moving to the next one child\n
      pexpect.spawn(''command'') child.expect(''password'') child.sendline(''the\n
      password'') child.wait() child = pexpect.spawn(''command2'') ... 3) use a different\n
      instance for all children, then wait on all of them at the end - and this would\n
      be most probably the best solution def exec_command(cmd) child = pexpect.spawn(cmd)\n
      child.expect(''password'') child.sendline(''the password'') return child commands\n
      [''command1'','command2''] childrens = [exec_command(cmd) for cmd in commands]\n
      for child in childrens child.wait() note all of the code here is untested, and\n
      written under the assumption that your script is hanging because deleting a spawn\n
      object will hang until the command will terminate.\n
    - i think the problem is, that ssh tries to open pty and it does not work\n
      on anything else than pty for security reasons. this won''t work well with pexpect.\n
      i have another ssh client it''s open-source, you can use it. what you are trying\n
      to do would be more commands, but you don''t need expect at all. first install\n
      it accordingly to manual, then do something like this run dssh-agent, add the\n
      password you need like this dssh-add -l  passwordfile or if it is a secure machine,\n
      i.e. no one else can log in there, this is very important, otherwise this would\n
      be a huge security hole echo "name-of-server;22;root;password;" | dssh-add -l\n
      password file would be something like name-of-server;22;root;password; and the\n
      do something like (replace contents of ... with actual content of that file)\n
      dssh root-of-server -- echo "contents of ~.sshidentity.pub"  .sshauthorized_keys\n
      \; chmod og-w .ssh .sshauthorized_keys you can (optionally) do dssh-add -f passwords\n
      (make sure no one else is doing all this stuff, otherwise you would have a race\n
      condition). also, pexpect should probably work with dssh itself (so you don''t\n
      need to use dssh-agent). but using dssh-agent is simpler and safer. installation\n
      manual for dssh is contained in the tarball. i don''t know any simpler way of\n
      doing this, openssh ssh-copy-id is very picky about where the password comes from...\n
    - try dynamically extending the bases that way you can take advantage of\n
      the mro and the methods are actual methods class parent(object) def bar(self)\n
      print "bar" class metafoo(type) def __new__(cls, name, bases, dict) return type(name,\n
      (parent,) + bases, dict) class foo(object) __metaclass__ = metafoo if __name__\n
      == "__main__" f = foo() f.bar() print f.bar.func_name\n
    - for the record, my code now looks like this def runstuff(commandline)\n
      outputfilename ='somefile.txt'' outputfile = open(outputfilename, "w") if guimode\n
      result = subprocess.call(commandline, shell=true, stdout=outputfile, stderr=subprocess.stdout)\n
      else proc = subprocess.popen(commandline, shell=true, stdout=subprocess.pipe,\n
      stderr=subprocess.stdout, stdin=subprocess.pipe) proc.stdin.close() proc.wait()\n
      result = proc.returncode outputfile.write(proc.stdout.read()) note that, due to\n
      an apparent bug in the subprocess module, the call to popen() has to specify a\n
      pipe for stdin as well, which we close immediately afterwards.\n
    - sys.stdin and sys.stdout handles are invalid because pythonw does not provide\n
      console support as it runs as a deamon, so default arguments of subprocess.call()\n
      are failing. deamon programs close stdinstdoutstderr purposedly and use logging\n
      instead, so that you have to manage this yourself i would suggest to use subprocess.pipe.\n
      if you really don''t care about what the sub process says for errors and all,\n
      you could use os.devnull (i''m not really sure how portable it is?) but i wouldn''t\n
      recommend that.\n
    - i don''t think that there is any chance to access inner() from the extern\n
      namespace. however, in my opinion the fact that you keep inner() nested implies\n
      that the only "contract" that really matters is outer()''s one. inner() is part\n
      of the implementation, and you shouldn''t want to test the implementation. if\n
      you really want to test inner(), do extensive tests on outer() with data that\n
      will involve all the functionalities of inner().\n
    - the python convention is to name "private" functions and methods with a\n
      leading underscore. when you see a leading underscore, you know not to try and\n
      use it. remember, python is not java.\n
    - inner doesn''t exist until outer makes it. you should either move inner\n
      up to a toplevel function for testability, or have the outer test test all the\n
      possible execution paths of itself and inner. do note that the inner function\n
      isn''t a simple function, it''s a closure. consider this case def outer(a) b\n
      compute_something_from(a) def inner() do_something_with(a, b) that''s the standard\n
      testability trade-off. if your cyclomatic complexity is too high, your tests will\n
      be too numerous.\n
    -  classes = [x for x in globals().values() if isinstance(x, type)]\n
    - you can smash this into one for statement, but that''d have messy code\n
      duplication. import sys import types this_module = sys.modules[__name__] [x for\n
      x in [getattr(this_module, x) for x in dir(this_module)] if type(x) == types.classtype]\n
    - import sys getattr(sys.modules[__name__],'a'')\n
    - the simplest thing to do would be the run the controlling script (the python\n
      script) via sudo. are you able to do that, or is that not an option?\n
    - i think what you want to do is this  class foo() ... def __init__(self,\n
      x) ... self.x = x ...  def bar(self) ... print'bar'', self.x ...  bar.func_name\n
      ='foobar''  foo.foobar = bar  f = foo(12)  f.foobar() bar 12  f.foobar.func_name\n
     'foobar'' now you are free to pass foos to a library that expects foo instances\n
      to have a method named foobar. unfortunately, (1) i don''t know how to use metaclasses\n
      and (2) i''m not sure i read your question correctly, but i hope this helps. note\n
      that func_name is only assignable in python 2.4 and higher.\n
    - thanks. i looked at the source. there isn''t really a way to change its\n
      form. since manipulating suffix, only appends to the end of the file name. ether\n
      way, there is no way real way to manipulate the full file name, what i was hoping\n
      for was where you can declare a file mask, and when it does the "rollover" it\n
      will create a new file name based on the file mask. i am just going to go back\n
      to my original idea, was to just kill the whole logging subsystem and reinitialize\n
      it with the new file name when it rollsover. thanks tho.\n
    - i think you should remove the sudo in your popen call and require the user\n
      of your script to type sudo. this additionally makes more explicit the need for\n
      elevated privileges in your script, instead of hiding it inside popen.\n
    - don''t writing your own parser unless you want to learn how to write a\n
      parser. as already mentioned in the comments by .f. sebastian, i would suggest\n
      a full-on computer algebra system (cas) like sage. it will handle mathematical\n
      statements much more complicated than 1+1 )\n
    - A_Body "because python supports some algebraic forms, you could do eval(\"1 +\\n
      1\") but this allows the input to execute about anything defined in your env\\n
      eval(\"__import__('sys').exit(1)\") also, if you want to support something python\\n
      doesn't support, the approach fails x\xE2\xB3 + y\xE2\xB2 + c ----------- =\\n
      0 z instead of doing this, you can implement a tokenizer and a parser with ply.\\n
      evaluating a thing like1 + 1' ought not take more than ten lines or so. you\\n
      could also implement the tokenizer and the parser by hand. read about ll and\\n
      lr parsers. before attempting this it's also better to learn using parser generators\\n
      first. "\n
    - read about the input function.\n
    - perhaps eval is what you''re after?  eval(''1+1'') 2\n
    - if you are receiving an expression as a string you''ll need to parse it\n
      into its operators and operands and then process the resulting tree. this isn''t\n
      a python problem per se. but a general issue of how to deal with mathematical\n
      expressions delivered as strings. a quick google reveals a bunch of lexical parsers\n
      for python.\n
    - "how can i change how it alters the filename?" since it isn''t documented,\n
      i elected to read the source. this is what i concluded from reading the source\n
      of logginghandlers.py handler = logging.handlers.timedrotatingfilehandler("c\\isis_ops\\logs\\rotate_test",''midnight'',1)\n
      handler.suffix = "%y-%m-%d" # or anything else that strftime will allow root_logger.addhandler(handler)\n
      the suffix is the formatting string.\n
    - return the header set-cookie token=opaque; domain=.your.domain; expires=thu,\n
      01-jan-1970 000010 gmt; path= the domain and path must match the original attributes\n
      that the cookie was issued under.\n
    - just an update, i ended up going a different approach. the easiest way\n
      i found to modify the file output, was to simply use a filehandler, then when\n
      it is time to do a roll over. i do this if(current_time  old_time) for each\n
      in logging.getlogger(''debug'').handlers each.stream = open("c\\newoutput",\n
     'a'') thats the gist of it. it took alot of poking and looking around but modifying\n
      the stream is the easiest way to do so. )\n
    - there are actually two libraries that solve this, the older curses and\n
      the newer s-lang. curses has a tendency to make buggy line art, especially on\n
      windows and on unicode consoles (it''s unicode support is shit). s-lang''s screen\n
      management functions are better. while i haven''t used either of them in python,\n
      and it seems curses is better supported, in c at least i''m switching my code\n
      to s-lang because of those issues, and because deep down i never really liked\n
      the curses api.\n
    - this would require a join, which isn''t possible in app engine. if you\n
      want to filter by a property of another model, you need to include that property\n
      on the model you''re querying against.\n
    - this would result in two datastore hits but should work. if you use memcache\n
      shouldnt be a problem. group = models.group.all().filter("name =", group_name).get()\n
      members = models.groupmember.all().filter(''group ='', group)\n
    - if your groups are uniquely named, then your "group.name" is a unique identifier\n
      of a group entity. that means you can write members = models.groupmember.all().filter(\n
      "group =",model.group.gql("where name=1", group_name).get() ) though you only\n
      need to do that if you don''t already have the group entity lying around in the\n
      stack somewhere. google''s essay on many-to-many with appengine is here.\n
    - if what you want is to get the members of a group, referenceproperties\n
      have that built-in. class groupmember(db.model) group = db.referenceproperty(group,\n
      collection_name="groupmembers") user = db.referenceproperty(user, collection_name="groupmembers")\n
      then you can write # get the group entity somehow group = group.get(group_key)\n
      # do something with the members, such as list the nicknames nicknames = [x.user.nickname\n
      for x in group.groupmembers]\n
    - i wouldn''t waste time and locs on checking for permissions. ultimate test\n
      of file creation in windows is the creation itself. other factors may come into\n
      play (such as existing files (or worse, folders) with the same name, disk space,\n
      background processes. these conditions can even change between the time you make\n
      the initial check and the time you actually try to create your file. so, if i\n
      had a scenario like that, i would just design my method to not lose any data in\n
      case of failure, to go ahead and try to create my file, and offer the user an\n
      option to change the selected directory and try again if creation fails.\n
    - i recently wrote a app to pass a set of test to obtain the isv status from\n
      microsoft and i also add that condition. the way i understood it was that if the\n
      user is least priveledge then he won''t have permission to write in the system\n
      folders. so i approached the problem the the way ishmaeel described. i try to\n
      create the file and catch the exception then inform the user that he doesn''t\n
      have permission to write files to that directory. in my understanding an least-priviledged\n
      user will not have the necessary permissions to write to those folders, if he\n
      has then he is not a least-priveledge user. should i stop bothering just because\n
      windows vista itself won''t allow the least-privileged user to save any files\n
      in %windir%? in my opinion? yes.\n
    - i agree with the other answers that the way to do this is to try to create\n
      the file and catch the exception. however, on vista beware of uac! see for example\n
      "why does my application allow me to save files to the windows and system32 folders\n
      in vista?" to support old applications, vista will "pretend" to create the file\n
      while in reality it creates it in the so-called virtual store under the current\n
      user''s profile. to avoid this you have to specifically tell vista that you don''t\n
      want administrative privileges, by including the appropriate commands in the .exe''s\n
      manifest, see the question linked above.\n
    - import os import tempfile def can_create_file(folder_path) try tempfile.temporaryfile(dir=folder_path)\n
      return true except oserror return false def can_create_folder(folder_path) try\n
      name = tempfile.mkdtemp(dir=folder_path) os.rmdir(name) return true except oserror\n
      return false\n
    - you can use curses. it has a windows port and unix port, and plenty of\n
      documentation. you can also use some helper libs.\n
    - there is a library called beautifulsoup, i think it''s what you''re looking\n
      for. as you''re trying to parse a invalid xml, the normal xml parser won''t work.\n
      beautifulsoup is more fail-tolerant, it can still extract information from invalid\n
      xml. beautiful soup is a python htmlxml parser designed for quick turnaround\n
      projects like screen-scraping. three features make it powerful beautiful soup\n
      won''t choke if you give it bad markup. it yields a parse tree that makes approximately\n
      as much sense as your original document. this is usually good enough to collect\n
      the data you need and run away. beautiful soup provides a few simple methods and\n
      pythonic idioms for navigating, searching, and modifying a parse tree a toolkit\n
      for dissecting a document and extracting what you need. you don''t have to create\n
      a custom parser for each application. beautiful soup automatically converts incoming\n
      documents to unicode and outgoing documents to utf-8. you don''t have to think\n
      about encodings, unless the document doesn''t specify an encoding and beautiful\n
      soup can''t autodetect one. then you just have to specify the original encoding.\n
      beautiful soup parses anything you give it, and does the tree traversal stuff\n
      for you. you can tell it "find all the links", or "find all the links of class\n
      externallink", or "find all the links whose urls match "foo.com", or "find the\n
      table heading that''s got bold text, then give me that text."\n
    - this previous stackoverflow question should give you some more useful information.\n
    - i would investigate using the curses module. it will take care of a lot\n
      of the details and let you focus on the higher level stuff.\n
    - it looks like there is a curses portlibrary for python\n
    - the behaviour does seem confusing, but intensional. i reproduce here the\n
      entirety of the unicode documentation from the python built-in functions documentation\n
      (for version 2.5.2, as i write this) unicode([object[, encoding [, errors]]])\n
      return the unicode string version of object using one of the following modes\n
      if encoding andor errors are given, unicode() will decode the object which can\n
      either be an 8-bit string or a character buffer using the codec for encoding.\n
      the encoding parameter is a string giving the name of an encoding; if the encoding\n
      is not known, lookuperror is raised. error handling is done according to errors;\n
      this specifies the treatment of characters which are invalid in the input encoding.\n
      if errors is'strict'' (the default), a valueerror is raised on errors, while\n
      a value of'ignore'' causes errors to be silently ignored, and a value of'replace''\n
      causes the official unicode replacement character, u+fffd, to be used to replace\n
      input characters which cannot be decoded. see also the codecs module. if no optional\n
      parameters are given, unicode() will mimic the behaviour of str() except that\n
      it returns unicode strings instead of 8-bit strings. more precisely, if object\n
      is a unicode string or subclass it will return that unicode string without any\n
      additional decoding applied. for objects which provide a __unicode__() method,\n
      it will call this method without arguments to create a unicode string. for all\n
      other objects, the 8-bit string version or representation is requested and then\n
      converted to a unicode string using the codec for the default encoding in'strict''\n
      mode. new in version 2.0. changed in version 2.2 support for __unicode__() added.\n
      so, when you call unicode(r,'utf-8''), it requires an 8-bit string or a character\n
      buffer as the first argument, so it coerces your object using the __str__() method,\n
      and attempts to decode that using the utf-8 codec. without the utf-8, the unicode()\n
      function looks for a for a __unicode__() method on your object, and not finding\n
      it, calls the __str__() method, as you suggested, attempting to use the default\n
      codec to convert to unicode.\n
    - unicode does not guess the encoding of your text. if your object can print\n
      itself as unicode, define the __unicode__() method that returns a unicode string.\n
      the secret is that unicode(r) is not actually calling __str__() itself. instead,\n
      it''s looking for a __unicode__() method. the default implementation of __unicode__()\n
      will call __str__() and then attempt to decode it using the ascii charset. when\n
      you pass the encoding, unicode() expects the first object to be something that\n
      can be decoded -- that is, an instance of basestring. behavior is weird because\n
      it tries to decode as ascii if i don''t pass'utf-8''. but if i pass'utf-8''\n
      it gives a different error... that''s because when you specify "utf-8", it treats\n
      the first parameter as a string-like object to be decoded. without it, it treats\n
      the parameter as an object to be coerced to unicode. i do not understand the confusion.\n
      if you know that the object''s text attribute will always be utf-8 encoded, just\n
      define __unicode__() and then everything will work fine.\n
    - lets try to clear up some of the confusion in the exception message. the\n
      function call sys.stdout.write(entry["title"]) returns none. the ".encode(''utf-8'')"\n
      is a call to the encode function on what is returned by the above function. the\n
      problem is that none doesn''t have an encode function (or an encode attribute)\n
      and so you get an attribute error that names the type you were trying to get an\n
      attribute of and the attribute you were trying to get.\n
    -   sys.stdout.write(entry["title"]).encode(''utf-8'') this is the culprit.\n
      you probably mean sys.stdout.write(entry["title"].encode(''utf-8'')) (notice\n
      the position of the last closing bracket.)\n
    - set the cookie again, as if you hadn''t set it the first time, but specify\n
      an expiration date that is in the past.\n
    - see, for example, extracting-text-from-html-file-using-python for suggestions\n
      regarding ways for parsing html in python.\n
    - it should be noted that while html looks like xml it is not xml. xhtml\n
      is an xml form of html.\n
    - list2 = filter( lambda x x.find('content_item_id') != -1, list1 )\n
      the filter calls the function (first parameter) on each element of list1 (second\n
      parameter). if the function returns true (non-zero), the element is copied to\n
      the output list. the lambda basically creates a temporary unnamed function. this\n
      is just to avoid having to create a function and then pass it, like this function\n
      look_for_content_item_id( elem ) if elem.find('content_item_id'') == -1 return\n
      0 return 1 list2 = filter( look_for_content_item_id, list1 )\n
    - for completeness; you can also use ifilter. it is like filter, but doesn''t\n
      build up a list. from itertools import ifilter for line in ifilter(lambda line\n
     'content_item_id'' in line, urls) do_something(line)\n
    -  the user_id field is the fk reference from idea to user. it looks like\n
      you''ve changed your model, and not updated your database, then you''ll have this\n
      kind of problem. drop the old table, rerun syncdb. your model tables get an id\n
      field by default. you can call it id in your queries. you can also use the synonym\n
      of pk. if you define your own primary key field you, you don''t get the automatic\n
      id field. but you can still use pk to refer to the primary key.\n
    - you''ll have to show your models to get real help, but it looks like your\n
      idea table doesn''t have a user_id column? did you modify the sql table structure?\n
    - we need more information. is sudo asking you for a password? what kind\n
      of interface does the mod script have for asking questions? because these kind\n
      of things are not handled as normal over the pipe. a solution for both of these\n
      might be pexpect, which is rather expert at handling funny scripts that ask for\n
      passwords, and various other input issues.\n
    - i would choose to go with pexpect. import pexpect child = pexpect.spawn\n
      (''sudo mod -p -c noresource -u dtt -q'') child.expect (''first question'') child.sendline\n
      (''y'') child.expect (''second question'') child.sendline (''yup'')\n
    - here''s another alternative to graeme''s, using the newer list comprehension\n
      syntax list2= [line for line in file if'content_item_id'' in line] which you\n
      prefer is a matter of taste!\n
    - i liked bobince''s answer (+1), but will up the ante. since you have a\n
      rather large starting set, you may wish to avoid loading the entire list into\n
      memory. unless you need the whole list for something else, you could use a python\n
      generator expression to perform the same task by building up the filtered list\n
      item by item as they''re requested for filtered_url in (line for line in file\n
      if'content_item_id'' in line) do_something_with_filtered_url(filtered_url)\n
    - i believe you want if'normal'' != root.state() tkmessagebox.showinfo("key\n
      you!", " ".join(sys.argv[1]))\n
    - a = dict((key,value) for (key,value) in a.iteritems() if key not in exclusion)\n
    - try these import re re.sub() re.findall() re.finditer() for example #\n
      finds all words of length 3 or 4 s = "the quick brown fox jumped over the lazy\n
      dogs." print re.findall(r''\b\w{3,4}\b'', s) # prints [''the'',''fox'',''over'',''the'',''lazy'',''dogs'']\n
    - you can use re.match to match anchored patterns. re.match will only match\n
      at the beginning (position 0) of the text, or where you specify. def match_sequence(pattern,text,pos=0)\n
      pat = re.compile(pattern) match = pat.match(text,pos) while match yield match\n
      if match.end() == pos break # infinite loop otherwise pos = match.end() match\n
      pat.match(text,pos) this will only match pattern from the given position, and\n
      any matches that follow 0 characters after.  for match in match_sequence(r''[^\w\d]+|\d+'',"he11o\n
      world!") ... print match.group() ... he 11 o\n
    - python does not have the g modifier for their regexen, and so do not have\n
      the \g regex token. a pity, really.\n
    - don''t try to put everything into one expression as it become very hard\n
      to read, translate (as you see for yourself) and maintain. import re lines = [re.sub(r''\n
      r''\g0'', line) for line in text_block.splitlines() if not line.startedwith('''')]\n
      print'\n''.join(lines) python is not usually best when you literally translate\n
      from perl, it has it''s own programming patterns.\n
    - i usually give my clickable objects a click function, like in your example.\n
      i put all of those objects in a list, for easy iteration when the click functions\n
      are to be called. when checking for which mousebutton you press, use the button\n
      property of the event. import pygame from pygame.locals import * #this lets you\n
      use pygame''s constants directly. for event in pygame.event.get() if event.type\n
      == mousebuttondown #better to seperate to a new if statement aswell, since there''s\n
      more buttons that can be clicked and makes for cleaner code. if event.button ==\n
      1 for object in clickableobjectslist object.clickcheck(event.pos) i would say\n
      this is the recommended way of doing it. the click only registers once, so it\n
      wont tell your sprite if the user is "dragging" with a button. that can easily\n
      be done with a boolean that is set to true with the mousebuttondown event, and\n
      false with the mousebuttonup. the have "draggable" objects iterated for activating\n
      their functions... and so on. however, if you don''t want to use an event handler,\n
      you can let an update function check for input with pygame.mouse.get_pos() pygame.mouse.get_pressed().\n
      this is a bad idea for larger projects, since it can create hard to find bugs.\n
      better just keeping events in one place. smaller games, like simple arcade games\n
      might make more sense using the probing style though.\n
    - i guess the best way is to set the expiration to a date of the cookie to\n
      some date in the past.\n
    - you could change your exclusion list to a set, then just use intersection\n
      to get the overlap. exclusion = set([3, 4, 5]) for key in exclusion.intersection(a)\n
      del a[key]\n
    - a very short introduction provides pypi minimock 1.0. it''s a very small\n
      library to establish mocks. inject your mock into the module, that should be mocked\n
      define, what your mock will return call the method your mock will say, which method\n
      were called. good luck!\n
    - why not just use the keys method, instead of iterkeys? that way you can\n
      do it in one loop because it returns a list, not an iterator.\n
    - the advantage of deployment for php is a huge one. you will also have a\n
      large developer base, and sound like you already have considerable expertise.\n
      in general if you know how to use a programming language well, you are safer to\n
      stick with it. the advantages of using a python web framework like pylons are\n
      that your code will be neater, and more maintainable. of course this is possible\n
      with php, but seems much harder to achieve. python is simply a nicer language\n
      than php, so that might affect your decision. personally, i would not describe\n
      either pylons or cherrypy as an "application server", if you want a python application\n
      server, try zope. (they both do serve wsgi applications, but that is a topic for\n
      another question.) there seem to be plenty of equivalent frameworks for php, and\n
      they have been listed in other answers.\n
    - using application servers like pylons, django, etc. require much more work\n
      to setup and deploy then php applications which are generally supported out of\n
      the box. i run a few django apps and had to learn a bit of configuring apache\n
      with mod_python in order to get things to work. i put forth the effort because\n
      coding in python is much more enjoyable to me than php and after you get the apache\n
      config right once you never really have to mess with it again. on another note,\n
      if you decide to go with a framework like django, rails, pylons, .... they tend\n
      to solve a lot of small repetitive tasks that you would otherwise do on your own.\n
      but frameworks are their own huge topic of discussion.\n
    - consider dict.pop for key in exclusion a.pop(key, none) the none keeps\n
      pop from raising an exception when key isn''t a key.\n
    - there are several products in php which fill the same space as cherrypy\n
      or pylons. (except, of course, they don''t run python ;) have a look at - cakephp\n
       symfony - code igniter - zend framework - personally, i prefer drupal, which\n
      works as a great framework and comes with a lot of cms and community site features\n
      out of the box. the ones above are quite different in many ways, but any of these\n
      should offer you the best of both worlds if you want an app framework  appserver\n
      that runs on php. drupal - which one is the right choice is largely a matter of\n
      taste, although each has its various advantages and disadvantages. there are many\n
      more - these are just the ones i''ve heard good things about from colleagues and\n
      collaborators. it''s not a complete list.\n
    - python web-apps tend to require more initial setup and development than\n
      the equivalent php site (particularly so for small sites). there also tend to\n
      be more reusable pieces for php (ie wordpress as a blog). configuring a server\n
      to run python web-apps can be a difficult process, and not always well documented.\n
      php tends to be very easy to get running with apache. also, as php is very widely\n
      used and is heavily used by beginners, there tends to be very good documentation\n
      for it. however, python is much more fun, and much more maintainable. it scales\n
      well (in development complexity terms, rather than traffic). personally, i would\n
      also say that using python tends to train you to solve problems in a better way.\n
      i am definitely a better developer for having learned the pythonic way of doing\n
      things.\n
    - i have a feeling that some of the responses didn''t address the initial\n
      question directly, so i decided to post my own. i understand that the question\n
      was about the difference between the mod_php deployment model and the application\n
      server deployment model. in simple words, php executes a given script on every\n
      request, and the application has no knowledge of what has happened before (unless\n
      it is emulated somehow). moreover even the source code is being parsed on every\n
      request (unless you use a bytecode cache like apc). this process can be slow,\n
      especially if you have a framework with complex initialization. in contrast to\n
      this, the application server has to be started once, and then it waits for a request\n
      to be processed. the application server should clean up resources after every\n
      requests (allocated memory, open descriptors, etc.), it can also pool certain\n
      resources (like database connections) that can be reused between requests for\n
      extra performance. this later model (application server) is more efficient in\n
      most cases, but on the other hand more difficult to setup and maintain. it is\n
      also more demanding, as you have to pay more attention to the resources you utilize,\n
      in order to avoid resource leaks.\n
    - they''re essentially the same. the python interpreter will only load a\n
      used module once, no matter how many times you import it. changing the location\n
      of the import statement only has an effect on where the name is bound -- for example,\n
      if your import statement is inside a function, the name can only be used in that\n
      function. generally, though, imports are usually done as close to the "top" of\n
      a file as possible.\n
    - you might want to look at combo box that suggests options. i hope this\n
      is what you were thinking of.\n
    - i agree with s.lott, that you should write out an example of what you want\n
      to generate. solving a problem with code generation should be less complicated\n
      than without. this is because your total program has to deal with a lot of input\n
      information, and if a subset of that information changes very seldom, like once\n
      a week, the code generator only has to condition on that subset. the generated\n
      code conditions on the remaining input that changes more frequently. it''s a divide-and-conquer\n
      strategy. another name for it is "partial evaluation". generated code should also\n
      run a lot faster because it''s less general. in your specific case, there''s no\n
      harm in doing the code generation in 2 (or more) passes. like on pass 1 you generate\n
      declarations. on pass 2 you generate process code. alternatively you could generate\n
      two output streams, and concatenate them at the end. hope that helps. sorry if\n
      i''m just saying what''s obvious.\n
    - from what i think i''ve understood you have two options you could either\n
      use an xml style "markup" to let them define entities and their groupings, but\n
      that may not be best. your alternatives are yes, yoou could embedd a language,\n
      but do you really need to, wouldnt that be overkill, and how can you control it?\n
      if you only need really simple syntax then perhaps write your own language. its\n
      actually not that hard to create a simple interpreter, as long as you have a strict,\n
      unambiguous language. have a look for some examples of compilers in whatever youre\n
      using, c#? i wrote a very simple interperter in java at uni, it wasnt as hard\n
      as you''d think.\n
    - the mechanize main page says mechanize.browser is a subclass of mechanize.useragentbase,\n
      which is, in turn, a subclass of urllib2.openerdirector my understanding is that\n
      urllib2 is one of the sandboxed modules in gae, with its functionality being replaced\n
      by the google-provided urlfetch. you''d need to re-implement the mechanize.useragentbase\n
      class to use urlfetch, if that''s at all possible.\n
    - i don''t believe you''ll be able to log in to a windows domain account\n
      in this way. you need to set up a user in sql directly for this manner of passing\n
      credentials.\n
    - i haven''t done it in a while, but i remember the whole unixodbc + freetds\n
      + pyodbc thing being a little tricky. however, it can be done, and once setup\n
      it''s not that hard. this website provides very good instructions (archived copy\n
      on web archive) also, in my experience pyodbc had issues compilingrunning on\n
      64 bit linux machines. because of that we eventually used ceodbc. ceodbc isn''t\n
      quite as stable as pyodbc (encountered more unexpected bugs than in pyodbc when\n
      running in python prorgram), but it is very easy to get up and running on linux\n
      64 bit.\n
    - while it might be great fun to create this mini-language and code it all\n
      up, the real questions you need to ask are what is the business case for adding\n
      this feature  facility? who is going to pay for this feature? who is going to\n
      "sign off" on this feature if you build it? "really neat" features have a way\n
      of getting built when the reality might indicate the true answer to such a request\n
      is "no". see if you have a stakeholder willing to sponsor this before proceeding.\n
      then check with the end users to see what they really want before committing to\n
      the project. cheers, -r\n
    - to add to s.lott''s comment, here''s how you eval a python script from\n
      c#\n
    - here''s a pythonic solution for building a dsl that you can use to compile\n
      and create byte code arrays. write a simple module that makes your c# structures\n
      available to python. the goal is to define each c# class that users are allowed\n
      to work with (composites or commands or whatever) as a python class. usually,\n
      this involves implementing a minimal set of methods with different conversions\n
      from c# types to native python types and vice versa. write some nice demos showing\n
      how to use these python class definitions to create their scripts. you should\n
      be able to create things like this in python. import * from someinterfacemodule\n
      scenario= scenario( delay(1), repeat( range(10), directpower( 23, false, 150),\n
      wait(3), directpower( 23, false, 150) ) ) scenario.compile() these are relatively\n
      simple classes to define. each class here be reasonably easy to implement as python\n
      modules that directly call your base c# modules. the syntax is pure python with\n
      no additional parsing or lexical scanning required.\n
    - contextual imports are technically more efficient, but i think they can\n
      create other problems. later, if you want to add a similar except clause, you\n
      now have two places to maintain the same block of code. you also now have the\n
      problem of testing the exception, to make sure that the first import doesn''t\n
      cause any unforeseen issues in your code.\n
    - when gae throws a 500, you can see the actual error in the logs on your\n
      admin console. if that doesn''t help, paste it here and we''ll help further. also,\n
      does it work on the dev_appserver?\n
    - i wouldn''t know a straightforward way, especially since from the interpreter''s\n
      pov, there is not that much of a difference between a method of a class and any\n
      other variable (methods have descriptors, but that''s it...). so when you only\n
      want non-callable class members, you have to fiddle around a little  class cols\n
      ... name = "name" ... ... def foo(cls) pass  import inspect  def get_vars(cls)\n
      ... return [name for name, obj in cls.__dict__.iteritems() if not name.startswith("__")\n
      and not inspect.isroutine(obj)]  get_vars(cols) [''name'']\n
    - thanks all for the prompt reply. here is the log content got from the gae,\n
     no module named clientform traceback (most recent call last) file "basedatahomeappsseoapp1.28main.py",\n
      line 10, in import mechanize file "basedatahomeappsseoapp1.28mechanizeinit.py",\n
      line 85, in from _mechanize import version file "basedatahomeappsseoapp1.28mechanize_mechanize.py",\n
      line 15, in from _useragent import useragentbase file "basedatahomeappsseoapp1.28mechanize_useragent.py",\n
      line 16, in import _opener file "basedatahomeappsseoapp1.28mechanize_opener.py",\n
      line 23, in import _http file "basedatahomeappsseoapp1.28mechanize_http.py",\n
      line 22, in from _html import unescape, unescape_charref file "basedatahomeappsseoapp1.28mechanize_html.py",\n
      line 12, in import sgmllib, clientform\n
    - this is a microoptimization. don''t worry about it.\n
    - try enc = msg[''content-transfer-encoding''] it''s a header so you won''t\n
      be able to get it looking at the body. you should be able to get at the same place\n
      you find out the subject.\n
    - one technique i''ve used for code generation is to not worry at all about\n
      formatting in the code generator. then, as a next step after generating the code,\n
      run it through indent to format it reasonably so you can read (and more importantly,\n
      debug) it.\n
    - i wrote cog partly to generate c++ code from an xml data schema. it lets\n
      you use python code embedded in c++ source files to generate c++ source.\n
    - see tooling to build test cases. it''s not clear what your problem is.\n
      if you question is "how do i handle all the special cases in my generating classes?"\n
      then here''s some advice. if your question is something else, then update your\n
      question. use a template generator. mako, for example, will make your life simpler.\n
      write an example of your result. replace parts with \n{thing} placeholders. since\n
      you started with something that worked, turning it into a template is easy. when\n
      generating code in another language, you need to have all of the class definitions\n
      in other other language designed for flexible assembly. you want to generate as\n
      little fresh, new code as possible. you want to tweak and customize a bit, but\n
      you don''t want to generate a lot of stuff from scratch. special cases are best\n
      handled with ordinary polymorphism. separate subclasses of a common superclass\n
      can implement the various exceptions and special cases. really complex situations\n
      are handled well by the strategy design pattern. in essence, you have python classes\n
      that represent the real-world objects. those classes have attributes that can\n
      be fit into a c++ template to generate the c++ version of those objects.\n
    - you would need to write your own type editor. you can think of this as\n
      a user control, in that when you write your own type editor you are providing\n
      the ui controls that appear when the property grid edits the property. as such,\n
      you can create a type editor that does anything, which means if you have a third-party\n
      editor control you can include it as part of type editor. some resources to get\n
      you started user interface type editors overview walkthrough implementing a\n
      ui type editor uitypeeditor class how to implement a ui type editor rich design\n
      time editing with uitypeeditors (vb.net) creating property editors in designtime\n
      for vs.net easily (uitypeeditor helper) using propertygrid\n
    - i have a code generation system and one of the best choices i have taken\n
      with it is to put much of the resultant program in non generated code, e.g. a\n
      libraryruntime. using templates works well also. complex template systems may\n
      be hard to work with by hand, but your not working with them by hand so leverage\n
      that.\n
    - it would actually be just recursing straight down, except i need to pull\n
      all function declarations out and put them elsewhere, and the fact that for all\n
      function calls i need to build a vector of all of the arguments, and then pass\n
      that to the function, since c++ doesn''t have a syntax for vectors.\n
    - your __enter__ method needs to return the object that should be used for\n
      the "as g" part of the with statement. see the documentation, where it states\n
      if a target was included in the with statement, the return value from __enter__()\n
      is assigned to it. currently, it has no return statement, so g gets bound to none\n
      (the default return value)\n
    - the performance differences between these two approaches will be very small\n
      in practice. i have never seen a case where this has made a difference that was\n
      noticeable. it is worth remembering that the python interpreter will only ever\n
      do the work of parsing the module once when it is 1st imported. in general you\n
      will end up with more maintainable code it you just import all the modules you\n
      need at the top of the file.\n
    - i wrote an 8-puzzle solver in lisp about a year ago. i just used a list\n
      of 3 lists, each sublist with 3 elements being the numbers. it''s not constant\n
      time, but it is portable. anyways, if you are really interested in doing this\n
      functionally (scheme doesn''t require you to) what is easiest to do is to create\n
      some helper functions that will get a specific value given rowcol and'set''\n
      a value given rowcol. instead of modifying the original data structure, the set\n
      operation will construct the new state based on the old state. then you can write\n
      a swap operation based on these get and set operations. here''s what i wrote about\n
      a year ago in common lisp, but it''s easily convertible to scheme ; getval ;\n
      ; this function takes a position (r . c) where and returns the corresponding ;\n
      number in the 8-puzzle state. for example, if you wanted (1 . 2) from ; ((1 2\n
      3) (4 5 6) (7 8 9)), the value would be 6. the r and c values begin ; at 0. ;\n
      ; parameters pos the position to get ; state the 8-puzzle state ; returns the\n
      value at pos in state (defun getval (pos state) (if (null state)'no-value (if\n
      (= 0 (car pos)) (if (= 0 (cdr pos)) (caar state) (getval (cons (car pos) (- (cdr\n
      pos) 1)) (list (cdar state)))) (getval (cons (- (car pos) 1) (cdr pos)) (cdr state)))))\n
      ; setval ; ; this function returns a state where the value at pos is replaced\n
      by val. ; like getval, this function is zero-based. accessing beyond the size\n
      of ; the state is undefined (and probably broken) ; ; parameters pos position\n
      to set ; val value to set ; state state to modify ; returns new state where pos\n
      is val (defun setval (pos val state) (if (null state)'() (if (= 0 (car pos))\n
      (if (= 0 (cdr pos)) (cons (cons val (cdar state)) (cdr state)) (let ((temp (setval\n
      (cons (car pos) (- (cdr pos) 1)) val (cons (cdar state) (cdr state))))) (cons\n
      (cons (caar state) (car temp)) (cdr temp)))) (cons (car state) (setval (cons (-\n
      (car pos) 1) (cdr pos)) val (cdr state)))))) ; state-swap ; ; this function takes\n
      a state and two positions and returns a new state with ; the values in those two\n
      positions swapped. ; ; parameters state state to swap within ; a position to\n
      swap with b ; b position to swap with a ; return state with a swapped with b\n
      (defun state-swap (state a b) (let ((olda (getval a state)) (oldb (getval b state)))\n
      (setval a oldb (setval b olda state))))\n
    - you identified that your initial problem was trying to write c semantics\n
      in lisp. is it not repeating the mistake to try to write scheme semantics in python?\n
      i always try to learn language x as a paradigm as much as a language and write\n
      in the most x-ish way. it might be justifiable if this was a business app you\n
      knew was going to be migrated, but otherwise i''d just write it in scheme to begin\n
      with.\n
    - i can finally manage with gae''s urlfetch instead of mechanizer. i can\n
      able to retrieve the response using the above said utility. thanks all for the\n
      great timely help. ^ponmalar\n
    - import inspect inspect.getmembers(cols) there are a lot if things you can\n
      do with the inspect module\n
    - here''s one way to achieve it. recreate the list using a function which\n
      will apply the appropriate mapping. def swap(p, (r1,c1), (r2,c2)) def getitem(r,c)\n
      if (r,c) == (r1,c1) return p[r2][c2] elif (r,c) == (r2,c2) return p[r1][c1]\n
      return p[r][c] return [ [getitem(r,c) for c in range(len(p[0]))] for r in range(len(p))\n
      ] you could even take this a step further and make the function be the actual\n
      interface, where each swap merely returns a function that does the appropriate\n
      conversions before passing through to the function below. not particularly performant,\n
      but a fairly simple functional approach that dispenses with nasty mutable datastructures\n
      def swap(f, (r1,c1), (r2,c2)) def getitem(r,c) if (r,c) == (r1,c1) return f(r2,c2)\n
      elif (r,c) == (r2,c2) return f(r1,c1) return f(r,c) return getitem l=[ [1,2,3],\n
      [4,5,6], [7,8,0]] f=lambda r,c l[r][c] # initial accessor function f=swap(f,\n
      (2,1), (2,2)) # 8 right f=swap(f, (1,1), (2,1)) # 5 down print [[f(x,y) for y\n
      in range(3)] for x in range(3)] # gives [[1, 2, 3], [4, 0, 6], [7, 5, 8]]\n
    - it depends on how often you execute the contextual import. an import statement\n
      requires checking to see if the module exists, which has a non-zero cost. lots\n
      of contextual imports will be a performance penalty for no real gain in simplicity.\n
      there''s very little benefit, unless you are really sure that the import will\n
      be used rarely or never. contextual imports inside if statements make sense, especially\n
      when it''s done at the top level, which means precisely once. if someconfig import\n
      this as bigdeal else import that as bigdeal\n
    - cool, thanks for the lisp code. i''ll need to study it to make sure i get\n
      it. as for the first answer, the first time i was "writing c" in lisp because\n
      that''s the only way i knew how to program and didn''t have a clue why anyone\n
      would use lisp. this time around, i''ve been playing around with scheme, but wanted\n
      to use python so if i got stuck on something i could "cheat" and use something\n
      pythonish, then while waiting for usenet answers go on to the next part of the\n
      problem.\n
    - this looks like a perfect scenario for a simple dsl. see for some information.\n
      you could also use a scripting language such as lua.net.\n
    - since in python you use duck typing you can write your own stream class\n
      and hand an instance of that class to imagefromstream. i think you only need to\n
      implement the read method and make it return your data.\n
    - django is a clean project that has a nice range of unit testing. have a\n
      look at how they propose you test your own projects. have a look at the unit testing\n
      code of the framework itself.\n
    - if you really just want a dirt simple language, you want a'recursive\n
      descent parser''. for example, a language like this scenario myscenario delay\n
      1 count 1 add 1 direct_power 23, false, 150 wait 3 ... end_scenario you might\n
      have a grammar like scenario 'scenario'' label newline _cmds end_scenario\n
      cmds _delay or _count or _direct_power or... delay'delay'' number which\n
      gives code like def scenario() match_word(''scenario'') scenario_name = match_label()\n
      emit(''var scenario = new scenario();'') cmds() match_word(''end_scenario'') emit(''byte[]\n
     ' + scenario_name +' = scenario.compile();'') def delay() match_word(''delay'')\n
      length = match_number() emit(''scenario.add(new delaycommand(''+ length +''))'')\n
      def cmds() word = peek_next_word() if word =='delay'' delay() elif ...\n
    - you should be using setuptools it allows you to lock the dependancies\n
      of an application, so even if multiple versions of an egg or package exist on\n
      a system only the right one will ever be used. this is a better way of working\n
      rather than fail if the wrong version of a dependancy is present it is better\n
      to ensure that the right version is present. setuptools provides an installer\n
      which guarantees that everything required to run the application is present at\n
      install-time. it also gives you the means to select which of the many versions\n
      of a package which may be present on your pc is the one that gets loaded when\n
      you issue an import statement.\n
    - as you say you have 0 control over the servers and can''t make your clients\n
      post trigger files as suggested by s. lott, you must deal with the imperfect solution\n
      and risk incomplete file transmission, perhaps by waiting for a while and compare\n
      file sizes before and after. you can try to rename as you suggested, but as you\n
      have 0 control you can''t be sure that the ftp-server-administrator (or their\n
      successor) doesn''t change platforms or ftp servers or restricts your permissions.\n
      sorry.\n
    - if you are dealing with multiple files, you could get the list of all the\n
      sizes at once, wait ten seconds, and see which are the same. whichever are still\n
      the same should be safe to download.\n
    - A_Body "\xE2\x80\x9Cdamn the torpedoes! full speed ahead!\xE2\x80\x9D just download\\n
      the file. if it is a large file then after the download completes wait as long\\n
      as is reasonable for your scenario and continue the download from the point\\n
      it stopped. repeat until there is no more stuff to download. "\n
    - i am somewhat new to python as well, but from what i understand although\n
      you can install multiple versions of the "same" egg (having the same name), only\n
      one of them will be available to any particular piece of code at runtime (based\n
      on your discovery method). so if your egg is the one calling this code, it must\n
      have already been selected as the version of my_project for this code, and your\n
      access will be to your own version.\n
    - exactly. so you should only be able to get the information for the currently\n
      available egg (singular) of a library. if you have multiple eggs of the same library\n
      in your site-packages folder, check the easy-install.pth in the same folder to\n
      see which egg is really used -) on a site note this is exactly the point of\n
      systems like zc.buildout which lets you define the exact version of a library\n
      that will be made available to you for example while developing an application\n
      or serving a web application. so you can for example use version 1.0 for one project\n
      and 1.2 for another.\n
    - import sys # argv is your commandline arguments, argv[0] is your program\n
      name, so skip it for n in sys.argv[1] print(n) #print out the filename we are\n
      currently processing input = open(n, "r") output = open(n + ".out", "w") # do\n
      some processing input.close() output.close() then call it like .foo.py bar.txt\n
      baz.txt\n
    - well, your specs point directly at a somewhat famous open source project,\n
      the python library. have a look at pythontrunklibtestregrtest.py, which will\n
      find all modules whose name is "test_*" in the test directory, and run them.\n
    - you may find the fileinput module useful. it is designed for exactly this\n
      problem.\n
    - i think what you miss is how to retrieve all the files in that directory.\n
      to do so, use the glob module. here is an example which will duplicate all the\n
      files with extension *.txt to files with extension *.out import glob list_of_files\n
      glob.glob(''.*.txt'') # create the list of file for file_name in list_of_files\n
      fi = open(file_name,'r'') fo = open(file_name.replace(''txt'','out''),'w'')\n
      for line in fi fo.write(line) fi.close() fo.close()\n
    - i''ve just learned of the os.walk() command recently, and it may help you\n
      here. it allows you to walk down a directory tree structure. import os output_dir\n
      ='c\\results'' for path, dirs, files in os.walk(''.'') for file in files\n
      read_f = open(os.join(path,file),''r'') write_f = open(os.path.join(output_dir,file))\n
      # do stuff\n
    - combined answer incorporating directory or specific list of filenames arguments\n
      import sys import os.path import glob def processfile(filename) filehandle =\n
      open(filename, "r") for line in filehandle # do some processing pass filehandle.close()\n
      def outputresults(filename) output_filemask = "out" filehandle = open("%s.%s"\n
      % (filename, output_filemask), "w") # do some processing filehandle.write(''processed\n'')\n
      filehandle.close() def processfiles(args) input_filemask = "log" directory =\n
      args[1] if os.path.isdir(directory) print "processing a directory" list_of_files\n
      glob.glob(''%s*.%s'' % (directory, input_filemask)) else print "processing\n
      a list of files" list_of_files = sys.argv[1] for file_name in list_of_files\n
      print file_name processfile(file_name) outputresults(file_name) if __name__ ==\n
     '__main__'' if (len(sys.argv)  1) processfiles(sys.argv) else print'usage\n
      message''\n
    - like this? assert tuple(map(int,module.__version__.split("."))) = (1,2),\n
      "module not version 1.2.x" this is wordy, but works pretty well. also, look into\n
      pip, which provides more advanced functionality.\n
    - you should be able to use stringio to wrap the buffer in a memory file\n
      object. ... import stringio buf = open("test.jpg", "rb").read() # buf = get_image_data()\n
      sbuf = stringio.stringio(buf) image = wx.imagefromstream(sbuf) ... buf can be\n
      replaced with any data string.\n
    - python comes with this inbuilt as part of distutils. the module is called\n
      distutils.version and is able to compare several different version number formats.\n
      from distutils.version import strictversion print strictversion(''1.2.2'')  strictversion(''1.2.1'')\n
      for way more information than you need, see the documentation  import distutils.version  help(distutils.version)\n
    - if you know the exact formatting of the version string a plain comparison\n
      will work  "1.2.2"  "1.2.1" true this will only work if each part of the version\n
      is in the single digits, though  "1.2.2"  "1.2.10" # bug! true\n
    - first, read about unittest. the documentation contains examples. second,\n
      since you want packages (not modules) the list is shorter. there are 15 packages\n
      in python 2.5 distribution. pick one at random. here''s a subset that might meet\n
      some of your criteria. bsddb 7 modules - many test - test_all.py ctypes 4 modules\n
       tests - runtests.py distutils many modules - tests - test_dist.py email many\n
      modules - tests - test_email.py sqlite3 - 2 modules - tests - (not clear if there''s\n
      an overall test, i got bored of looking)\n
    - you can''t know when the os copy is done. it could slow down or wait. for\n
      absolute certainty, you really need two files. the massive file. and a tiny trigger\n
      file. they can mess with the massive file all they want. but when they touch the\n
      trigger file, you''re downloading both. if you can''t get a trigger, you have\n
      to balance the time required to poll vs. the time required to download. do this.\n
      get a listing. check timestamps. check sizes vs. previous size of file. if size\n
      isn''t even close, it''s being copied right now. wait; loop on this step until\n
      size is close to previous size. while you''re not done a. get the file. b. get\n
      a listing again. check the size of the new listing, previous listing and your\n
      file. if they agree you''re done. if they don''t agree file changed while you\n
      were downloading; you''re not done.\n
    - maybe nose itself?\n
    - ok i figured it out put the split pattern in capturing parens and will\n
      be included in the output. you can use either \w+ or \w+  re.compile(r''(\w+)'').split(''hello,\n
      foo'') ['''','hello'',',','foo'','''] to get rid of the empty results,\n
      pass it through filter() with none as the filter function, which will filter anything\n
      that doesn''t evaluate to true  filter(none, re.compile(r''(\w+)'').split(''hello,\n
      foo'')) [''hello'',',','foo''] edit cms points out that if you use \w+\n
      you don''t need to use filter()\n
    - one can also use re.findall() for this  re.findall(r''.+?\b'','hello,\n
      foo'') [''hello'',',','foo'']\n
    - interesting. so far most re engines i tried do this split. i played a bit\n
      and found that re.compile(r''(\w+)'').split(''hello, foo'') is giving the output\n
      you expected... not sure if that''s reliable, though.\n
    - if you are talking about modules installed with easy_install, this is what\n
      you need import pkg_resources pkg_resources.require("turbogears=1.0.5") this will\n
      raise an error if the installed module is of a lower version traceback (most recent\n
      call last) file "tempplg.py", line 2, in module pkg_resources.require("turbogears=1.0.5")\n
      file "usrlibpython2.5site-packagespkg_resources.py", line 626, in require\n
      needed = self.resolve(parse_requirements(requirements)) file "usrlibpython2.5site-packagespkg_resources.py",\n
      line 528, in resolve raise versionconflict(dist,req) # xxx put more info here\n
      pkg_resources.versionconflict (turbogears 1.0.4.4 (usrlibpython2.5site-packagesturbogears-1.0.4.4-py2.5.egg),\n
      requirement.parse(''turbogears=1.0.5''))\n
    - (\w+) can give you the expected output  re.compile(r''(\w+)'').split(''hello,\n
      foo'') [''hello'',',','foo'']\n
    - try  re.compile(r''\w\b'').split(''hello, foo'') [''hello,'','foo'']\n
      this splits at the non-word characted before a boundry. your example has nothing\n
      to split on.
    - it depends on if your function is already written and cannot be changed,\n
      in which case you may need to check swig docs to see if there is already a typemap\n
      from pylist to stdvector (i think there is). if not, taking pyobject* as the\n
      argument to the function and using the python c api for manipulating lists should\n
      work fine. i haven''t had any problems with it so far. for self-documentation,\n
      i recommend typedef''ing pyobject* to some kind of expected type, like "pythonlist"\n
      so that the parameters have some meaning. this may also be useful\n
    - in addition to overriding save to provide the generated value you want,\n
      you can also use the exclude option in your modeladmin class to prevent the field\n
      from being displayed in the admin class entryadmin(admin.modeladmin) exclude\n
      (''slug'',)\n
    - the traditional way would be to create and use a setuid helper to do whatever\n
      you need. note that, however, properly writing a setuid helper is tricky (there\n
      are several attack vectors you have to protect against). the modern way would\n
      be to use a daemon (running as root, started on boot) which listens to requests\n
      from the rest of the application. this way, your attack surface is mostly limited\n
      to whichever ipc you chose (i''d suggest d-bus, which seems to be the modern way).\n
      finally, if you are managing network interfaces, what you doing is very similar\n
      to what network-manager does on a modern distribution. it would be a good idea\n
      to either try to somehow integrate what you are doing with network-manager (so\n
      it will not conflict with your manipulations), or at least looks at how it works.\n
    - i''m not familiar enough with python to tell you what the necessary commands\n
      would be in that language, but you should be able to accomplish this by forking\n
      and using a pipe to communicate between the parent and child processes. something\n
      along the lines of run the program as root via sudo or suid on startup, the program\n
      immediately forks and establishes a pipe for communication between the parent\n
      and child processes the child process retains root power, but just sits there\n
      waiting for input from the pipe the parent process drops root (changes its uid\n
      back to that of the user running it), then displays the gui, interacts with the\n
      user, and handles all operations which are available to a non-privileged user\n
      when an operation is to be performed which requires root privileges, the (non-root)\n
      parent process sends a command down the pipe to the (root) child process which\n
      executes it and optionally reports back to the parent this is likely to be a bit\n
      easier to write than an independent daemon, as well as more convenient to run\n
      (since you don''t need to worry about whether the daemon is running or not), while\n
      also allowing the gui and other things which don''t need root powers to be run\n
      as non-root.\n
    - did you take a look at majordomo, or mailman?\n
    - rfc 2919 has some info and more references on this.\n
    - that specific error tells you that class variables hasn''t implemented\n
      python''s __getitem__ interface which would allow you to use [ ...] on opts. if\n
      all you want to do is print out your keys, the variables documentation seems to\n
      indicate that you can iterate over your keys for key in opts.keys() print key\n
      or you can print out the help text print opts.generatehelptext()\n
    - typically you would store the variables in your environment for later testing.\n
      opts = variables() opts.add(''fcgi'',0) env = environment(variables=opts, ...)\n
      then later you can test if env[''fcgi''] == 0 # do something\n
    - what you want is a "group" you create a group, specify that the account\n
      wanting to do the action belongs to the group, then you specify that the resource\n
      you want access to is a member of that group. sometimes group management can be\n
      kind of irritating, but it should allow you to do anything you want, and it''s\n
      the user that is authorized, not your program. (if you want your program authorized,\n
      you can create a specific user to run it as and give that user the proper group\n
      membership, then su to that group within your program to execute the operation\n
      without giving the running user the ability.)\n
    - your idea about the daemon has much merit, despite the complexity it introduces.\n
      as long as the actions don''t require some user interface interaction as root,\n
      a daemon allows you to control what operations are allowed and disallowed. however,\n
      you can use sudo to create a controlled compromise between root and normal users...\n
      simply grant sudo access to the users in question for the specific tools they\n
      need. that reduces the attack surface by allowing only "permitted" root launches.\n
    - this django snippet does what you want by defining a custom read-only widget.\n
      so you define a custom editor for the field which in fact doesn''t allow any editing.\n
    - for this particular case you can override your save method to slugify (it''s\n
      built-in method, look at django source) the title and store it in slug field.\n
      also from there you can easily check if this slug is indeed unique and change\n
      it somehow if it''s not. consider this example def save(self) from django.template.defaultfilters\n
      import slugify if not self.slug self.slug = slugify(self.title) super(your_model_name,self).save()\n
    - this snippet gives you an autoslugfield with exactly the behavior you are\n
      seeking, and adding it to your model is a one-liner.\n
    - for x in thousand[400500] pass if you are working with an iterable instead\n
      of a list, you should use itertools import itertools for x in itertools.islice(thousand,\n
      400, 500) pass if you need to loop over thousand[500], then use 501 as the latter\n
      index. this will work even if thousand[501] is not a valid index.\n
    - using for element in allelements[400501] dosomething(element) makes python\n
      create new object, and might have some impact on memory usage. instead i''d use\n
      for index in xrange(400, 501) dosomething(allelements[index]) this way also enables\n
      you to manipulate list indexes during iteration. edit in python 3.0 you can use\n
      range() instead of xrange(), but in 2.5 and earlier versions range() creates a\n
      list while xrange() creates a generator, which eats less of your precious ram.\n
    - you''ve got a couple options. one is to write a supressions file for valgrind\n
      that turns off reporting of stuff that you''re not working on. python has such\n
      a file, for example if valgrind doesn''t like your setup, another possibility\n
      is using libmudflap; you compile your program with gcc -fmudflap -lmudflap, and\n
      the resulting code is instrumented for pointer debugging. described in the gcc\n
      docs, and here\n
    - for element in allelements[400501] # do something these are slices and\n
      generate a sublist of the whole list. they are one of the main elements of python.\n
    - just pass the label in as a string argument to order_by result_exp = sqlalchemy.sql.expression.label(''result'',\n
      ((test2_table.c.a * test2_table.c.b) - (test2_table.c.x + test2_table.c.y)  test2_table.c.z))\n
      select([result_exp], from_obj=[test2_table], order_by="result")\n
    - you could create and distribute a selinux policy for your application.\n
      selinux allows the kind of fine-grained access that you need. if you can''t or\n
      won''t use selinux, then the daemon is the way to go.\n
    - there''s no single user that is halfway between a "normal" user and root.\n
      you have root, and then you have users; users can have differing levels of capabilities.\n
      if you want something that''s more powerful than a "normal" user but not as powerful\n
      as root, you just create a new user with the capabilities you want, but don''t\n
      give it the privileges you don''t want it to have.\n
    - currently, it looks like sqlalchemy is working on it, but it''s incomplete\n
     unfinished. good luck!\n
    - there is an orm for google app engine. there are some differences between\n
      it and sqlalchemy, but looks like it works. check this page\n
    - in the past, i''ve disabled python readline by rebuilding it from source\n
      configure --disable-readline this might be overkill, though, for your situation.\n
    - you are looking for the undocumented function inspect.classify_class_attrs(cls).\n
      pass it a class and it will return a list of tuples (''name'','kind'' e.g.'method''\n
      or'data'', defining class, property). if you need information on absolutely\n
      everything in a specific instance you''ll have to do additional work. example  import\n
      inspect  import pprint  import calendar   hc = calendar.htmlcalendar()  hc.__class__.pathos\n
      none  calendar.calendar.phobos = none  pprint.pprint(inspect.classify_class_attrs(hc.__class__))\n
      [... (''__doc__'','data'', class'calendar.htmlcalendar'','\n this calendar\n
      returns complete html pages.\n'), ... (''__new__'','data'', type'object'',\n
      built-in method __new__ of type object at 0x814fac0), ... (''cssclasses'','data'',\n
      class'calendar.htmlcalendar'', [''mon'','tue'','wed'','thu'','fri'',\n
     'sat'','sun'']), (''firstweekday'','property'', class'calendar.calendar'',\n
      property object at 0x98b8c34), (''formatday'','method'', class'calendar.htmlcalendar'',\n
      function formatday at 0x98b7bc4), ... (''pathos'','data'', class'calendar.htmlcalendar'',\n
      none), (''phobos'','data'', class'calendar.calendar'', none), ... ]\n
    - this is more-or-less impossible without static analysis, and even then,\n
      it won''t always work. you can get the line where a function was defined and in\n
      which file by examining its code object, but beyond that, there''s not much you\n
      can do. the inspect module can help with this. so import ab a = ab.a() meth =\n
      a.x # so, now we have the method. func = meth.im_func # and the function from\n
      the method. code = func.func_code # and the code from the function! print code.co_firstlineno,\n
      code.co_filename # or import inspect print inspect.getsource(meth), inspect.getfile(meth)\n
      but consider def some_method(self) pass ab.a.some_method = some_method ab.a.some_class_attribute\n
      none or worse some_cls = ab.a some_string_var ='another_instance_attribute''\n
      setattr(some_cls, some_string_var, none) especially in the latter case, what do\n
      you want or expect to get?\n
    - you are looking for the inspect module, specifically inspect.getsourcefile()\n
      and inspect.getsourcelines(). for example a.py class hello(object) def say(self)\n
      print 1  from a import hello  hi = hello()  inspect.getsourcefile(hi.say) a.py  inspect.getsourcelines(a,\n
      foo) (['' def say(self)\n print 1\n''], 2) given the dynamic nature of python,\n
      doing this for more complicated situations may simply not be possible...\n
    - i would not run the application full time as root, but you might want to\n
      explore making your application setuid root, or setuid to some id that can become\n
      root using something like sudo for particular applications. you might be able\n
      to set up an account that cannot login, use setuid to change your program''s id\n
      (temporarily when needed) and have sudo set up to not prompt for password, but\n
      always allow access to that account for specific tasks. this way your program\n
      has no special privileges when running normally, only elevates it''s privileges\n
      when needed, and is restricted by sudo to only running certain programs. it''s\n
      been awhile since i''ve done much unix development, so i''m not really sure whether\n
      it''s possible to set up sudo to not prompt for a password (or even if there is\n
      an api for it), but as a fallback you could enable setuid to root only when needed.\n
      [edit] looks like sudo has a nopasswd mode so i think it should work since you''re\n
      running the programs as external commands.\n
    - well, i had to look into a solution. this works (ugly, and wo javascript\n
      validation) -- using the smtplib lib. also, note that i stole jeff''s captcha\n
      for this example. anyone using this will need to change it. edit i added validation.\n
      #!usrlocalbinpython2.4 import smtplib import cherrypy class inputexample\n
      .expose def index(self) return "htmlheadheadbodya href="contactus"contact usabodyhtml"\n
      .expose def contactus(self,message='''') return """ html headtitlecontact ustitle\n
      script type="textjavascript" function isnotempty(elem) { var str = elem.value;\n
      var re = .+; if (!str.match(re)) { elem.focus(); return false; } else { return\n
      true; } } function isemailaddr(elem) { var str = elem.value; var re = ^[\w-]+(\.[\w-]+)*([\w-]+\.)+[a-za-z]{2,7}\n;\n
      if (!str.match(re)) { return false; } else { return true; } } function validateform(form)\n
      { if (isnotempty(form.firstname) &amp;&amp; isnotempty(form.lastname)) { if (isnotempty(form.email))\n
      { if (isemailaddr(form.email)) { if (isnotempty(form.captcha)) { if ( form.captcha.value==''egnaro''.split("").reverse().join(""))\n
      { if (isnotempty(form.subject)) { alert("all required fields are found. we will\n
      respond shortly."); return true; } } else { alert("please enter the word as displayed\n
      in the image."); return false; } }captcha empty } else { alert("please enter\n
      a valid email address."); return false; } email } email } first and last\n
      name alert("please fill in all required fields."); return false; } script head\n
      body p%(message)sp form method=''post'' action=''contactussubmitted'' onsubmit=''return\n
      validateform(this)'' label for="firstname"first name label input type="text"\n
      id="firstname" name="firstname"  (required)br label for="lastname"last name\n
      label input type="text" id="lastname" name="lastname"  (required)br label for="email"e-mail\n
      address label input type="text" id="email" name="email"  (required)br label\n
      for="phone"phone number label input type="text" id="phone" name="phone"  brbr\n
      !--this needs to be changed to match your own captcha scheme!! -- label for="captcha"enter\n
      the wordbr img alt="rhymes with.." src=" width="99" height="26" border="0" labelbr\n
     (a href=" it spokena)br  input tabindex="3" id="captcha" name="captcha" br\n
      br  label for="subject"subject label input type="text" id="subject" name="subject"\n
     (required)br label for="body"details label textarea id="body" name="body"textareabr\n
      input type=''submit'' value=''contact us''  form body html """%{''message''message}\n
      .expose def contactussubmitted(self, firstname, lastname, email, phone, captcha,\n
      subject, body ) if captcha[-1] !='egnaro'' return self.contactus("please\n
      reenter the word you see in the image." ) self.sendemail(''mail2.example.com'',''mailbox_account'',''mailbox_pwd'',''me.com'',email,\n
     'website contact'+subject,'sender email' + email +'\r\n'''name'\n
      + firstname +'' + lastname +'\r\n'' +'phone' + phone +'\r\n'' + body)\n
      return self.index() def sendemail(self,smtpserver, mailboxname, mailboxpassword,\n
      contactemail,senderemail,subject,body) server = smtplib.smtp(smtpserver) #''smtp1.example.com'')\n
      server.login(mailboxname, mailboxpassword) msg = "to %(contactemail)s\r\nfrom\n
      %(senderemail)s\r\nsubject %(subject)s\r\ncontent-type textplain\r\n\r\n%(body)s"\n
      msg = msg%{''contactemail''contactemail,''senderemail''mailboxname +'.com'',''subject''subject,''body''body}\n
      server.sendmail(contactemail, contactemail, msg) #this is to send it from an internal\n
      account to another internal account. server.quit() cherrypy.root = inputexample()\n
      cherrypy.config.update ( file ='development.conf'' ) cherrypy.server.start()\n
    - you could use a ssh connection to the remote pc and run the commands on\n
      the other machine directly. you could even copy the python code to the machine\n
      and execute it.\n
    - it seems like you have admin media missing (hence js and images aren''t\n
      loading). i generally do following. in settings.py admin_media_prefix ='mediaadmin''\n
      then i symlink path of django.contrib.admin.media within my media dir. say ln\n
      s varlibpython-supportpython2.5djangocontribadminmedia varwwwmediaadmin\n
      development server serves admin media automatically. but on production servers\n
      one generally prefers to server static stuff directly from apache (or whatever\n
      server).\n
    - you could use a ready-made clustering solution like parallel python. you\n
      can relatively easily set up multiple remote slaves and run arbitrary code on\n
      them.\n
    - take a look at pyro (python remote objects) it has the ability to set up\n
      services on all the computers in your cluster, and invoke them directly, or indirectly\n
      through a name server and a publish-subscribe mechanism.\n
    - check the media location, permissions and setup on your deployment server.\n
    - i''m not sure what you''re asking for is possible. your best bet is probably\n
      to hide the slug from the admin interface completely by specifying your fieldsets,\n
      and than overriding the save method to copy the slug from the tile, and potentially\n
      slugifying it...\n
    - there is no way to ``block'''' signals temporarily from critical sections\n
      (since this is not supported by all unix flavors).\n
    - pod is my favorite solution to your problem.\n
    - you can build some fancy pdfs from python with the reportlab toolkit.\n
    - stackless had ability to pickle and unpickle running code. unfortunately\n
      current implementation doesn''t support this feature.\n
    - there are no direct bindings for this in python. accessing them through\n
      ctypes is easy enough; here is an example. import ctypes, signal libc = ctypes.cdll.loadlibrary("libc.so.6")\n
      libc.sighold(signal.sigkill) libc.sigrelse(signal.sigkill) i''m not familiar with\n
      the use of these calls, but be aware that python''s signal handlers work differently\n
      than c. when python code is attached to a signal callback, the signal is caught\n
      on the c side of the interpreter and queued. the interpreter is occasionally interrupted\n
      for internal housekeeping (and thread switching, etc). it is during that interrupt\n
      the python handler for the signal will be called. all that to say, just be aware\n
      that python''s signal handling is a little less asynchronous than normal c signal\n
      handlers.\n
    - for elementtree 1.2.x there is an article on reading processing instructions\n
      and comments with elementtree ( edit the alternative would be using lxml.etree\n
      which implements the elementtree api. a quote from elementtree compatibility of\n
      lxml.etree  elementtree ignores comments and processing instructions when parsing\n
      xml, while etree will read them in and treat them as comment or processinginstruction\n
      elements respectively.\n
    - read the unit testing framework section of the python library reference.\n
      a basic example from the documentation import random import unittest class testsequencefunctions(unittest.testcase)\n
      def setup(self) self.seq = range(10) def testshuffle(self) # make sure the shuffled\n
      sequence does not lose any elements random.shuffle(self.seq) self.seq.sort() self.assertequal(self.seq,\n
      range(10)) def testchoice(self) element = random.choice(self.seq) self.assert_(element\n
      in self.seq) def testsample(self) self.assertraises(valueerror, random.sample,\n
      self.seq, 20) for element in random.sample(self.seq, 5) self.assert_(element\n
      in self.seq) if __name__ =='__main__'' unittest.main()\n
    - here''s an example and you might want to read a little more on pythons\n
      unit testing.\n
    - have you tried checking out firebug''s net tab to see if the admin javascriptcssimage\n
      files are all loading correctly? i had that problem once. compare all those files\n
      from the dev server against the production server.\n
    - campfire from 37 signals - the rails guys. edit it doesn''t meet your\n
      requirements but it has some great features...\n
    - it sounds like you want to do the following. define a shared filesystem\n
      space. put all your python source in this shared filesystem space. define simple\n
      agents or servers that will "execfile" a block of code. your client then contacts\n
      the agent (rest protocol with post methods works well for this) with the block\n
      of code. the agent saves the block of code and does an execfile on that block\n
      of code. since all agents share a common filesystem, they all have the same python\n
      library structure. we do with with a simple wsgi application we call "batch server".\n
      we have restful protocol for creating and checking on remote requests.\n
    - mechanize itself only sends gets and posts, but you can easily extend the\n
      request class to send head. example import mechanize class headrequest(mechanize.request)\n
      def get_method(self) return "head" request = headrequest(" response = mechanize.urlopen(request)\n
      print response.info()\n
    - it''s probably best to start off with the given unittest example. some\n
      standard best practices put all your tests in a tests folder at the root of your\n
      project. write one test module for each python module you''re testing. test modules\n
      should start with the word test. test methods should start with the word test.\n
      when you''ve become comfortable with unittest (and it shouldn''t take long), there\n
      are some nice extensions to it that will make life easier as your tests grow in\n
      number and scope nose -- easily find and run all your tests, and more. testoob\n
      - colorized output (and more, but that''s why i use it). pythoscope -- haven''t\n
      tried it, but this will automatically generate (failing) test stubs for your application.\n
      should save a lot of time writing boilerplate code.\n
    - you can use a list comprehension domains = [matching[''domain''] for matching\n
      in matchings if matching[''id''] == the_id] which follows the format standard\n
      format of resulting_list = [item_to_return for item in items if condition] and\n
      basically encapsulates all the following functionality domains = [] for matching\n
      in matchings if matching[''id''] == the_id domains.append(matching[''domain''])\n
      all that functionality is represented in a single line using list comprehensions.\n
    - the fact that there are dictionaries in the list doesn''t really matter\n
       the problem reduces to finding an item in a list where some property is true.\n
      to that end, some variation on soviut''s answer is the way to go loop or list\n
      comprehension, examining each of the items until a match is found. there''s no\n
      inherent ordering of the items, so you couldn''t even rely on something as helpful\n
      as bisect.\n
    - the best i can figure is to do an explicit search. this is one area where\n
      i get disappointed in python is that it doesn''t give you a strong set of decoupled\n
      building blocks like in the c++ stl algorithms [d["domain"] for d in matchings\n
      if d["id"] == "someid3"]\n
    - i''d restructure matchings. from collections import defaultdict matchings_ix=\n
      defaultdict(list) for m in matchings matchings_ix[m[''id'']].append( m ) now\n
      the most efficient lookup is matchings_ix[ d ]\n
    - a partial answer the easily readable format you are looking for might\n
      be docbook. from there it is very easy to go to pdf, html, rtf, etc. etc.\n
    - and so it goes, according to this guy, you need some oil.... and it works\n
      like a charm include this lib\n
    - using jython is a great idea for this i think. but why could you not use\n
      two scripts, one with pyuno2.3 and one with pymssql2.5 (or whatever db adapter\n
      you are using)?. the intermediate format could be anything like a pickle, or json,\n
      or xml. edit i should add that i have used pyuno quite extensively, and i feel\n
      your pain.\n
    - two suggestions. suggestion one is to use a separate process instead of\n
      a separate thread. create a stand-alone xmlrpc server program. start it with subprocess.popen().\n
      kill it when the test is done. in standard os''s (not windows) the kill works\n
      nicely. in windows, however, there''s no trivial kill function, but there are\n
      recipes for this. the other suggestion is to have a function in your xmlrpc server\n
      which causes server self-destruction. you define a function that calls sys.exit()\n
      or os.abort() or raises a similar exception that will stop the process.\n
    - i think that "a" is the answer you want, but you don''t have to do it yourself.\n
      have you considered ampoule?\n
    - i think that b is problematic. the thread would only run on one cpu, and\n
      even if it runs a process, the thread is still running. a may be better. it is\n
      best to try and measure both in terms of time and see which one is faster and\n
      which one scales well. however, i''ll reiterate that i highly doubt that b will\n
      scale well.\n
    - qt''s own opengl based surfaces (using qpainter) are known to be much faster\n
      than cairo. might you explain why you want specifically cairo in qt? for the basics\n
      of using qpainter see this excerpt from the book "c++ gui programming with qt4",\n
      and while it''s c++ code, the pyqt implementation will be parallel. as for joining\n
      cairo with qt... this article in arstechnica sheds some light - it seems nothing\n
      that could help you exists currently (iow., nobody tried such marriage).\n
    - for plotting with you should also consider matplotlib, which provides a\n
      higher level api and integrates well with pyqt.\n
    - you can test if a module is installed like so \n python  import modulename\n
    - you''re running a separate copy of python provided by cygwin. you can run\n
      cygdrivecpython25python (or wherever you installed it) to get your win32 one,\n
      or just install another copy of numpy.\n
    - ensure that pythonpath has numpy. refer the module search path (section\n
      6.1.2) and modifying python''s search path (section 4.1).\n
    - i think there is something wrong in the design if you already have a file-like\n
      object if you want your data to end up in the subprocess. you should then arrange\n
      that they get written into the subprocess in the first place, rather than having\n
      them written into something else file-like first. whoever is writing the data\n
      should allow the flexibility to specify the output stream, and that should be\n
      the subprocess pipe. alternatively, if the writer insists on creating its own\n
      stream object, you should let it complete writing, and only then start the subprocess,\n
      feeding it from the result of first write. e.g. if it is a stringio object, take\n
      its value after writing, and write it into the pipe; no need for thread synchronization\n
      here.\n
    - cygwin comes with its own version of python, so it''s likely that you have\n
      two python installs on your system; one that installed under windows and one which\n
      came with cygwin. to test this, try opening a bash prompt in cygwin and typing\n
      which python to see where the python executable is located. if it says cygdrivecpython25python.exe\n
      or something similar then you''ll know you''re running the windows executable.\n
      if you see usrlocalbinpython or something like that, then you''ll know that\n
      you''re running the cygwin version. i recommend opening a dos prompt and running\n
      python from there when you need interactive usage. this will keep your two python\n
      installs nicely separate (it can be very useful to have both; i do this on my\n
      own machine). also, you may have some problems running a program designed for\n
      windows interactive console use from within a cygwin shell.\n
    - i don''t know python, so i can''t comment on what it offers, and i agree\n
      with those who suggest nagios or other existing systems. however, if you decide\n
      to roll your own system with perl, consider using poe. poe is a cooperative multitasking\n
      and networking framework. poe has a steep learning curve. but you will be repaid\n
      for you effort very quickly. poe will provide a solid foundation to build from.\n
      much of the client code you will need is already available on cpan.\n
    - inheritance can be implemented two ways in a relational model. a subclass\n
      can be a new table with all the same columns as the superclass repeated. this\n
      works well when you have an abstract superclass or subclass features that override\n
      the superclass. a subclass can be just the unique columns with a join to the superclass\n
      table. this works well when you have a concrete superclass. in your case, it looks\n
      you might have the following. class filefacts( models.model ) content_type =\n
      models.foreignkey(contenttype) object_id = models.positiveintegerfield() content_object\n
      generic.genericforeignkey() class downloadfile( models.model ) facts = models.foreignkey(\n
      filefacts ) file = models.filefield(upload_to=''files%y%m%d'') class inlineimage(\n
      models.model ) facts = models.foreignkey( filefacts ) file = models.imagefield(upload_to=''files%y%m%d'')\n
      this is my preference for handling a subclass-like model.\n
    -  i want to add a rule that checks for the presence of a folder.jpg file\n
      in each directory, but to add this would make the code substantially more messy\n
      in it''s current state.. this doesn''t look bad. in fact your current code does\n
      it very nicely, and sven mentioned a good way to do it as well get a list of\n
      all the files check for "required" files you would just have have add to your\n
      dictionary a list of required files checker = { ...'required'' [''file'',\n
     'list'','for_required''] } as far as there being a betterextensible way to\n
      do this? i am not exactly sure. i could only really think of a way to possibly\n
      drop the "multiple" regular expressions and build off of sven''s idea for using\n
      a delimiter. so my strategy would be defining a dictionary as follows (and i''m\n
      sorry i don''t know python syntax and i''m a tad to lazy to look it up but it\n
      should make sense. the regex is shorthand for a regex) check_dict = {'delim''\n
     \-,'parts''  ['show name'','episode name'','episode number'' ],'patterns''\n
     [valid name, valid episode name, valid number ],'required''  [''list'',\n
     'of'','files''],'ignored''  [''.*'','hidden.txt''],'start_dir'''pathtodirtotest''\n
      } split the filename based on the delimiter. check each of the parts. because\n
      its an ordered list you can determine what parts are missing and if a section\n
      doesn''t match any pattern it is malformed. here the parts and patterns have a\n
      1 to 1 ratio. two arrays instead of a dictionary enforces the order. ignored and\n
      required files can be listed. the . and .. files should probably be ignored automatically.\n
      the user should be allowed to input "globs" which can be shell expanded. i''m\n
      thinking here of svnignore properties, but globbing is natural for listing files.\n
      here start_dir would be default to the current directory but if you wanted a single\n
      file to run automated testing of a bunch of directories this would be useful.\n
      the real loose end here is the path template and along the same lines what path\n
      is required for "valid files". i really couldn''t come up with a solid idea without\n
      writing one large regular expression and taking groups from it... to build a template.\n
      it felt a lot like writing a textmate language grammar. but that starts to stray\n
      on the ease of use. the real problem was that the path template was not composed\n
      of parts, which makes sense but adds complexity. is this strategy in tune with\n
      what you were thinking of?\n
    - well, i work in both perl and python, and my day job is supporting a network\n
      monitoring software. most of the import points have already been covered, but\n
      i''ll consolidatereiterate here don''t reinvent the wheel - there are dozens\n
      of network monitoring solutions that you can use to perform ping tests and analyze\n
      collected data. see for example nagios zenoss opennms pynms if you insist on doing\n
      this yourself, this can be done in either perl or python - use the one you know\n
      best. if you''re planning on parsing a lot of text, it will be easier to do this\n
      "quick and dirty" in perl than it will be in python. both can do it, but python\n
      requires an oop approach and it just isn''t as easy as perl''s inline regex syntax.\n
      use libraries - many, many people have done this task before you so look around\n
      for a suitable lib like netping in perl or the icmplib in python or this ping.py\n
      code. use threads or asynchronous pings - otherwise pinging is going to take forever\n
      for example see this recipe using threads to run pings simultaneously. this is\n
      particularly easy to do in python using either approach, so this is one place\n
      python will be easier to work with imo than using perl.\n
    - maybe you should take the approach of defaulting to "the filename is correct"\n
      and work from there to disprove that statement with the fact that you only allow\n
      filenames with'show name'','season number x episode number'' and'episode\n
      name'', you know for certain that these items should be separated by a "-" (dash)\n
      so you have to have 2 of those for a filename to be correct. if that checks out,\n
      you can use your code to check that the show name matches the show name as seen\n
      in the parent''s parent folder (case insensitive i assume), the season number\n
      matches the parents folder numeric value (with or without an extra 0 prepended).\n
      if however you don''t see the correct amount of dashes you instantly know that\n
      there is something wrong and stop before the rest of the tests etc. and separately\n
      you can check if the file folder.jpg exists and take the necessary actions. or\n
      do that first and filter that file from the rest of the files in that folder.\n
    - whichever you know better or are more comfortable using. they both can\n
      do the job and do it well, so it is your preference.\n
    - different paradigms mix in different ways. for example, using oop doesn''t\n
      eliminate the use of subroutines and procedural code from an outside library.\n
      it merely moves the procedures around into a different place. it is impossible\n
      to purely program with one paradigm. you may think you have a single one in mind\n
      when you program, but that''s your illusion. your resultant code will land along\n
      the borders and within the bounds of many paradigms.\n
    - i''d say that if you need something quick and dirty that''s up and running\n
      by this afternoon, then perl is probably the better language. however for developing\n
      solid application that''s easy to maintain and extend and that you can build on\n
      over time, i''d go with python. this is of course assuming you know both languages\n
      more or less equally well.\n
    - i agree that it is pretty subjective which programming language you use\n
       essentially i would rather get the job done as quickly and efficiently as possible\n
      which making it supportable - so that depends on your infrastructure... can i\n
      suggest that you look at nagios rather than re-inventing the wheel yourself? while\n
      nagios might require a greater learning curve in terms of configuration, it will\n
      be worth it in the long run, and if you can''t find a plugin to suit your requirements,\n
      then it is easy to write your own. joel spolsky has written an interesting article\n
      on this.\n
    - go with perl. you''ll have access to a nice ping object, netping and\n
      storing the results in a database is pretty easy.\n
    - use shutil''s copyfileobj() function import shutil import subprocess proc\n
      subprocess.popen([...], stdin=subprocess.pipe) my_input = get_filelike_object(''from\n
      a place not given in the question'') shutil.copyfileobj(my_input, proc.stdin)\n
      no need to use threads.\n
    - you should use the queue module for sharing sequential data across threads.\n
      you would have to make a file-like queue subclass, where .read and .write mutually\n
      block each other, with a buffer in-between. otoh, i wonder why the first thread\n
      can''t write to the real file in the first place.\n
    - i''m not clear what you''re trying to do ehre. this sounds like a job for\n
      a regular old pipe, which is a file-like object. i''m guessing, however, that\n
      you mean you''re got a stream of some other sort. it also sounds a lot like what\n
      you want is a python queue, or maybe a tempfile.\n
    - you can pass a gameplayer object to __init__ as another argument. def __init__(self,\n
      parent, id, title, gameplayer ) ...etc... in the long run, this isn''t ideal.\n
      you should separate building an empty panel from loading that panel with data.\n
      the empty panel is one thing, populating it with data from the model is unrelated.\n
      populating a frame with data is where you must be given the gameplayer object\n
      which will be used to update the various display widgets. i''d suggest you look\n
      at the document-view framework for guidance on this. unfortunately, there aren''t\n
      any good python examples of this, so it can be confusing to convert from the c++\n
      code to python. ultimately, you have a "document" which is the main object ("gameplayer")\n
      that is being displayed. each frame is a view of that document.\n
    - i''d try the following open python shell type import modulename parse\n
      the results (no error, importerror or some module loading error) try to invoke\n
      any function from imported module (to see if module is correctly initialized).\n
      do you need something more sophisticated?\n
    - you can use perl to help you complete your task. use strict; use lwp; my\n
      \nbrowser = lwpuseragent-new; my \nresponce = \nbrowser-get(" print \nresponce-content;\n
      your responce object can tell you if it suceeded as well as returning the content\n
      of the page.you can also use this same library to post to a page. here is some\n
      documentation.\n
    - this is called web scraping, and it even has its own wikipedia article\n
      where you can find more information. also, you might find more details in this\n
      so discussion.\n
    - as long as the layout of the web page your trying to'scrape'' doesnt\n
      regularly change, you should be able to parse the html with any modern day programming\n
      language.\n
    - are you sure that the machine does not have a 128m process limit? if you\n
      are running the python script as a cgi inside a web server, it is quite likely\n
      that there is a process limit set - you will need to look at the web server configuration.\n
    - either one should work just fine. if you don''t have experience with either,\n
      flip a coin. no language is inherently productive; languages allow people to be\n
      productive. different people will benefit differently from different languages.\n
      in general, though, when you know your specific task and need to choose a tool,\n
      look for the libraries that would make your life easy. for perl, check out the\n
      comprehensive perl archive network. there are modules for just every networking\n
      thing you might need. python probably has very similar tools and libraries; i\n
      just don''t know what they are.\n
    - forget all that, python just allocates more memory as needed, there is\n
      not a myriad of comandline arguments for the vm as in java, just let it run. for\n
      all comandline switches you can just run python -h or read man python.\n
    - you really need to be more specific what is it that you want to test in\n
      your ws-consumer? that it calls the right ws? this looks a bit pointless - ws\n
      are a perfect place for mocking whatever may be called - without anything being\n
      called. in order to test the consumer you''d otherwise be writing a webservice\n
      that mocks the original, right? i''d suppose that the communication protocol that\n
      goes through the wire is not the clients domain - e.g. it''s generated. so the\n
      only thing a ws-consumer''s client sees is the interface. and there''s nothing\n
      to test in an interface. it might be that i completely misunderstood your question\n
       please clarify if i did. i''ll revise the answer then.\n
    - well, there is a system called virtualenv which allows you to run python\n
      in a sort of safe environment, and configureloadshutdown these environments\n
      on the fly. i don''t know much about it, but you should take a serious look into\n
      it; here is the description from its web page (just google it and you''ll find\n
      it) the basic problem being addressed is one of dependencies and versions, and\n
      indirectly permissions. imagine you have an application that needs version 1 of\n
      libfoo, but another application requires version 2. how can you use both these\n
      applications? if you install everything into usrlibpython2.4site-packages\n
      (or whatever your platform''s standard location is), it''s easy to end up in a\n
      situation where you unintentionally upgrade an application that shouldn''t be\n
      upgraded. or more generally, what if you want to install an application and leave\n
      it be? if an application works, any change in its libraries or the versions of\n
      those libraries can break the application. also, what if you can''t install packages\n
      into the global site-packages directory? for instance, on a shared host. in all\n
      these cases, virtualenv can help you. it creates an environment that has its own\n
      installation directories, that doesn''t share libraries with other virtualenv\n
      environments (and optionally doesn''t use the globally installed libraries either).\n
    - i''ve used web service studio. web service studio is a tool to invoke web\n
      methods interactively. the user can provide a wsdl endpoint. on clicking button\n
      get the tool fetches the wsdl, generates .net proxy from the wsdl and displays\n
      the list of methods available. the user can choose any method and provide the\n
      required input parameters. on clicking invoke the soap request is sent to the\n
      server and the response is parsed to display the return value. this tool is meant\n
      for web service implementers to test their web services without having to write\n
      the client code. this could also be used to access other web services whose wsdl\n
      endpoint is known. also the web services explorer in eclipse which comes as part\n
      of the web tools platform. through uddi and wsil, other applications can discover\n
      wsdl documents and bind with them to execute transactions or perform other business\n
      processes. the web services explorer allows you to explore, import, and test wsdl\n
      documents.\n
    - i have used soapui by a maven plugin. it can create junit-linke reports\n
      to be run and analysed like unit tests. this can be easily integrated in continious\n
      build, also with the free distribution of soapui.\n
    - the grinder is right up your ally with both java and python, that handles\n
      most web services, (soaprestcorbarmijmsejb) etc.\n
    - that site doesnt offer an api for you to be able to get the appropriate\n
      data that you need. in that case you''ll need to parse the actual html page returned\n
      by, for example, a curl request .\n
    - what you''re asking about is called "web scraping." i''m sure if you google\n
      around you''ll find some stuff, but the core notion is that you want to open a\n
      connection to the website, slurp in the html, parse it and identify the chunks\n
      you want. the python wiki has a good lot of stuff on this.\n
    - beautiful soup is a python library designed for parsing web pages. between\n
      it and urllib2 (urllib.request in python 3) you should be able to figure out what\n
      you need.\n
    - since you write in c, you may want to check out curl; in particular, take\n
      a look at libcurl. it''s great.\n
    - you can use the mechanize library that is available for python\n
    - i know perl better than python, so my choice would fall on perl. that said,\n
      i''d argue that on low level tasks (like pinging computers on a network and things\n
      like that) they are rather equivalent. python may have a better object-oriented\n
      support but for scripting (that happens to be what you need) the power of perl\n
      is quite obvious. the large pool of tested modules (some of them are even object\n
      oriented) that you find on cpan usually can do everything you need and they can\n
      even scale well if you use them appropriately.\n
    - dan is right urlparse is your friend  from urlparse import urlparse   parts\n
      urlparse("  parts.scheme + "" + parts.netloc'  parts.path'questionsask''\n
    - import pypdf pdf = pypdf.pdffilereader(open("file.pdf")) pdf.decrypt("password")\n
      you can then do whatever you want with the contents. this will work with either\n
      the user or owner passwords.\n
    - i saw this blog post recently talking about using scsi passthrough under\n
      os x. looks like it isn''t as easy as windows or unix\n
    - import re url = " protocol, domain = re.match(r"( url).groups()\n
    - use the python urlparse module for a well-defined and well-traveled problem\n
      like this, don''t bother with writing your own code, let alone your own regular\n
      expressions. they cause too much trouble ;-).\n
    - it seems that, when windows wants to start the screen saver or turn the\n
      monitor off, it will send a wm_syscommand to the topmost window with a wparam\n
      of sc_screensave (to start the screen saver) or a wparam of sc_monitorpower and\n
      a lparam of 1 or 2 (to turn the monitor off). this message will then be passed\n
      to defwindowproc, which will actually do the action. so, if your window happens\n
      to be the topmost one, you can intercept these events and ignore them (or do anything\n
      else you want before passing them to defwindowproc). on windows vista, there seems\n
      to be a more intuitive, and more reliable, way to know the monitor power state.\n
      you call registerpowersettingnotification to tell the system to send your window\n
      a wm_powerbroadcast message with a wparam of pbt_powersettingchange and a lparam\n
      pointing to a powerbroadcast_setting structure. i cannot test either of them since\n
      i currently do not have any computer with windows nearby. i hope, however, they\n
      point you in the right direction. references the old new thing  fumbling around\n
      in the dark and stumbling across the wrong solution recursive hook ... - borland.public.delphi.nativeapi.win32\n
      | google groups registering for power events (windows)\n
    - no, there isn''t. it''s because the http spec does not provide anything\n
      for the client to specify time-to-live information with a http request. you can\n
      do this only on tcp level, as you mentioned. on the other hand, the server may\n
      inform the client about timeout situations with http status codes 408 request\n
      timeout resp. 504 gateway timeout.\n
    - you can set a global socket timeout (*) import socket timeout = 10 socket.setdefaulttimeout(timeout)\n
      (*) edit as people in the comments correctly point out this is technically true,\n
      but it only has predictable results for tasks that involve a single socket operation.\n
      an http request consists of multiple socket operations (e.g. dns requests or other\n
      things that might be abstracted away from an http client). the timeout of the\n
      overall operation becomes unpredictable because of that.\n
    - you could append the devenv command onto the end of the original batch\n
      file like so'%comspec% k "...vcvarsall.bat" x86 &amp;&amp; devenv asdf.sln\n
      rebuild ...'' (obviously i have shortened the commands for simplicity''s sake)\n
    - a const sane_device *** is a three-level pointer it''s a pointer to a\n
      pointer to a pointer to a constant sane_device. you can use the program cdecl\n
      to decipher complicated cc++ type definitions. according to the sane documentation,\n
      sane_get_devices() will store a pointer to a null-terminated list of pointers\n
      to sane devices if successful. thus, the proper way to call it is to declare a\n
      variable of type const sane_device ** (i.e. a pointer to a pointer to a constant\n
      `sane_device), and pass in the address of that pointer const sane_device **device_list;\n
      sane_get_devices(&amp;device_list, local_only);  check return value  now,\n
      device_list[0] points to the first device,  device_list[1] points to the second\n
      device, etc.  once you hit a null pointer, that''s the end of the list int\n
      num_devices = 0; while(device_list[num_devices] != null) num_devices++;  num_devices\n
      now stores the total number of devices now, this is how you would call it from\n
      c code. i''ve skimmed the documentation on ctypes, and it appears that you want\n
      to use the byref function to pass the argument by reference, and that the value\n
      you pass should be a pointer to a pointer to a sane_device. note the distinction\n
      between pointer and pointer the former creates a pointer to an instance, whereas\n
      the latter creates a pointer to a type. thus, i''m guessing the following code\n
      will work  sane_device declared as you had it devices = pointer(pointer(sane_device))()\n
     devices is a null pointer to a pointer to a sane_device status = libsane.sane_get_devices(byref(devices),\n
      c_int(0)) if status != successful  replace this by whatever success is print\n
      error else num_devices = 0  convert null-terminated c list into python list\n
      device_list = [] while devices[num_devices] device_list.append(devices[num_devices].contents)\n
     use .contents here since each entry in the c list is itself a pointer num_devices\n
      += 1 print device_list [edit] i''ve tested the above code using a very simple\n
      placeholder for sane_get_devices, and it works.\n
    - you''re doing it wrong. threading.lock is not an object.  import threading  threading.lock\n
      built-in function allocate_lock  type(threading.lock) type'builtin_function_or_method''  x=threading.lock()  type(x)\n
      type'thread.lock''  dir(x) [''__enter__'','__exit__'','acquire'','acquire_lock'',\n
     'locked'','locked_lock'','release'','release_lock''] \n
    - i run my python script from a batch file that sets the variables -) call\n
      ...\vcvarsall.bat c\python26\python.exe myscript.py but brett''s solution sounds\n
      better.\n
    - i these situations i use script that does it all. that way you can chain\n
      as much as you want. sometimes i will generate the script on the fly. compileit.cmd\n
      call c\program files\microsoft visual studio 9.0\vc\vcvarsall.bat devenv \n1.sln\n
      rebuild debug out last-build.txt\n
    - filter itself doesn''t execute a query, no query is executed until you\n
      explicitly fetch items from query (e.g. get), and list( query ) also executes\n
      it.\n
    - i think the backslashes are messing you up. you need to use an r string\n
      (raw) r"string" see for reference\n
    - if you are adventurous use opengl ) you can draw bezier curves in 3d space\n
      on top of a textured plane (earth map), you can specify a thickness for them and\n
      you can draw a point (small cone) at the end. it''s easy and it looks nice, problem\n
      is learning the basics of opengl if you haven''t used it before but that would\n
      be fun and probably useful if your in to programing graphics. you can use opengl\n
      from python either with pyopengl or pyglet. if you make the animation this way\n
      you can capture it to an avi file (using camtasia or something similar) that can\n
      be put onto a presentation slide.\n
    - if you want a complete example of how to use threads and events to update\n
      your gui with long running tasks using wxpython have a look at this page. this\n
      tutorial is quite useful and helped me perform a similar program than yours.\n
    - it depends largely on the effort you want to expend on this, but the basic\n
      outline of an easy way. would be to load an image of an arrow, and use a drawing\n
      library to color and rotate it in the direction you want to point(or draw it using\n
      shapescurves). finally to actually animate it interpolate between the coordinates\n
      based on time. if its just for a presentation though, i would use macromedia flash,\n
      or a similar animation program.(would do the same as above but you don''t need\n
      to program anything)\n
    -  the client will present this as a slide in a presentation in a windows\n
      machine i think this is the key to your answer. before going to a 3d implementation\n
      and writing all the code in the world to create this feature, you need to look\n
      at the presentation software. chances are, your options will boil down to two\n
      things animated gif custom presentation scripts obviously, an animated gif is\n
      not ideal due to the fact that it repeats when it is done rendering, and to make\n
      it last a long time would make a large gif. custom presentation scripts would\n
      probably be the other way to allow him to bring it up in a presentation without\n
      running any side-programs, or doing anything strange. i''m not sure which presentation\n
      application is the target, but this could be valuable information. he sounds like\n
      he''s more non-technical and requesting something he doesn''t realize will be\n
      difficult. i think you should come up with some options, explain the difficulty\n
      in implementing them, and suggest another solution that falls into the'bang\n
      for your buck'' range.\n
    - you can see the query that will be generated by using soknad_list.query.as_sql()[0]\n
      you can then put that into your database shell to see how long the query takes,\n
      or use explain (if your database backend supports it) to see how expensive it\n
      is.\n
    - as aaron mentioned, you should get a hold of the query text that is going\n
      to be run against the database and use an explain (or other some method) to view\n
      the query execution plan. once you have a hold of the execution plan for the query\n
      you can see what is going on in the database itself. there are a lot of operations\n
      that see very expensive to run through procedural code that are very trivial for\n
      any database to run, especially if you provide indexes that the database can use\n
      for speeding up your query. if i read your question correctly, you''re retrieving\n
      a result set of all rows in the soknad table. once you have these results back\n
      you use the filter() method to trim down your results meet your criteria. from\n
      looking at the django documentation, it looks like this will do an in-memory filter\n
      rather than re-query the database (of course, this really depends on which data\n
      access layer you''re using and not on django itself). the most optimal solution\n
      would be to use a full-text search engine (lucene, ferret, etc) to handle this\n
      for you. if that is not available or practical the next best option would be to\n
      to construct a query predicate (where clause) before issuing your query to the\n
      database and let the database perform the filtering. however, as with all things\n
      that involve the database, the real answer is'it depends.'' the best suggestion\n
      is to try out several different approaches using data that is close to production\n
      and benchmark them over at least 3 iterations before settling on a final solution\n
      to the problem. it may be just as fast, or even faster, to filter in memory rather\n
      than filter in the database.\n
    - "ftplib" is the standard ftp library built in to python. in python 2.6,\n
      it had a callback parameter added to the method used for uploading. that callback\n
      is a function you provide to the library; it is called once for every block that\n
      is completed. your function can send a message to the gui (perhaps on a different\n
      threadprocess, using standard inter-thread or inter-process communications) to\n
      tell it to update its progress bar. reference\n
    - if you data transfer runs in a separate thread from the gui, you can use\n
      wx.callafter() whenever you have to update you progress bar from the data transfer\n
      thread. first, using callafter() is mandatory as wxpython function cannot be called\n
      from child threads. second, this will decouple the execution of the data transfer\n
      from the gui in the main thread. note that callafter() only works for threads,\n
      not for separate processes. in that case, using the multiprocessing package should\n
      help.\n
    - okay sorry for using this a a stream of consciousness thinking stimulator\n
      but it appears that writing out my original question got me on the path. it seems\n
      to me that this is a solution for what i am trying to do missingparen=re.compile(r"^\(\d\n")\n
    - easy fix sc.sendscintilla(sc.sci_sethscrollbar, 0)\n
    - if you''re willing to use trunk, you can take advantage of the brand new\n
      annotate() queryset method added just a week or so ago, which solves this exact\n
      problem if you want to stick with django 1.0, you can achieve this in a slightly\n
      less elegant way using the select argument of the extra() queryset method. there''s\n
      an example of exactly what you are talking about using extra() here finally,\n
      if you need this to be really high performance you can denormalise the count in\n
      to a separate column. i''ve got some examples of how to do this in the unit testing\n
      part of my presentation here\n
    - if your problem is just to serialze a modelform to json, just write your\n
      own simplejson serializer subclass.\n
    - if you want to handle arbitrary expressions like {''{spam'' 42}["spam}"],\n
      you can''t get away without full-blown parser.\n
    - here''s a macfuse-based proc fs if you have control of the boxes you''re\n
      running your python program on it might be a reasonable solution. at any rate\n
      it''s nice to have a proc to look at!\n
    - the only stuff that''s really nicely accesible is available from the platform\n
      module, but it''s extremely limited (cpu, os version, architecture, etc). for\n
      cpu usage and uptime i think you will have to wrap the command line utilities\n
     'uptime'' and'vm_stat''. i built you one for vm_stat, the other one is up to\n
      you ;-) import os, sys def memoryusage() result = dict() for l in [l.split('''')\n
      for l in os.popen(''vm_stat'').readlines()[18]] result[l[0].strip('' "'').replace(''\n
     ','_'').lower()] = int(l[1].strip(''.\n')) return result print memoryusage()\n
    - you can get a large amount of system information from the command line\n
      utilities sysctl and vm_stat (as well as ps, as in this question.) if you don''t\n
      find a better way, you could always call these using subprocess.\n
    - i did some more googling (looking for "os x proc") -- it looks like the\n
      sysctl command might be what you want, although i''m not sure if it will give\n
      you all the information you need. here''s the manpage also, wikipedia.\n
    - after posting this, reading the replies so far (thanks everyone!), and\n
      thinking about the problem for a while, here is the best approach i''ve been able\n
      to come up with find the first \n{. find the next } after that. feed whatever''s\n
      in between to compile(). if it works, stick a fork in it and we''re done. otherwise,\n
      keep extending the string by looking for subsequent occurences of }. as soon as\n
      something compiles, return it. if we run out of } without being able to compile\n
      anything, use the results of the last compilation attempt to give information\n
      about where the problem lies. advantages of this approach the code is quite short\n
      and easy to understand. it''s pretty efficient -- optimal, even, in the case where\n
      the expression contains no }. worst-case seems like it wouldn''t be too bad either.\n
      it works on many expressions that contain \n{ andor }. no external dependencies.\n
      no need to import anything, in fact. (this surprised me.) disadvantages sometimes\n
      it grabs too much or too little. see below for an example of the latter. i could\n
      imagine a scary example where you have two expressions and the first one is subtly\n
      wrong and the algorithm ends up mistakenly grabbing the whole thing and everything\n
      in between and returning it as valid, though i haven''t been able to demonstrate\n
      this. perhaps things are not so bad as i fear. i don''t think misunderstandings\n
      can be avoided in general -- the problem definition is kind of slippery -- but\n
      it seems like it ought to be possible to do better, especially if one were willing\n
      to trade simplicity or execution time. i haven''t done any benchmarks, but i could\n
      imagine there being faster alternatives, especially in cases that involve lots\n
      of } in the expression. that could be a big deal if one wanted to apply this technique\n
      to sizable blocks of python code rather than just very short expressions. here\n
      is my implementation. def findexpr(s, i0=0, begin=''\n{'', end=''}'', compargs=(''string'',\n
     'eval'')) assert'\n'' not in s,'line numbers not implemented'' i0 = s.index(begin,\n
      i0) + len(begin) i1 = s.index(end, i0) code = errmsg = none while code is none\n
      and errmsg is none expr = s[i0i1] try code = compile(expr, *compargs) except\n
      syntaxerror, e i1 = s.find(end, i1 + 1) if i1  0 errmsg, i1 = e.msg, i0 + e.offset\n
      return i0, i1, code, errmsg and here''s the docstring with some illustrations\n
      in doctest format, which i didn''t insert into the middle of the function above\n
      only because it''s long and i feel like the code is easier to read without it.\n
     ''''' search s for a (possibly invalid) python expression bracketed by begin\n
      and end, which default to'\n{'' and'}''. return a 4-tuple.  s ='foo \n{a*b\n
      + c*d} bar''  i0, i1, code, errmsg = findexpr(s)  i0, i1, s[i0i1], errmsg (6,\n
      15,'a*b + c*d'', none) ''.join(''%02x'' % ord(byte) for byte in code.co_code)\n
     '65 00 00 65 01 00 14 65 02 00 65 03 00 14 17 53''  code.co_names (''a'','b'',\n
     'c'','d'')  eval(code, {''a'' 1,'b'' 2,'c'' 3,'d'' 4}) 14  eval(code,\n
      {''a'''a'','b'' 2,'c'''c'','d'' 4})'aacccc''  eval(code, {''a''\n
      none}) traceback (most recent call last) ... nameerror name'b'' is not defined\n
      expressions containing start andor end are allowed.  s ='{foo \n{{"}" "\n{"}["}"]}\n
      bar}''  i0, i1, code, errmsg = findexpr(s)  i0, i1, s[i0i1], errmsg (7, 23,'{"}"\n
      "\n{"}["}"]'', none) if the first match is syntactically invalid python, i0 points\n
      to the start of the match, i1 points to the parse error, code is none and errmsg\n
      contains a message from the compiler.  s ='{foo \n{qwerty asdf zxcvbnm!!!} \n{7}\n
      bar}''  i0, i1, code, errmsg = findexpr(s)  i0, i1, s[i0i1], errmsg (7, 18,'qwerty\n
      asdf'','invalid syntax'')  print code none if a second argument is given, start\n
      searching there.  i0, i1, code, errmsg = findexpr(s, i1)  i0, i1, s[i0i1], errmsg\n
      (33, 34,'7'', none) raise valueerror if there are no further matches.  i0, i1,\n
      code, errmsg = findexpr(s, i1) traceback (most recent call last) ... valueerror\n
      substring not found in ambiguous cases, match the shortest valid expression. this\n
      is not always ideal behavior.  s ='{foo \n{x or {} # return {} instead of none}\n
      bar}''  i0, i1, code, errmsg = findexpr(s)  i0, i1, s[i0i1], errmsg (7, 25,'x\n
      or {} # return {'', none) this implementation must not be used with multi-line\n
      strings. it does not adjust line number information in the returned code object,\n
      and it does not take the line number into account when computing the offset of\n
      a parse error.'''''\n
    - if you can''t use python 2.6''s ftplib, there is a company offering a commercial\n
      solution. chilkat''s ckftp2 costs several hundreds of dollars, but promises to\n
      work with python 2.5, and offers a function call get_asyncbytessent() which returns\n
      the information you need. (i didn''t see a callback, but it may offer that too.)\n
      i haven''t used this product. also consider that if ftp proves to be too hardexpensive,\n
      you could always switch to http uploads instead. chilkat have a free httphttps\n
      upload library.\n
    - remember that in addition to setting pythonpath in your system environment,\n
      you''ll also want to assign django_settings_module.\n
    - perhaps this helps it''s a guide to installing python in windows vista.\n
    - simplest solution is to define a method on the model which encapsulates\n
      the numeric logic and returns the human-friendly string. or you can write a template\n
      tag to do it, which is a lot more code, but perhaps preserves the modelview layer\n
      separation a bit better.\n
    - according to this, it seems you can only compare strings. i''d make my\n
      own template tag if i were you.\n
    - in java apps, it''s common to jsonify the name. input name="records[pk].fieldname"\n
      pk being the primary key of the row and fieldname the field. of course most frameworks\n
      handle this transparently. each record ends up as a instance of a class with a\n
      property for each field, all of which are put into a list called "records". you\n
      may have to write some sort of interpreter, but that shouldn''t be too hard.\n
    - you can do this def allocation(**kwargs) print kwargs myargs = {"param\n
      1"val1, "param 2"val1} allocation(**myargs) edit your edit now includes my\n
      answer so no, there is no easier way to have spaces in keyword arguments.\n
    - unless i am mistaking your basic premise here, there''s nothing to stop\n
      you from writing a class that parses your own custom syntax, and then using that\n
      custom syntax as a single-argument string allocation("param 1=check up; param\n
      2=mean value theorem;") in this example, semicolons act as the name-value-pair\n
      separators, and equals represents the name-value separator. moreover, you can\n
      easily configure your parser to accept custom delimiters as part of the object\n
      constructor. if it seems too daunting to write a parser, consider that (for a\n
      syntax such as this) you could obtain your values by simply splitting the string\n
      on \s*;\s* and then on \s*=\s* to quickly obtain the name-value pairs. you\n
      also have the option to choose from any of several argument parsers already written\n
      for python. admittedly, this does not use python as the argument parser, which\n
      is a consideration you will have to balance against the simplicity of an approach\n
      such as this.\n
    - i''d imagine that there would be some way to do it. but i feel compelled\n
      to ask, is there really a big enough difference in readability from this allocation(param1\n
      val1, param2 = val2 ) to this allocation(param 1 = val1, param 2 = val2 ) to\n
      make that big a difference? i''m sure there''s a way to do what you want to do,\n
      but my first concern is if the effort involved would be worth the result. my goal\n
      is to provide a dsl which can be used for data entry into the system. in the above\n
      scenario, params would be people names and values would be percentages. i have\n
      a better understanding of what you want to do now, but i still think that you\n
      might end up having to sacrifice some readability to get what you want. personally,\n
      i would go with something like allocation( {'name1''  value1,'name1'' \n
      value2, } ) if that''s not something you can go with, then you might want to reconsider\n
      whether you want to use python for your dsl or go with something home-grown. allowing\n
      whitespace allows too many ambiguities for most programming languages to allow\n
      it. if you still want to pursue this with using python, you might want to consider\n
      posting to the c-api sig (sigs) or maybe the python-dev list (as a last resort).\n
      the only way that i can see to do this would be to embed the python interpreter\n
      into a cc++ program and do some kind of hacking with it (which can be difficult!).\n
    - here''s my preference. allocationset( alloc( name="some name", value=1.23\n
      ), alloc( name="another name", value=2.34 ), alloc( name="yet another name", value=4.56\n
      ), ) these are relatively easy class declarations to create. the resulting structure\n
      is pleasant to process, too.\n
    - you can either pass back a reference to the file itself i.e. the full path\n
      to the file. then you can open the file or otherwise manipulate it. or, the more\n
      normal case is to pass back the file handle, and, use the standard readwrite\n
      operations on the file handle. it is not recommended to pass the actual data as\n
      files can be arbiterally large and the program could run out of memory. in your\n
      case, you probably want to return a tuple containing the open file handle, the\n
      file name and any other meta data you are interested in.\n
    - for information on mime types (which are how downloads happen), start here\n
      properly configure server mime types. for information on cherrypy, look at the\n
      attributes of a response object. you can set the content type of the response.\n
      also, you can use tools.response_headers to set the content type. and, of course,\n
      there''s an example of file download.\n
    - fully supported in cherrypy using from cherrypy.lib.static import serve_file\n
      as documented in the cherrypy docs - filedownload import glob import os.path\n
      import cherrypy from cherrypy.lib.static import serve_file class root def index(self,\n
      directory=".") html = """htmlbodyh2here are the files in the selected directoryh2\n
      a href="index?directory=%s"upabr  """ % os.path.dirname(os.path.abspath(directory))\n
      for filename in glob.glob(directory +'*'') abspath = os.path.abspath(filename)\n
      if os.path.isdir(abspath) html +='a href="index?directory='' + abspath +'"''\n
      + os.path.basename(filename) + "a br " else html +='a href="download?filepath=''\n
      + abspath +'"'' + os.path.basename(filename) + "a br " html += """bodyhtml"""\n
      return html index.exposed = true class download def index(self, filepath) return\n
      serve_file(filepath, "applicationx-download", "attachment") index.exposed = true\n
      if __name__ =='__main__'' root = root() root.download = download() cherrypy.quickstart(root)\n
    - this isn''t refactoring (it doesn''t need refactoring as far as i can see),\n
      but some suggestions you should use the email package rather than rfc822. replace\n
      rfc822.message with email.message, and use email.utils.parseaddr(msg["from"])\n
      to get the name and email address, and msg["subject"] to get the subject. use\n
      os.path.join to create the path. this emailpath = str(self._emailpath + self._inboxfolder\n
      + "\\" + email + "_" + msg.getheader("subject") + ".eml") becomes emailpath =\n
      os.path.join(self._emailpath + self._inboxfolder, email + "_" + msg.getheader("subject")\n
      + ".eml") (if self._inboxfolder starts with a slash or self._emailpath ends with\n
      one, you could replace the first + with a comma also). it doesn''t really hurt\n
      anything, but you should probably not use "file" as a variable name, since it\n
      shadows a built-in type (checkers like pylint or pychecker would warn you about\n
      that). if you''re not using self.popinstance outside of this function (seems unlikely\n
      given that you connect and quit within the function), then there''s no point making\n
      it an attribute of self. just use "popinstance" by itself. use xrange instead\n
      of range. instead of just importing stringio, do this try import cstringio as\n
      stringio except importerror import stringio if this is a pop mailbox that can\n
      be accessed by more than one client at a time, you might want to put a tryexcept\n
      around the retr call to continue on if you can''t retrieve one message. as john\n
      said, use "\n".join rather than string.join, use tryfinally to only close the\n
      file if it is opened, and pass the logging parameters separately. the one refactoring\n
      issue i could think of would be that you don''t really need to parse the whole\n
      message, since you''re just dumping a copy of the raw bytes, and all you want\n
      is the from and subject headers. you could instead use popinstance.top(0) to get\n
      the headers, create the message (blank body) from that, and use that for the headers.\n
      then do a full retr to get the bytes. this would only be worth doing if your messages\n
      were large (and so parsing them took a long time). i would definitely measure\n
      before i made this optimisation. for your function to sanitise for the names,\n
      it depends how nice you want the names to be, and how certain you are that the\n
      email and subject make the filename unique (seems fairly unlikely). you could\n
      do something like emailpath = "".join([c for c in emailpath if c in (string.letters\n
      + string.digits + "_ ")]) and you''d end up with just alphanumeric characters\n
      and the underscore and space, which seems like a readable set. given that your\n
      filesystem (with windows) is probably case insensitive, you could lowercase that\n
      also (add .lower() to the end). you could use emailpath.translate if you want\n
      something more complex.\n
    - further to my comment on john''s answer i found out what the issue was,\n
      there were illegal characters in the name field and subject field, which caused\n
      python to get the hiccups, as it tried to write the email as a directory, after\n
      seeing "" and "". john point number 4 doesnt work! so i left it as before. also\n
      is point no 1 correct, have i implemented your suggestion correctly? def _dump_pop_emails(self)\n
      self.logger.info("open pop account %s with username %s", self.account[0], self.account[1])\n
      self.popinstance = poplib.pop3(self.account[0]) self.logger.info(self.popinstance.getwelcome())\n
      self.popinstance.user(self.account[1]) self.popinstance.pass_(self.account[2])\n
      try (nummsgs, totalsize) = self.popinstance.stat() for thisnum in range(1, nummsgs+1)\n
      (server_msg, body, octets) = self.popinstance.retr(thisnum) text ='\n''.join(body)\n
      mesg = stringio.stringio(text) msg = rfc822.message(mesg) name, email = msg.getaddr("from")\n
      emailpath = str(self._emailpath + self._inboxfolder + "\\" + self._sanitize_string(email\n
      + " " + msg.getheader("subject") + ".eml")) emailpath = self._replace_whitespace(emailpath)\n
      print emailpath file = open(emailpath,"wb") file.write(text) file.close() self.popinstance.dele(thisnum)\n
      finally self.logger.info(self.popinstance.quit()) def _replace_whitespace(self,name)\n
      name = str(name) return name.replace(" ", "_") def _sanitize_string(self,name)\n
      illegal_chars = "", "", "\\" name = str(name) for item in illegal_chars name\n
      name.replace(item, "_") return name\n
    - i don''t see anything significant wrong with that code -- is it behaving\n
      incorrectly, or are you just looking for general style guidelines? a few notes\n
      instead of logger.info ("foo %s %s" % (bar, baz)), use "foo %s %s", bar, baz.\n
      this avoids the overhead of string formatting if the message won''t be printed.\n
      put a try...finally around opening emailpath. use'\n''.join (body), instead\n
      of string.join (body,'\n''). instead of msg.getaddr("from"), just msg.from.\n
    - i think you mean polyhedron, not polygon .. and you might wanna look at\n
      vpython\n
    - one of the most complete geographymapping systems available for python\n
      that i know about is geodjango. this works on top of the django, an mvc framework.\n
      with it comes a large collection of polygon, line and distance calculation tools\n
      that can even take into account the curvature of the earth''s surface if need\n
      be. with that said, the quickest way i can think of to produce a 3d map is using\n
      a height map. create a two dimensional list of tuples containing (x, y, z) coordinates.\n
      each tuple represents an evenly spaced point on a grid, mapped out by the dimensions\n
      of the array. this creates a simple plane along the x and z axes; the ground plane.\n
      the polygons that make up the plane are quads, a polygon with four sides. next,\n
      to produce the three dimensional height, simply give each point a y value. this\n
      will create peaks and valleys in your ground plane. how you render this will be\n
      up to you, and converting your grid of points into a polygon format that something\n
      like opengl can understand may take some work, but have a look at visual python,\n
      its the simplest 3d library i''ve seen for python.\n
    - your example program works, because the two instances of'good'' are different\n
      variables (you just happen to have both variables with the same name). the following\n
      code is exactly the same def hello(x,y) good=hi(iy,ix) "then do somethings,and\n
      use the parameter''good''." return something def hi(iy,ix) "code" return great\n
    - the scope of functions hello and hi are entirely different. they do not\n
      have any variables in common. note that the result of calling hi(x,y) is some\n
      object. you save that object with the name good in the function hello. the variable\n
      named good in hello is a different variable, unrelated to the variable named good\n
      in the function hi. they''re spelled the same, but the exist in different namespaces.\n
      to prove this, change the spelling the good variable in one of the two functions,\n
      you''ll see that things still work. edit. follow-up "so what should i do if i\n
      want use the result of hi function in hello function?" nothing unusual. look at\n
      hello closely. def hello(x,y) fordf150 = hi(y,x) "then do somethings,and use\n
      the variable'fordf150''." return something def hi( ix, iy ) "compute some value,\n
      good." return good some script evaluates hello( 2, 3). python creates a new namespace\n
      for the evaluation of hello. in hello, x is bound to the object 2. binding is\n
      done position order. in hello, y is bound to the object 3. in hello, python evaluates\n
      the first statement, fordf150 = hi( y, x ), y is 3, x is 2. a. python creates\n
      a new namespace for the evaluation of hi. b. in hi, ix is bound to the object\n
      3. binding is done position order. c. in hi, iy is bound to the object 2. d. in\n
      hi, something happens and good is bound to some object, say 3.1415926. e. in hi,\n
      a return is executed; identifying an object as the value for hi. in this case,\n
      the object is named by good and is the object 3.1415926. f. the hi namespace is\n
      discarded. good, ix and iy vanish. the object (3.1415926), however, remains as\n
      the value of evaluating hi. in hello, python finishes the first statement, fordf150\n
      hi( y, x ), y is 3, x is 2. the value of hi is 3.1415926. a. fordf150 is bound\n
      to the object created by evaluating hi, 3.1415926. in hello, python moves on to\n
      other statements. at some point something is bound to an object, say, 2.718281828459045.\n
      in hello, a return is executed; identifying an object as the value for hello.\n
      in this case, the object is named by something and is the object 2.718281828459045\n
      . the namespace is discarded. fordf150 and something vanish, as do x and y. the\n
      object (2.718281828459045 ), however, remains as the value of evaluating hello.\n
      whatever program or script called hello gets the answer.\n
    - the "hello" function doesn''t mind you calling the "hi" function which\n
      is hasn''t been defined yet, provided you don''t try to actually use the "hello"\n
      function until after the both functions have been defined.\n
    - if you want to define a variable to the global namespace from inside a\n
      function, and thereby make it accessible by other functions in this space, you\n
      can use the global keyword. here''s some examples vara = 5 #a normal declaration\n
      of an integer in the main "global" namespace def funca() print vara #this works,\n
      because the variable was defined in the global namespace #and functions have read\n
      access to this. def changea() vara = 2 #this however, defines a variable in the\n
      function''s own namespace #because of this, it''s not accessible by other functions.\n
      #it has also replaced the global variable, though only inside this function def\n
      newvar() global varb #by using the global keyword, you assign this variable to\n
      the global namespace varb = 5 def funcb() print varb #making it accessible to\n
      other functions conclusion variables defined in a function stays in the function''s\n
      namespace. it still has access to the global namespace for reading only, unless\n
      the variable has been called with the global keyword. the term global isn''t entirely\n
      global as it may seem at first. it''s practically only a link to the lowest namespace\n
      in the file you''re working in. global keywords cannot be accessed in another\n
      module. as a mild warning, this may be considered to be less "good practice" by\n
      some.\n
    - queryset.count() see also an example how to build querysets of related\n
      models.\n
    - getattr(x,"value=",99) returns 99 because x has no attribute "value=" (note\n
      the equals sign), so getattr returns the supplied default (99).\n
    - if you were using pure django, you''d pass the form to your template, and\n
      could then call individual fields on the form for more precise rendering, rather\n
      than using modelform.to_table. you can use the following to iterate over each\n
      field and render it exactly how you want {% for field in form.fields %} div class="form-field"{{\n
      field }}div {% endfor %} this also affords you the ability to do conditional\n
      checks using {% if %} blocks inside the loop should you want to exclude certain\n
      fields.\n
    - isn''t that when you use decaling, through gltexenv()?\n
    - the python dict is an unordered container. if you need to preserve the\n
      order of the entries, you should consider using a list of 2-tuples. another option\n
      would be to keep an extra, ordered list of the keys. this way you can benefit\n
      from the quick, keyed access offered by the dictionary, while still being able\n
      to iterate through its values in an ordered fashion data = {''reportdate'' u''r20070501'',\n
     'idnum'' u''1078099'','columnlabel'' u''2005'','actiondate'' u''c20070627'',\n
     'data'' u''76,000'','rowlabel'' u''sales of bananas''} dataorder = [''reportdate'',\n
     'idnum'','columnlabel'','actiondate'','data'','rowlabel''] for key in\n
      dataorder print key, data[key]\n
    - i coded something like this for chandler, where any unhandled exceptions\n
      pop up a window with the stack and other info, and users can put in additional\n
      comments (what did they do when it happened etc.) and submit it for chandler developers.\n
      a bit like the mozilla talkback (nowadays they use breakpad i believe) feature\n
      if you will. to do this in wxpython, you need to provide redirect parameter to\n
      wx.app. this will pop up wx.pyondemandoutputwindow (you will probably want to\n
      override it to provide a nicer looking implementation). the relevant source files\n
      in chandler are here chandler.py starts the application and sets the redirect\n
      attribute, as well as tries to catch and display error dialogs in case normal\n
      application startup fails application.py customizes the application object, including\n
      setting up our customized wx.pyondemandoutputwindow feedback.py has the implementation\n
      for the customized wx.pyondemandoutputwindow; it will additionally need feedback.xrc\n
      and feedback_xrc.py\n
    - python does not retain order in dictionaries. however, there is the ordereddict\n
      class in the collections module. another option would be to use a list of tuples\n
      [(''reportdate'', u''r20080501''), (''idnum'', u''1078099''), ...etc] you can\n
      use the built in dict() if you need to convert this to a dictionary later.\n
    - you need to do something like class x def __init__(self) self._value\n
      90 def _get(self) return self._value def _set(self, value) self._value = value\n
      value = property(_get, _set) note that the "internal" variable has to have a different\n
      name than the property (i used _value). then, setattr(x,'value'', 99) should\n
      work.\n
    - more details on the python scoping rules are here  short description of\n
      python scoping rules\n
    - you want to set glenable(gl_color_material). this makes the texture color\n
      mix with the current opengl color. you can also use the glcolormaterial function\n
      to specify whether the frontbackboth of each polygon should be affected. docs\n
      here.\n
    - i think what you''re asking about is being able to insert python code into\n
      text files to be evaluated. there are several modules that already exist to provide\n
      this kind of functionality. you can check the python.org templating wiki page\n
      for a comprehensive list. some google searching also turned up a few other modules\n
      you might be interested in texttemplate (part of py-templates project) template\n
      module if you''re really looking just into writing this yourself for whatever\n
      reason, you can also dig into this python cookbook solution yet another python\n
      templating utility (yaptu)  "templating" (copying an input file to output, on\n
      the fly inserting python expressions and statements) is a frequent need, and yaptu\n
      is a small but complete python module for that; expressions and statements are\n
      identified by arbitrary user-chosen regular-expressions. edit just for the heck\n
      of it, i whipped up a severely simplistic code sample for this. i''m sure it has\n
      bugs but it illustrates a simplified version of the concept at least #!usrbinenv\n
      python import sys import re file = sys.argv[1] handle = open(file) fcontent =\n
      handle.read() handle.close() for myexpr in re.finditer(r''\\n{([^}]+)}'', fcontent,\n
      re.m|re.s) text = myexpr.group(1) try exec text except syntaxerror print "error\n
      unable to compile expression'%s''" % (text) tested against the following text\n
      this is some random text, with embedded python like \n{print "foo"} and some bogus\n
      python like \n{anything}. and a multiline statement, just for kicks \n{ def multiline_stmt(foo)\n
      print foo multiline_stmt("ahem") } more text here. output [user]\n .exec_embedded_python.py\n
      test.txt foo error unable to compile expression'anything'' ahem\n
    - i think your best bet is to match for all curly braced entries, and then\n
      check against python itself whether or not it''s valid python, for which compiler\n
      would be helpful.\n
    - don''t know if this will work for a wxpython application, but in the sys\n
      module you can overwrite the excepthook attribute, which is a function called\n
      with 3 arguments, (type, value, traceback), when an uncaugth exception is caught.\n
      you can install your own function in there that handles only the exceptions you\n
      want, and call the original function for all the others. consult\n
    - perhaps this question might be of some use, it tries to capture all exceptions.\n
    - so what''s wrong with pickle? if you structure your data as a list of dicts,\n
      then everything should work as you want it to (if i understand your problem).  import\n
      pickle  d1 = {1''one'', 2''two'', 3''three''}  d2 = {1''eleven'', 2''twelve'',\n
      3''thirteen''}  d3 = {1''twenty-one'', 2''twenty-two'', 3''twenty-three''}  data\n
      [d1, d2, d3]  out = open(''data.pickle'','wb'')  pickle.dump(data, out)  out.close()  input\n
      open(''data.pickle'')  data2 = pickle.load(input)  data == data2 true\n
    - this may be an editline issue; libedit may not accept utf-8 characters\n
    - using the writefunction, instead of turning it off would save you a lot\n
      off trouble. you might want to rewrite your pageasstring by utilizing writefunction..\n
      as an example from cstringio import stringio c = pycurl.curl() buffer = stringio()\n
      c.setopt(pycurl.writefunction, buffer.write) c.setopt(pycurl.url, " c.perform()\n
      ... buffer.getvalue() # will return the data fetched.\n
    - do you have a typo in positionchanged() ? def positionchanged(self, newpos)\n
      self.snappedpos = snaptogrid(newpos, y_offset, y_step) i guess you are off by\n
      one pixel because of the accuracy problems during float division. try changing\n
      your snaptogrid() to this def snaptogrid(originalpos, offset, step) eps = 1e-6\n
      index = int((originalpos - offset)  step + eps) #truncates the remainder away\n
      return index * gap + offset\n
    - if you want to exit based on time, you can use the signal module''s alarm(time)\n
      function, and the catch the sigalrm - here''s an example you can let the user\n
      interrupt the program in a sane manner by catching keyboardinterrupt. simply catch\n
      the keyboardinterrupt exception from outside you main loop, and do whatever cleanup\n
      you want. if you want to continue later where you left off, you will have to add\n
      some sort persistence. i would pickle a data structure to disk, that you could\n
      read back in to continue the operations. i haven''t tried anything like this,\n
      but you could look into using something like memoizing, and caching to the disk.\n
    - read the fabulous manual\n
    - in your %appdata% directory visual studio saves a list of websites used\n
      in visual studio, with some settings of that site on my vista machine the exact\n
      location of the file is \n
      this file contains entries like ?xml version="1.0" encoding="utf-16"? designtimedata\n
      website rooturl="e\documents\visual studio 2008\websites\website\" cachefolder="website"\n
      sccprovider="subversionscc" scclocalpath="svn" sccauxpath="svn" addnewitemlang="visual\n
      basic" sccprojectname="svn" targetframework="3.5" vwdport="60225" _lastaccess="11-11-2008\n
      105803" website rooturl="e\siteje.webproj\" cachefolder="siteje.webproj" _lastaccess="11-6-2008\n
      144345" !-- and many more -- designtimedata  as you can see it contains the\n
      scc references that are also part of your solution file. (in this case the scc\n
      provider is ankhsvn 2.0, so it doesn''t contain the actual scc mapping; just some\n
      constant strings that tell the scc provider to look at the working copy). i think\n
      tried to fix the missing project file by caching this information in several locations.\n
      but it would be welcome if this file was properly documented.\n
    - you could do something like this to generate fibonnacci numbers for 1 second\n
      then stop. fibonnacci = [1,1] stoptime = time.time() + 1 # set stop time to 1\n
      second in the future while time.time()  stoptime fibonnacci.append(fibonnacci[-1]+fibonnacci[-2])\n
      print "generated %s numbers, the last one was %s." % (len(fibonnacci),fibonnacci[-1])\n
      i''m not sure how efficient it is to call time.time() in every loop - depending\n
      on the what you are doing inside the loop, it might end up taking a lot of the\n
      performance away.\n
    - you could use a generator for this def finished() "define your exit condition\n
      here" return ... def count(i=0) while not finished() yield i i += 1 for i in\n
      count() print i if you want to change the exit condition you could pass a value\n
      back into the generator function and use that value to determine when to exit.\n
    - i happened to post a blog on implementing john conway''s game of life in\n
      xamlwpf using embedded python. it might be of interest to you.\n
    - it is perfectly acceptable to have a'cleanup()'' function that you call\n
      at the end of your script, which will call'os.remove()'' on your files.\n
    - thanks for the answer, there may be a typo, but i can''t see it... unfortunately\n
      the change to snaptogrid didn''t make a difference, so i don''t think that''s\n
      the issue. it''s not off by one pixel, but rather it''s off by y_step. playing\n
      around with it some more i''ve found that i can''t get it to be exact at any point\n
      that the screen is scrolled up and also that it happens towards the top of the\n
      screen, which i suspect is ode position zero, so i''m guessing my problem is around\n
      small or negative values.\n
    - ok, i''m answering my own question here, as alexk mentioned, using int\n
      to truncate was my mistake. the behaviour i''m after is best modeled by math.floor().\n
      apologies, the original question does not contain enough information to really\n
      work out what the problem is. i didn''t have the extra bit of information at that\n
      point. with regards to the typo note, i think i may be using the context in a\n
      confusing manner... from the perspective of the positionchanged() function, the\n
      parameter is a new position coming in. from the perspective of the snaptogrid()\n
      function the parameter is an original position which is being changed to a snapped\n
      position. the language is like that because part of it is in my event handling\n
      code and the other part is in my general services code. i should have changed\n
      it for the example\n
    - just call os.remove("pathtofile"). for example, to remove the file .emacs,\n
      call os.remove(".emacs") the path should be a str that''s the pathname of the\n
      file. it may be relative or absolute.\n
    - it sounds like what you really want is a temp file\n
    - as the question is phrased, it''s hard to guess what the intention (or\n
      even the intended semantics) is. for setting headers, try the following import\n
      soappy headers = soappy.types.headertype() headers.value1 = value2 or [...] headers.foo\n
      value1 headers.bar = value2\n
    - your specific solution to the path name copy is reasonable, but your general\n
      solution to the entire problem could be improved. i would easy_install anyvc,\n
      a library developed for the pida ide which is a uniform python interface into\n
      version control systems, and use it instead from anyvc import subversion vc =\n
      subversion(''trunk'') modified = [f.relpath for f in vc.list() if f.state !=\n
     'clean''] for f in modified print f.relpath # the relative path of the file\n
      to the source root additionally, i would probably attach a diff to an email rather\n
      than the actual file. but i guess that''s your choice.\n
    - stay with the slice operator, but do not change the loop variable inside\n
      the loop. for fun, try the generator expression (or keep the listcomp). baselen\n
      len(self.basepath) return (path[baselen].replace("", "\\") for path in paths)\n
      edit `lstrip()'' is not relevant here. from the manual str.lstrip([chars]) return\n
      a copy of the string with leading characters removed. if chars is omitted or none,\n
      whitespace characters are removed. if given and not none, chars must be a string;\n
      the characters in the string will be stripped from the beginning of the string\n
      this method is called on.\n
    - hm... that would do it baselen = len(self.basepath) for path in paths\n
      path = path[baselen].replace("", "\\") newpaths.append(path) return newpaths\n
      if you like, you can do it like this baselen = len(self.basepath) return (path[baselen].replace("",\n
      "\\") for path in paths) not calculating baselen in every loop iteration is also\n
      good practice.\n
    - there are two ways i could imagine handling this have your backend script\n
      (python) output the information of a long process to a log of some sort (text\n
      file, database, session, etc...) and then have javascript grab the information\n
      via ajax and update the current page. same deal, but instead of ajax just have\n
      a meta refresh on the page which would grab the latest updated information.\n
    - check the max_packet setting in your my.cnf file. this determines the largest\n
      amount of data you can send to your mysql server in a single statement. exceeding\n
      this values results in that error.\n
    - i will start answering this question here while we perform tests but i''d\n
      love to have feedback from other users. install we have spent a small afternoon\n
      from tuto to "how to" to finally install and run the thing on a virtual machine.\n
      this one is ok  there are setuptools packages but this does not works out of\n
      the box (and certainly not without compiling anything). we had to install  setuptools\n
      >= 0.6c5 (tested with 0.6c9 from of course, compilation implies installing gcc,\n
      linux-header et lib6-dev libxslt in dev (we used libxslt1-dev) linking with zl\n
      so zlib (we used zlib1g-dev) you''d better install pastescript before starting\n
      the deliverance install installing python-nose is not mandatory but it helps to\n
      check if everything went fine we did not manage to make it works with python-virtualenv\n
      to we definitly messed up the debian system but it seems to run ok. hope it can\n
      help.\n
    - if your python application runs in the 64-bit space, you will need to access\n
      a 64-bit installation of oracle''s oci.dll, rather than the 32-bit version. normally\n
      you would update the system path to include the appropriate oracle home bin directory,\n
      prior to running the script. the solution may also vary depending on what component\n
      you are using to access oracle from python.\n
    - you need to append the c\oracle32\bin directory to the path variable of\n
      your environment before you execute python.exe. in linux, i need to set up the\n
      ld_library_path variable for similar reasons, to locate the oracle libraries,\n
      before calling python. i use wrapper shell scripts that set the variable and then\n
      call python. in your case, maybe you can call, in the service startup, a .cmd\n
      or .vbs script that sets the path variable and then calls python.exe with your\n
      .py script. i hope this helps!\n
    - if you really want your function to run and still wants user (or system)\n
      input, you have two solutions multi-thread multi-process it will depend on how\n
      fine the interaction. if you just want to interrupt the function and don''t care\n
      about the exit, then multi-process is fine. in both cases, you can rely on some\n
      shared resources (file or shared memory for multi-thread, variable with associated\n
      mutex for multi-thread) and check for the state of that resource regularly in\n
      your function. if it is set up to tell you to quit, just do it. example on multi-thread\n
      from threading import thread, lock from time import sleep class myfct(thread)\n
      def __init__(self) thread.__init__(self) self.mutex = lock() self._quit = false\n
      def stopped(self) self.mutex.acquire() val = self._quit self.mutex.release()\n
      return val def stop(self) self.mutex.acquire() self._quit = true self.mutex.release()\n
      def run(self) i = 1 j = 1 print i print j while true if self.stopped() return\n
      i,j = j,i+j print j def main_fct() t = myfct() t.start() sleep(1) t.stop() t.join()\n
      print "exited" if __name__ == "__main__" main_fct()\n
    - you''ll probably get some good documentation here \n
    - it probably is only trying to add it on your instance of vs. you have to\n
      remove the cache so vs thinks its no longer under ss under file -> sourcecontrol\n
      > workspaces select the ss location edit choose the working folder remove!\n
    - those things are pernicious! visual studio sticks links to sourcesafe in\n
      everywhere, including into the xml that makes up your sln file. i wrote an article\n
      about my experiences converting sourcesafe to subversion, and included with it\n
      the python script that i used to clean out the junk. please note 1) this is very\n
      lightly tested. make backups so you don''t screw up your sln*proj files. run\n
      your test suite before and after to make sure it didn''t screw up something (how\n
      could it? who knows! but stranger things have happened.) 2) this may have been\n
      with a different version of sourcesafe and visual studio in mind, so you may need\n
      to tweak it. anyway, without further ado import os, re proj_re = re.compile(r"^\s+scc")\n
      sln_re = re.compile(r"globalsection\(sourcecodecontrol\).*?endglobalsection",\n
      re.dotall) vdproj_re = re.compile(r"^\"scc") for (dir, dirnames, filenames) in\n
      os.walk(''.'') for fname in filenames fullname = os.path.join(dir, fname) if\n
      fname.endswith(''scc'') os.unlink(fullname) elif fname.endswith(''vdproj'')\n
      #installer project has a different format fin = file(fullname) text = fin.readlines()\n
      fin.close() fout = file(fullname,'w'') for line in text if not vdproj_re.match(line)\n
      fout.write(line) fout.close() elif fname.endswith(''csproj'') fin = file(fullname)\n
      text = fin.readlines() fin.close() fout = file(fullname,'w'') for line in text\n
      if not proj_re.match(line) fout.write(line) fout.close() elif fname.endswith(''sln'')\n
      fin = file(fullname) text = fin.read() fin.close() text = sln_re.sub("", text)\n
      fout = file(fullname,'w'') fout.write(text)\n
    - once you get the name of the function, use a dispatch dict to run the function\n
      def mysum(...) ... def myotherstuff(...) ... # create dispatch dict myfunctions\n
      {''sum'' mysum,'stuff'' myotherstuff} # run your parser function_name,\n
      parameters = parse_result(line) # run the function myfunctions[function_name](parameters)\n
      alternatively create a class with the commands class commands(object) def do_sum(self,\n
      ...) ... def do_stuff(self, ...) ... def run(self, funcname, params) getattr(self,\n
     'do_'' + funcname)(params) cmd = commands() function_name, parameters = parse_result(line)\n
      cmd.run(function_name, parameters) you could also look at the cmd module in the\n
      stdlib to do your class. it can provide you with a command-line interface for\n
      your language, with tab command completion, automatically.\n
    - it all depends on what code you are parsing. if you are parsing python\n
      syntax, use the parser module from python a quite complete list of parser libraries\n
      available for python you can find at\n
    - check out pyparsing, it allows for definition of the grammar directly in\n
      python code assuming a function call is just somename()  from pyparsing import\n
      *  grammar = word(alphas + "_", alphanums + "_")("func_name") + "()" + stringend()  grammar.parsestring("ab()\n")["func_name"]\n
      "ab"\n
    - take a look at ply. it should help you keep your parser specification clean.\n
    - thanks guys. after doing some more searching i found exactly what i was\n
      looking for here. it''s an example project directory structure and settings.py.\n
      if you view the comments there you can see a lot of others were confused about\n
      this as well and found the example helpful. it would be nice if django created\n
      a recommended dir structure so you know where to store css, js, django app files,\n
      template files, etc.\n
    - don''t use apache for development, that''ll make you tear your hair out\n
      restarting apache every fifteen seconds (edit or you could just use pythondebug\n
      on). this technique is how to get your media (stylesheets, etc) loading via the\n
      development server. if you used that exact snippet, you''d need to set media_url\n
      to'site_media'' and media_root to'pathtomedia'' (obviously this latter\n
      is likely to need changing to wherever your media files actually are).\n
    - there''s a lot to your question, so i''ll try to boil it down to this\n
      the tutorial is aimed at getting you to use the framework and to be up and running\n
      with as little configuration as possible. no server to configure, etc. if you\n
      are trying to load css with the dev server, you will need to pull the css from\n
      somewhere "beyond" the dev server. for example, on my mac, i launch the dev server,\n
      but load the css from the built-in apache server. there is more info available\n
      about using apache and mod-python here mod_python and apache setup info i''m\n
      not sure what you mean by "creating the directory structure", but most of the\n
      core application files are typically created by running the django-admin.py script,\n
      by running startproject and startapp. this is demonstrated in the tutorial. you\n
      can also ask questions on the irc #django channel! if you are looking for a book\n
      on the subject, you can also check out the django book.\n
    - send the 50 quid to me ) (i''m kidding, of course)\n
    - try here instead. these are places where you can hire people to do small\n
      freelance work for you.\n
    - you probably don''t need to pay to learn python. implementing cellular\n
      automata makes for good starting project. the best place to start with python\n
      is the official tutorial and you can follow that with dive into python. the answers\n
      here and here may be helpful as well. if you can bear the self-praising and claims\n
      to godness wolfram''s book is a good way to get a feel for cellular automata,\n
      but don''t take the book itself too seriously (that''s a separate issue that can\n
      fill several blog posts). he also has a set of papers on this stuff that is published\n
      as a book that goes into all the details. and of course if you just google for\n
      cellular automata and conway''s game you''ll find a myriad of implementations\n
      and explanations.\n
    - if you use a child thread to run the function while the main thread waits\n
      for character input it should work. just remember to have something that stops\n
      the child thread (in the example below the global runthread) for example import\n
      threading, time runthread = 1 def myfun() while runthread print "a" time.sleep(.1)\n
      t = threading.thread(target=myfun) t.start() raw_input("") runthread = 0 t.join()\n
      does just that\n
    - there''s a few people on the pygame.org website who''ve done their versions\n
      of the game of life. maybe they''ll be of help pygame.org - search "life"\n
    - just tried the code to make sure, but this does do what it''s supposed\n
      to... you can type q and enter in to the console and make the application quit\n
      before a=0 (so it says hey less then 5 times) i don''t know what you mean by the\n
      raw_input dialog, raw_input normally just takes info from stdin\n
    - sys.path is python''s internal representation of the pythonpath, it sounds\n
      to me like you want to modify the path. i''m not sure that this will work, but\n
      you can try import os os.environ[''path''] += os.pathsep + "c\\oracle32\\bin"\n
    - as in almost all languages while true # check what you want and eventually\n
      break print nextvalue() the second part of your question is more interesting\n
      also, if it is based on time then is there anyway i could just extend the time\n
      and start it going from that point again rather than having to start again from\n
      0 you can use a yield instead of return in the function nextvalue()\n
    - "i don''t find the error at compile but at run time" correct. true for\n
      all non-compiled interpreted languages. "i need to change and run the script again"\n
      also correct. true for all non-compiled interpreted languages. "is there a way\n
      to have it break and let me modify and run?" what? if it''s a run-time error,\n
      the script breaks, you fix it and run again. if it''s not a proper error, but\n
      a logic problem of some kind, then the program finishes, but doesn''t work correctly.\n
      no language can anticipate what you hoped for and break for you. or perhaps you\n
      mean something else. "...code that needs a lot of enums" you''ll need to provide\n
      examples of code that needs a lot of enums. i''ve been writing python for years,\n
      and have no use for enums. indeed, i''ve been writing c++ with no use for enums\n
      either. you''ll have to provide code that needs a lot of enums as a specific example.\n
      perhaps in another question along the lines of "what''s a pythonic replacement\n
      for all these enums." it''s usually polymorphic class definitions, but without\n
      an example, it''s hard to be sure.\n
    - python is an interpreted language, there is no compile stage, at least\n
      not that is visible to the user. if you get an error, go back, modify the script,\n
      and try again. if your script has long execution time, and you don''t want to\n
      stop-restart, you can try a debugger like pdb, using which you can fix some of\n
      your errors during runtime. there are a large number of ways in which you can\n
      implement enums, a quick google search for "python enums" gives everything you''re\n
      likely to need. however, you should look into whether or not you really need them,\n
      and if there''s a better, more'pythonic'' way of doing the same thing.\n
    - with interpreted languages you have a lot of freedom. freedom isn''t free\n
      here either. while the interpreter won''t torture you into dotting every i and\n
      crossing every t before it deems your code worthy of a run, it also won''t try\n
      to statically analyze your code for all those problems. so you have a few choices.\n
      1) {pyflakes, pychecker, pylint} will do static analysis on your code. that settles\n
      the syntax issue mostly. 2) test-driven development with nosetests or the like\n
      will help you. if you make a code change that breaks your existing code, the tests\n
      will fail and you will know about it. this is actually better than static analysis\n
      and can be as fast. if you test-first, then you will have all your code checked\n
      at test runtime instead of program runtime. note that with 1 &amp; 2 in place\n
      you are a bit better off than if you had just a static-typing compiler on your\n
      side. even so, it will not create a proof of correctness. it is possible that\n
      your tests may miss some plumbing you need for the app to actually run. if that\n
      happens, you fix it by writing more tests usually. but you still need to fire\n
      up the app and bang on it to see what tests you should have written and didn''t.\n
    - you might want to look into something like nosey, which runs your unit\n
      tests periodically when you''ve saved changes to a file. you could also set up\n
      a save-event trigger to run your unit tests in the background whenever you save\n
      a file (possible e.g. with komodo edit). that said, what i do is bind the f7 key\n
      to run unit tests in the current directory and subdirectories, and the f6 key\n
      to run pylint on the current file. frequent use of these allows me to spot errors\n
      pretty quickly.\n
    - the simplest way is just to write a program with an infinite loop, and\n
      then hit control-c to stop it. without more description it''s hard to know if\n
      this works for you. if you do it time-based, you don''t need a generator. you\n
      can just have it pause for user input, something like a "continue? [yn]", read\n
      from stdin, and depending on what you get either exit the loop or not.\n
    - you mean the while loop runs before the thread? well, you can''t predict\n
      this unless you synchronize it. no one guarantees you that the thread will run\n
      before or after that while loop. but if it''s being blocked for 5 seconds that''s\n
      akward - the thread should have been pre-empted by then. also, since you''re first\n
      use of wanttoquit is in the run() method, no one assures you that the thread has\n
      been started when you''re checking for it''s wanttoquit attribute in while not\n
      mythread.wanttoquit .\n
    - the behaviour here is not what you described. look at those sample outputs\n
      i got 1st pressing qenter as fast as possible hey q 2nd wait a bit before\n
      pressing qenter hey hey hey q 3rd don''t touch the keyboard hey hey hey hey\n
      hey hey # application locks because main thread is over but # there are other\n
      threads running. add mythread.wantquit = 1 # to prevent that if you want\n
    - huperboreean has your answer. the thread is still being started when the\n
      for loop is executed. you want to check that a thread is started before moving\n
      into your loop. you could simplify the thread to monitor raw_input, and return\n
      when a'q'' is entered. this will kill the thread. you main for loop can check\n
      if the thread is alive.\n
    - i think you can get the result you want by doing something like this for\n
      i in range(2, 11) print 1.0*(1 % i)  i this computes the (integer) remainder\n
      as explained by others. then you divide by the denominator again, to produce the\n
      fractional part of the quotient. note that i multiply the result of the modulo\n
      operation by 1.0 to ensure that a floating point division operation is done (rather\n
      than integer division, which will result in 0).\n
    - modulo is performed in the integer context, not fractional (remainders\n
      are integers). therefore 1 % 1 = 0 (1 times 1 plus 0) 1 % 2 = 1 (2 times 0 plus\n
      1) 1 % 3 = 1 (3 times 0 plus 1) 6 % 3 = 0 (3 times 2 plus 0) 7 % 3 = 1 (3 times\n
      2 plus 1) 8 % 3 = 2 (3 times 2 plus 2) etc how do i get the actual remainder of\n
      x  y? by that i presume you mean doing a regular floating point division? for\n
      i in range(2, 11) print 1.0  i\n
    - wouldn''t dividing 1 by an number larger than it result in 0 with remainder\n
      1? the number theorists in the crowd may correct me, but i think modulusremainder\n
      is defined only on integers.\n
    - you''ve confused division and modulus. "0.5, 0.333333, 0.25" etc. as i\n
      expected (12 = 0.5, etc)." that''s the result of division. not modulus. modulus\n
      (%) is the remainder left over after integer division. your sample values are\n
      simple division, which is the  operator. not the % operator.\n
    - it seems you are trying to use the solution marked in this question. if\n
      your goal is access values in a loop, you should just use a list. this weird concept\n
      of variable names with numbers in them is not one that should be used in any language.\n
      try this. vals = [''foo'','bar'','blah'', 67, -0.4,'your mom''] for i in\n
      range(len(vals)) print(vals[i]) that is the correct way to have a list of values\n
      indexed by an integer, not putting it in the variable name.\n
    - it looks like the code you''re generating expands to e0=zbc e1=2.3 at\n
      the next iteration through the loop, you''ll get an indexerror exception because\n
      a is only two elements long. so given the above, you are trying to assign the\n
      value of zbc to e0. if zbc doesn''t exist (which it seems that it doesn''t), then\n
      you will get the nameerror you mention. it''s hard to determine what you''re actually\n
      trying to do with this code, so i''m not sure what to recommend. you could assign\n
      strings instead exec(''e%d="%s"'' %(i,a[i])) this would expand to e0="zbc" e1="2.3"\n
      you would still get the indexerror because your array a is not 5 elements long.\n
      that should be an easy fix for you.\n
    - A_Body "just keep in mind thatexec' executes whatever string you pass in to it\\n
      as if you typed it in your .py file or the interpreter. when debugging exec()\\n
      related code, it's helpful to log whatever you're about toexec' when you run\\n
      into trouble, if you did that you'd easily have noticed that e0 wasn't being\\n
      assigned to the string \"zbc\" but to the non-existent object zbc. aside from\\n
      that, this code sample is really weird. \xE2\_there are some legitimate uses\\n
      for parsing strings into instance variables, or objects in other namespaces,\\n
      most notably when you're coding a highly dynamic class that needs to do sensible\\n
      stuff with messy input, or needs to setup a bunch of instance variables from\\n
      a dict or string. \xE2\_but without context, the code in your question looks\\n
      like you're avoiding, or don't understand how, to use list() and dict() objects..\\n
      i'd recommend telling a bit more about what you're trying to achieve next time\\n
      you ask a question around something as peculiar as this. \xE2\_that would give\\n
      people a good opportunity to suggest a better solution, or \xE2\x80\x93if you're\\n
      approaching a particular problem in a completely sensible way\xE2\x80\x93 prevent\\n
      a bunch of answers telling you that you're doing something completely wrong. "\n
    - okay. this code is very weird. as a one liner like this, it''s not syntactically\n
      correct, but i suspect you''re missing line breaks for some reason. but then it\n
      becomes a = [''zbc'',''2.3''] for i in range(0,5) exec(''e%d=%s'' %(i,a[i]))\n
      but that will result in an index error on the reference to a[i] as shown  a [''zbc'',\n
     '2.3'']  for i in range(0,5) ... print a[i] ... zbc 2.3 traceback (most recent\n
      call last) file "stdin", line 2, in module indexerror list index out of range\n
      if you avoided that issue, you''d get exec("e2.3=1") on the second pass through\n
      the lopp, and that''s a syntax error too.\n
    - python does not support the concept of passing a string "by reference"\n
      in the same way that vb.net does. so it might not be possible to do this without\n
      some more work. however, without seeing your code it''s definitely not possible\n
      to tell you what''s wrong.\n
    - python strings are immutable. there is no way the string can be changed\n
      inside the function. so what you really want is to pass a char buffer of some\n
      sort. you can create those in python using the ctypes module. please edit the\n
      question and paste a minimal snippet of the code so we can test and give more\n
      information.

#- intent: subject
#  examples: |
#    - I want to take test
#    -
#    - I want to take exam
#
#- intent: goodbye
#  examples: |
#    - good afternoon
#    - cu
#    - good by
#    - cee you later
#    - good night
#    - bye
#    - goodbye
#    - have a nice day
#    - see you around
#    - bye bye
#    - see you later
#
#- intent: affirm
#  examples: |
#    - yes
#    - y
#    - indeed
#    - of course
#    - that sounds good
#    - correct
#
#- intent: affirm
#  examples: |
#    - yes
#
#- intent: deny
#  examples: |
#    - no
#    - n
#    - never
#    - I don't think so
#    - don't like that
#    - no way
#    - not really
#
#- intent: mood_great
#  examples: |
#    - perfect
#    - great
#    - amazing
#    - feeling like a king
#    - wonderful
#    - I am feeling very good
#    - I am great
#    - I am amazing
#    - I am going to save the world
#    - super stoked
#    - extremely good
#    - so so perfect
#    - so good
#    - so perfect
#
#- intent: mood_unhappy
#  examples: |
#    - my day was horrible
#    - I am sad
#    - I don't feel very well
#    - I am disappointed
#    - super sad
#    - I'm so sad
#    - sad
#    - very sad
#    - unhappy
#    - not good
#    - not very good
#    - extremly sad
#    - so saad
#    - so sad
#
#- intent: bot_challenge
#  examples: |
#    - are you a bot?
#    - are you a human?
#    - am I talking to a bot?
#    - am I talking to a human?
